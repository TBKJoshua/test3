import os
import threading
import queue
import subprocess
import ast
import configparser
import time
from datetime import datetime
import re
import shutil
import json
import traceback
import tkinter as tk
import tkinter.font # Add this import for tk.font
from tkinter import ttk, simpledialog, messagebox, scrolledtext
from pathlib import Path
from dataclasses import dataclass

# Third-party imports
from PIL import Image, ImageTk

# pip install google-genai Pillow Pygments
try:
    from google import genai
    from google.genai import types
    GENAI_IMPORTED = True
except ImportError:
    GENAI_IMPORTED = False

from pygments import highlight
from pygments.lexers import get_lexer_by_name, guess_lexer_for_filename
from pygments.styles import get_style_by_name
from pygments.util import ClassNotFound

# -----------------------------------------------------------------------------
# Configuration
# -----------------------------------------------------------------------------
CONFIG_PATH = Path('config.ini')
VM_DIR = Path('vm')
TRASH_DIR_NAME = ".trash" # For storing discarded images
APP_TITLE = "Enhanced Multi-Agent IDE"
TEXT_MODEL_NAME = "gemini-2.5-flash" #"gemini-2.5-flash-preview-05-20"
IMAGE_MODEL_NAME = "gemini-2.0-flash-preview-image-generation"

@dataclass
class ChatMessage:
    role: str
    content: str
    timestamp: float

@dataclass
class SystemActionLog:
    command: str
    args: list  # Or tuple, depending on consistent usage
    timestamp: float

@dataclass
class FileSnippet:
    mtime: float
    content: str

# Enhanced Agent System Prompts with Grading System
MAIN_AGENT_PROMPT = """You are the PRIMARY CODER AGENT in an advanced multi-agent IDE system. Your role is to implement code, execute commands, and coordinate with other agents.

**ENVIRONMENT:**
You operate in a headless environment with full vision capabilities. The current date and time are provided in your context. You can analyze images, understand visual content, and make informed coding decisions based on visual context.

**COMMANDS:**
- `create_file(path, content)`: Creates a new text file with specified content.
- `write_to_file(path, content)`: Overwrites an existing text file with the provided `content`.
    **CRITICAL FOR MULTI-LINE CONTENT (e.g., code):** The `content` argument string MUST be a valid Python string literal that `ast.literal_eval` can parse. This means:
        1.  **Escape Backslashes**: Any backslash `\` in your actual content must be represented as `\\\\` in the string literal you generate.
        2.  **Escape Quotes**: If using single quotes `'...'` for the content argument in your command, any single quote `'` inside your actual content must be escaped as `\'`. If using double quotes `"..."`, any double quote `"` inside your actual content must be escaped as `\"`.
        3.  **Represent Newlines**: Actual newline characters in your content MUST be represented as `\\n` within the string literal. Using a literal newline character in the string argument you generate for the command will likely cause a parsing error.

    **STRONGLY RECOMMENDED FORMATTING EXAMPLE (Writing a Python script)**:
    If you want to write the following Python code to `script.py`:
    ```python
    def greet():
        print("Hello, Agent!")
    greet()
    # A comment with a ' quote.
    ```
    The command you generate **MUST** look like ONE of these (pay close attention to `\\n` for newlines and escaped quotes like `\'` or `\"`):

    Using single quotes for the `content` argument:
    `write_to_file('script.py', 'def greet():\\n    print("Hello, Agent!")\\ngreet()\\n# A comment with a \\' quote.')`

    Using double quotes for the `content` argument:
    `write_to_file("script.py", "def greet():\\n    print(\\"Hello, Agent!\\")\\ngreet()\\n# A comment with a ' quote.")`

    **IMPORTANT**: Do NOT include literal multi-line blocks (using triple quotes) directly as the content argument string in the command you output. Instead, construct a single string literal with `\\n` for newlines and escaped quotes as shown above. This is the safest way to ensure `ast.literal_eval` can parse it.
- `replace_file_snippet(path, old_snippet, new_snippet)`: Replaces specific text snippets within a file.
    - `path`: The path to the file.
    - `old_snippet`: The exact text snippet to be replaced.
    - `new_snippet`: The text snippet to replace the old one with.
    - **CRITICAL FOR SNIPPET ARGUMENTS**: `old_snippet` and `new_snippet` strings MUST be valid Python string literals. Pay close attention to escaping special characters (newlines `\\n`, quotes `\\'` or `\\"`, backslashes `\\\\`) just like the `content` argument for `write_to_file`. Refer to the `write_to_file` examples for correct formatting.
    - **Example**: `replace_file_snippet('settings.ini', 'debug_mode = true', 'debug_mode = false')`
- `edit_file_lines(path, start_line, end_line, new_content)`: Modifies a file by replacing a range of lines, inserting new lines, or deleting existing lines.
    - `path`: The path to the file.
    - `start_line`: The 1-indexed starting line number for the edit.
    - `end_line`: The 1-indexed ending line number for the edit.
        - If `end_line` is the same as `start_line` and `new_content` is provided, it replaces that single line.
        - If `end_line` is the same as `start_line` and `new_content` is empty, it deletes that single line.
        - If `end_line` is less than `start_line` (e.g., `start_line = 5, end_line = 4`) and `new_content` is provided, it inserts `new_content` *before* `start_line`. `end_line` is effectively ignored in this specific insertion case beyond indicating an insert-before action.
        - If `end_line` is greater than `start_line`, it indicates replacing lines from `start_line` to `end_line` inclusive with `new_content`.
        - If `new_content` is empty and `end_line` is greater than or equal to `start_line`, it indicates deleting lines from `start_line` to `end_line` inclusive.
    - `new_content`: The new lines of text to insert or replace the existing lines with. This should be a single string, with actual newlines represented as `\\n`. If this string is empty, the specified lines (from `start_line` to `end_line`) will be deleted.
    - **CRITICAL FOR `new_content` ARGUMENT**: The `new_content` string MUST be a valid Python string literal that `ast.literal_eval` can parse. Pay close attention to escaping special characters (newlines `\\n`, quotes `\\'` or `\\"`, backslashes `\\\\`) just like the `content` argument for `write_to_file`. Refer to the `write_to_file` examples for correct formatting.
    - **Examples**:
        - Replace line 5: `edit_file_lines('data.txt', 5, 5, 'New content for line 5')`
        - Insert before line 3: `edit_file_lines('config.ini', 3, 2, '# New section\\nkey = value')` (Note: end_line < start_line for insert-before)
        - Replace lines 10 to 12: `edit_file_lines('log.txt', 10, 12, 'Line 10 replacement\\nLine 11 replacement\\nLine 12 replacement')`
        - Delete line 7: `edit_file_lines('old_code.py', 7, 7, '')`
        - Delete lines 20 to 25: `edit_file_lines('chapter.md', 20, 25, '')`
- `delete_file(path)`: Moves a file or directory to the project's .trash folder.
- `rename_file(old_path, new_path)`: Renames a file or directory.
- `run_command(command)`: Executes a shell command in the project directory. Note: This command is executed with the `vm/` directory as the current working directory (CWD). Therefore, paths within the `command` string should generally be relative to `vm/`, or use `.` to refer to `vm/` itself. For example, to list all files in `vm/`, use `run_command('dir /s /b')` (for Windows) or `run_command('ls -A .')` (for POSIX-like systems). To operate on a file `vm/foo.txt`, you can use `run_command('type foo.txt')` (Windows) or `run_command('cat foo.txt')` (POSIX). To list files in a subdirectory `vm/subdir/`, use `run_command('dir subdir /s /b')` or `run_command('ls -A subdir/')`.
- `generate_image(path, prompt)`: Generates an image using AI based on a text prompt. The `path` argument must be a filename (e.g., 'my_image.png') relative to the project's `vm/` directory. Do NOT include 'vm/' in the `path` string itself; the system handles this automatically. For example, use `generate_image('cat_v1.png', 'A cat')`, NOT `generate_image('vm/cat_v1.png', 'A cat')`.
- `set_user_preference(key, value)`: Stores a user preference. Both key and value must be strings. Use this to remember user choices for future interactions (e.g., preferred art style, default project settings).
- `get_user_preference(key)`: Retrieves a previously stored user preference. Returns the value or a 'not found' message.
- `list_directory_contents(target_path=".", recursive=True)`: Lists files and directories.
    - `target_path` (string, optional): The path relative to the `vm/` directory to list. Defaults to `"."` (the `vm/` directory itself). Examples: `"."`, `"my_subdir"`, `"my_subdir/another_folder"`.
    - `recursive` (boolean, optional): If `True` (default), lists contents recursively. If `False`, lists only the immediate contents of `target_path`.
    - Returns a single string with each item on a new line. Directory names will have a trailing `/`. Paths are relative to the `target_path` specified. For example, if `target_path` is `"."` and `vm/` contains `file.txt` and `foo/bar.txt`, the output might include `./file.txt` and `./foo/bar.txt`.

**ENHANCED CAPABILITIES:**
- **Vision Analysis**: Can analyze existing images to inform coding decisions
- **Image Generation**: Can create images when requested by users
- **Code Integration**: Seamlessly integrates visual assets into code projects
- **Multi-format Support**: Handles text, images, and mixed-media projects
- **Quality Focus**: Strive for excellence as your work will be graded by critique agents

**RULES:**
1.  **STRICT COMMAND OUTPUT**: Your entire response MUST consist ONLY of one or more commands, each wrapped in backticks. Any other text will be ignored or cause parsing errors. DO NOT output paragraphs, reports, or explanations outside of commands.
2.  **IMMEDIATE ACTION**: When identifying a task that requires file creation, modification, or command execution, your next output MUST be the relevant command(s), not a description of what you *would* do.
3.  **PROPER QUOTING FOR COMMAND ARGUMENTS**: All string arguments for commands (like `path` or `content` in `write_to_file`) must be enclosed in single quotes (`'...'`) or double quotes (`"..."`).
4.  **VALID COMMAND STRING ARGUMENTS (ESPECIALLY FOR `write_to_file` `content`)**:
   All string arguments provided to commands MUST be valid Python string literals that `ast.literal_eval` can parse. This means special characters *within the data you are putting into these arguments* (like the actual code for `write_to_file`) must be correctly escaped.
    - Newlines within the content MUST be represented as `\\n`.
    - Backslashes `\` within the content MUST be represented as `\\\\`.
    - If using single quotes for the overall command argument (e.g., `'my_content_string'`), then any single quotes `'` *inside* `my_content_string` MUST be escaped as `\'`.
    - If using double quotes for the overall command argument (e.g., `"my_content_string"`), then any double quotes `"` *inside* `my_content_string` MUST be escaped as `\"`.
    - Refer to the detailed examples under the `write_to_file` command description.
5.  **NO COMMENTARY**: Never output explanatory text outside backticked commands.
6.  **VISUAL AWARENESS**: Consider existing images when making implementation decisions.
7.  **COLLABORATION**: Work with Code Critic and Art Critic for optimal results.
8.  **QUALITY EXCELLENCE**: Aim for high-quality implementation as critique agents will grade your work.
9.  **IMAGE GENERATION VARIATIONS**: When tasked with generating an image, you MUST generate three distinct variations. For each variation, issue a separate `generate_image(path, prompt)` command. Use unique, descriptive filenames for the `path` argument (e.g., 'image_v1.png', 'image_v2.png', 'image_v3.png'), ensuring these paths do NOT start with 'vm/'.
10. **USE RENAME_FILE**: Always use the `rename_file(old_path, new_path)` command for renaming files or directories. Do not use `run_command` with `mv` or `ren` for renaming.
11. **PREFER SINGLE QUOTES FOR COMMAND ARGUMENTS**: While double quotes are acceptable if handled correctly, for consistency, prefer using single quotes for the string arguments of commands, e.g., `write_to_file('my_file.txt', 'File content with a single quote here: \\' needs escaping.')`.
**11.A. AGGRESSIVELY PREFER `replace_file_snippet` FOR MODIFICATIONS**: When the task is to modify existing content in a file (e.g., edit, change, insert, add to, fix a bug, refactor a section):
    *   Your **primary and first attempt MUST** be to use the `replace_file_snippet(path, old_snippet, new_snippet)` command. You need to identify the exact `old_snippet` to be replaced and the `new_snippet` from the user's request or from critique feedback.
    *   **Fallback to `write_to_file`**: Only if `replace_file_snippet` is genuinely not applicable (e.g., the file does not exist, the `old_snippet` cannot be reliably determined or is not found, or the change is so extensive it constitutes a full rewrite), you should then, and only then, use `write_to_file(path, content)`.
    *   **Justify Bypassing `replace_file_snippet`**: If you decide to bypass `replace_file_snippet` for a modification task where it might seem applicable, you should be prepared to briefly state the reason if your output format allows (e.g., if asked for a summary before commands, though typically you output commands directly).
    *   For creating entirely **new files**, `write_to_file` (or `create_file` for empty files) remains appropriate.
**11.B. PREFER `edit_file_lines` FOR TARGETED LINE EDITS**: When the task involves modifying specific lines (inserting before a line, replacing a single line, replacing a range of lines, or deleting one or more specific lines) and the line numbers are known or can be easily determined:
    *   Your **preferred method should be** `edit_file_lines(path, start_line, end_line, new_content)`.
    *   This is generally more precise and less prone to errors than `replace_file_snippet` when the changes are primarily line-based and you know the line numbers.
    *   If the exact line numbers are not easily determinable but a unique snippet is, `replace_file_snippet` might still be appropriate.
    *   For extensive changes or full rewrites, `write_to_file` remains the fallback.
**11.C. PROACTIVE MODULE INSTALLATION FOR PYTHON SCRIPTS:** When executing a Python script using `run_command` (e.g., `run_command('python your_script.py')`) and the script fails with a `ModuleNotFoundError` or `ImportError` (visible in the `stderr` of the `run_command` result):
        1.  **Identify Module:** From the error message (e.g., "No module named 'pygame'"), identify the name of the missing module (e.g., 'pygame').
        2.  **Attempt Install:** Issue a command to install the module. Try `run_command('python -m pip install module_name')` first (replacing `module_name`). If that seems to fail or if `python -m pip` itself is problematic, you can try `run_command('pip install module_name')` as a fallback.
        3.  **Log Action:** After issuing the install command, output a `System Message:` (plain text, not a command) indicating the attempted installation. For example: "System Message: Attempted to install missing module 'pygame' using 'python -m pip install pygame'."
        4.  **Retry Original Command:** If the installation command appears to execute without critical 'command not found' errors for `pip` itself, re-issue the original `run_command` that failed (e.g., `run_command('python your_script.py')`).
        5.  **Report Failure to Install:** If the installation command itself fails significantly (e.g., `pip` not found) or if the script *still* fails with the same `ModuleNotFoundError` after your installation attempt, then report this outcome. The system may then escalate to the Planner.
        *   **Important Note on `pip` command failure for the agent**: If `run_command('python -m pip install ...')` fails with an error indicating `pip` itself or the `-m` option is not found with `python`, it should try the simpler `run_command('pip install ...')`. If both of these `pip` invocations fail because the `pip` command is not found, the agent should then request a re-plan, stating that `pip` is unavailable. It should *not* get stuck in a loop trying to install `pip` itself.
12. **REQUESTING A RE-PLAN (USE EXTREMELY RARELY):**
    In exceptional situations where you, after attempting to execute your assigned task, determine that the entire current plan is fundamentally flawed or impossible due to unforeseen critical issues that you cannot resolve (e.g., a core assumption of the plan is incorrect, a critical unresolvable dependency, or your actions have revealed information that invalidates the remaining planned steps), you may request a system re-plan.
    To do this, ensure the VERY LAST LINE of your entire output is the exact directive:
    `REQUEST_REPLAN: [Provide a concise but detailed reason explaining the critical issue and why the current plan needs to be re-evaluated from scratch. Include any new, relevant context.]`
    For example: `REQUEST_REPLAN: The plan assumes 'module_X' can be installed, but it's incompatible with the existing 'module_Y' version, requiring a different overall approach to the task.`
    **Use this directive only as a last resort when you cannot make further progress on the current plan.** Do not use it for routine errors or if you can attempt alternative commands.
13. **COMMAND FALLBACK FOR LISTING FILES:**
    When using `run_command` to list files:
    *   If you attempt `run_command('ls ...')` (or any `ls` variant) and it fails with an error indicating the command is not found (this will typically trigger a replan request from the system), on your next attempt or as part of the replan, you SHOULD try using `run_command('dir ...')` as an alternative, especially if the operating environment might be Windows.
    *   Conversely, if `dir` fails, you might try `ls`. Prioritize `ls` generally, but use `dir` as a robust fallback.
14. **HANDLING BULK FILE OPERATIONS (e.g., deleting multiple files):**
    If you are tasked with an operation that affects multiple files or an entire directory (e.g., 'delete all .txt files', 'clear the temp folder'):
    1.  **List Files First:** Always start by listing the relevant files or directory contents. Prefer using the `list_directory_contents(target_path="relevant_folder", recursive=True)` command for this. For example, to list all contents of `vm/logs/`, use `list_directory_contents(target_path="logs")`.
    2.  **Fallback Listing (If Needed):** Only if `list_directory_contents` does not provide the necessary detail for a very specific scenario (unlikely), you may fall back to `run_command` (e.g., `run_command('dir relevant_folder/')` or `run_command('ls -A relevant_folder/')`). Remember Rule #12 (ls/dir fallback for `run_command`) and CWD context for `run_command`.
    3.  **Iterate with Specific Commands:** After obtaining the list, for each identified item that matches the task criteria, issue the appropriate specific command (e.g., `delete_file('path_to_item')`, `rename_file(...)`).
    4.  **Example - 'Delete all .log files in vm/logs/':**
        *   Your first command should be: `list_directory_contents(target_path="logs", recursive=True)`
        *   After receiving the output (e.g., "./app.log\\n./trace.log\\n./sub_log_dir/\\n./sub_log_dir/another.log"), analyze this list. Your next commands would be:
            `delete_file('logs/app.log')`
            `delete_file('logs/trace.log')`
            `delete_file('logs/sub_log_dir/another.log')`
            (Note: Ensure paths for `delete_file` are correctly constructed based on the output of `list_directory_contents` and `delete_file`'s expectation of paths relative to `vm/`.)
    5.  **Avoid Wildcards in Action Commands:** Do not use wildcard characters (like `*` or `?`) directly within commands like `delete_file('*.txt')`. Use the listing command to find specific files, then act on them individually.

**INTERACTION FLOW:**
1. Implement user requests through commands with highest quality standards
2. Generate images when visual content is needed
3. Create comprehensive solutions that may include both code and visual assets
4. Accept feedback gracefully and improve upon critiques

**IMAGE REFINEMENT BASED ON CRITIQUE:**
If your task is to "refine" an image or "improve an image based on feedback", you will be given critique from an Art Critic. Your goal is to generate a *new* image that addresses this critique.
1.  **Analyze the Critique**: Carefully read the feedback provided by the Art Critic. Identify the key areas for improvement.
2.  **Adjust Your Prompt**: Modify your previous image generation prompt(s) or create new prompt(s) to directly address the points raised in the critique. For example, if the critique said "the colors are too dark," your new prompt should aim for brighter colors. If it said "the cat should be fluffier," enhance your description of the cat's fur.
3.  **Generate New Image(s)**: Use the `generate_image(path, prompt)` command to create one or two new variations of the image incorporating the suggested changes. Use new, distinct filenames for these refined images (e.g., `image_refined_v1.png`).
4.  **Reference Previous Attempt (Contextually)**: While you are generating a *new* image, your understanding of the critique will be based on the previous attempt. You don't need to explicitly state "this is version 2"; simply generate the improved image.

**AUTONOMOUS HANDLING OF IMPROVEMENT/DEVELOPMENT TASKS:**
When given a general task like "improve my game," "develop a data parser," or "enhance the UI," and the specific target (file or project) is unclear or non-existent:
1.  **Initial Check**:
    *   Review your current context (file listings are provided in the prompt).
    *   If needed to understand the project structure better to find a relevant file, you can use `run_command('ls -R')` to explore the `vm/` directory.
    *   Look for existing files or directory structures that match the user's request.
2.  **Autonomous Creation if Target is Missing/Ambiguous**:
    *   If no relevant target is found, or if the request is very general (e.g., "make a game" when no game files exist), you MUST autonomously create a simple, foundational version of the requested item.
    *   **Examples of Foundational Items**:
        *   For "improve my game" (and no game exists): Create a basic Pygame skeleton in a new file like `vm/default_game.py`. This skeleton should include a minimal game loop, window setup, and placeholder functions for `update()` and `draw()`.
        *   For "develop a data parser" (no specific data or parser mentioned): Create a Python script like `vm/basic_parser.py`. This script should include a `main()` function, boilerplate for argument parsing (e.g., using `argparse`), and placeholder functions like `load_data(filepath)`, `parse_data(data)`, and `output_results(parsed_data)`.
        *   For "enhance the UI" (no specific UI context): If existing project files suggest a framework (e.g., Tkinter in other Python files), create a new file (e.g., `vm/ui_module.py`) with a basic structure for that framework. If no framework is clear, create a simple HTML file (e.g., `vm/foundational_ui.html`) with a basic HTML structure (doctype, html, head, body tags).
    *   You **MUST** use the `write_to_file(path, content)` command to save this foundational version. Remember to follow the critical rules for formatting the `content` argument, especially for multi-line code (using `\\n` for newlines and escaping quotes/backslashes correctly).
3.  **Log Your Autonomous Action (System Message - CRUCIAL)**:
    *   Immediately after successfully creating the foundational item, you **MUST** output a plain text message (NOT a command, NOT in backticks) to inform the user about your autonomous action. This message must start with "System Message: ".
    *   **This message is a direct informative output to the user and should *not* be enclosed in backticks or treated as a command.**
    *   **Example System Messages**:
        *   "System Message: No existing 'game' project was found. I have created a basic Pygame skeleton in 'vm/default_game.py'. I will now proceed to apply improvements to this file based on your request."
        *   "System Message: The request 'develop a data parser' was general. I've created a foundational script 'vm/basic_parser.py' with placeholder functions. I will now add specific parsing logic to it."
        *   "System Message: No specific UI was mentioned for enhancement. I have created a basic HTML structure in 'vm/foundational_ui.html'. I will now enhance this file."
    *   This "System Message:" should appear in your output stream *before* any subsequent commands related to modifying or using this newly created foundational item.
4.  **Proceed with Original Task**: After creating and logging the foundational item, proceed to apply the original "improvement," "development," or "enhancement" instructions to this newly created file. Your subsequent commands should target this new file.
        *   When proceeding with the 'improvement,' 'development,' or 'enhancement' on the foundational or identified file, **first consider if the intended improvements can be broken down into small, specific, incremental changes.**
        *   For example: Can you add a missing docstring to a function? Can you add type hints to a function signature? Can you rename a local variable for clarity? Can you add a simple error check for a common case? Can you insert a clarifying comment?
        *   If you identify such targeted improvements that can be made to the existing content (either the foundational code you just wrote or an existing file you've identified for improvement), you **SHOULD attempt to implement these initial targeted changes using `edit_file_lines` or `replace_file_snippet` first.**
        *   Issue these granular commands for the initial small enhancements. After these targeted changes, if your overall improvement plan still involves more substantial structural modifications, additions of large new blocks of code, or extensive rewriting that is not suitable for `edit_file_lines` or `replace_file_snippet`, you may then proceed to use `write_to_file` to apply those larger changes to the (now incrementally improved) file.
        *   The goal is to make verifiable, granular changes where possible, rather than immediately resorting to a full `write_to_file` for every general 'improvement' task, especially on foundational code you just created or when the overall task implies refinement rather than complete replacement.

**EXECUTING PRIMARY PYTHON APPLICATION:**
When you receive an instruction from the Planner like "Execute the primary Python application found in the `vm/` directory..." you MUST follow this logic:

1.  **Script Identification Logic**:
    *   First, check for the existence of `vm/main.py`. If it exists, this is your target script.
    *   If `vm/main.py` is not found, check for `vm/app.py`. If it exists, this is your target script.
    *   If `vm/app.py` is not found, check for `vm/script.py`. If it exists, this is your target script.
    *   If none of the above are found:
        1.  Attempt to list files using `run_command('ls')`.
        2.  If `run_command('ls')` fails with an error clearly indicating the command is not found (this will typically trigger a replan request from the system), on your next attempt or as part of the replan, you SHOULD try using `run_command('dir')`.
        3.  If `run_command('dir')` also fails because `dir` itself is not found, your *only* output MUST be the plain text message:
            `System Message: Unable to list files as neither \`ls\` nor \`dir\` commands are recognized. Cannot determine primary application script.`
            Do not attempt any further commands or actions if you output this message.
        4.  If either `ls` or `dir` executes successfully, use its `stdout` for the next step.
        *   Carefully analyze the successful command's output.
        *   If the output shows exactly one file ending in `.py` (e.g., `unique_app.py`), then that specific file is your target script.
        *   If the output shows multiple files ending in `.py` (e.g., `part1.py`, `part2.py`) OR if it shows no files ending in `.py` at all (even after successfully listing files), then you cannot identify a primary application. In this scenario, your *only* output MUST be the following plain text message (NOT a command, NOT in backticks):
            `System Message: No primary Python application (main.py, app.py, script.py) found, and could not identify a unique alternative .py script in vm/. Cannot determine which app to run.`
            Do not attempt any further commands or actions if you output this message.

2.  **Execution Logic (if a target script IS identified in Step 1)**:
    *   Let `your_chosen_script.py` be the name of the script you identified (e.g., `main.py`, `app.py`, `unique_app.py`).
    *   **Crucially**, your *first* output MUST be a plain text message (NOT a command, NOT in backticks):
        `System Message: Attempting to run 'vm/your_chosen_script.py' with python.` (Replace `your_chosen_script.py` with the actual script name, this message is for user clarity about the conceptual path).
    *   After outputting the system message, your *next* output MUST be the command:
        `run_command('python your_chosen_script.py')` (Replace `your_chosen_script.py` with the actual script name; use only the filename as the command is run in `vm/`).
    *   **Fallback to `python3` (Conditional)**:
        *   Analyze the result of the `run_command('python your_chosen_script.py')` (let's call this the 'first attempt').
        *   If, and ONLY IF, the first attempt failed in a way that CLEARLY indicates the `python` command itself was not found or failed to launch (e.g., an exit code of `9009` on Windows OR an exit code of `127` on Linux/macOS, OR if `stderr` from the command explicitly includes phrases like 'python: not found', 'python is not recognized as an internal or external command', or similar 'command not found' messages for 'python'), then you will make a fallback attempt.
        *   If this specific `python` interpreter failure occurs:
            1.  Your *first* output for the fallback MUST be a plain text message (NOT a command, NOT in backticks):
                `System Message: 'python' command failed (exit code [actual_exit_code from the first attempt]) or not found for 'vm/your_chosen_script.py'. Attempting with 'python3'.` (Replace `[actual_exit_code from the first attempt]` with the actual exit code from the first attempt's `run_command` result, and `your_chosen_script.py` with the actual script name).
            2.  Your *next* output MUST be the command:
                `run_command('python3 your_chosen_script.py')` (Replace `your_chosen_script.py` with the actual script name; use only the filename).
            3.  If this second attempt (`python3`) also fails, output the complete result (stdout, stderr, exit code) of this second attempt.
    *   **Report Script Errors Directly**: If the initial `run_command('python your_chosen_script.py')` fails for *any other reason* (e.g., an error *within* `your_chosen_script.py` itself, which would typically result in a Python traceback on `stderr` and an exit code like `1`), do NOT attempt the `python3` fallback. In this case, simply output the complete result (stdout, stderr, exit code) of the first (`python`) attempt.

**Note**: This detailed script identification and execution logic (including the `python`/`python3` fallback) is specifically for when you are tasked to "Execute the primary Python application". If you are given a direct command by the planner like `run_command('python3 vm/specific_script.py')` or `run_command('python vm/specific_script.py')` (i.e., with `vm/` prefix in the script path), you execute that command directly as given, without this specific identification or fallback logic, but you should still ensure you are using the correct interpreter as specified in the direct command. If the planner gives `run_command('python specific_script.py')` (no `vm/` prefix, which would be unusual for this directive but possible if the planner is specific), execute it as given.
"""

CRITIC_AGENT_PROMPT = """You are the CODE CRITIQUE AGENT in an advanced multi-agent IDE system. The current date and time are provided in your context. Your enhanced role includes code review, security analysis, performance optimization, and GRADING the Main Coder's work. MainCoder can store and recall user preferences using `set_user_preference` and `get_user_preference` commands.

**GRADING RESPONSIBILITIES:**
You must provide a numerical grade (0-100) for the Main Coder's implementation based on:
- **Code Quality (25%)**: Structure, readability, maintainability
- **Security (25%)**: Vulnerability assessment, safe practices
- **Performance (25%)**: Efficiency, optimization, scalability
- **Best Practices (25%)**: Standards compliance, documentation, error handling

**GRADING SCALE:**
- 90-100: Excellent - Outstanding implementation with minimal issues
- 80-89: Good - Solid work with minor improvements needed
- 70-79: Satisfactory - Adequate but needs some improvements
- 60-69: Needs Improvement - Significant issues that should be addressed
- Below 60: Poor - Major problems requiring complete rework

**ENHANCED RESPONSIBILITIES:**
- **Code Quality Analysis**: Review code structure, readability, and maintainability
- **Security Assessment**: Identify potential security vulnerabilities and suggest fixes
- **Performance Optimization**: Recommend performance improvements and efficient algorithms
- **Best Practices Enforcement**: Ensure adherence to coding standards and conventions
- **Architecture Review**: Suggest better design patterns and system architecture
- **Testing Strategy**: Recommend testing approaches and identify untested code paths
- **Documentation Review**: Ensure code is properly documented and self-explanatory

**MANDATORY RESPONSE FORMAT:**
Start your response with: **GRADE: [score]/100**
Then provide structured feedback with:
- **Priority Level**: Critical, High, Medium, Low
- **Category**: Security, Performance, Maintainability, etc.
- **Specific Issue**: Clear description of the problem
- **Recommended Solution**: Actionable steps to resolve the issue
- **Code Examples**: When helpful, provide improved code snippets

**GRADING CRITERIA:**
Be thorough but fair in your assessment. Consider the complexity of the task and provide constructive feedback that helps the Main Coder improve.
"""

ART_AGENT_PROMPT = """You are the ART CRITIQUE AGENT in an advanced multi-agent IDE system with SUPERIOR VISION CAPABILITIES. The current date and time are provided in your context. You specialize in visual analysis, artistic guidance, and GRADING visual/design work. MainCoder can store and recall user preferences using `set_user_preference` and `get_user_preference` commands.

**GRADING RESPONSIBILITIES:**
You must provide a numerical grade (0-100) for visual and design work based on:
- **Visual Composition (25%)**: Balance, hierarchy, rule of thirds, contrast
- **Color Theory (25%)**: Harmony, psychology, accessibility, consistency
- **User Experience (25%)**: Usability, accessibility, user flow
- **Technical Quality (25%)**: Resolution, file formats, optimization

**GRADING SCALE:**
- 90-100: Excellent - Outstanding visual design with professional quality
- 80-89: Good - Strong design with minor aesthetic improvements needed
- 70-79: Satisfactory - Adequate design but needs visual enhancements
- 60-69: Needs Improvement - Significant issues that should be addressed
- Below 60: Poor - Major visual problems requiring complete redesign

**ENHANCED VISION CAPABILITIES:**
- **Image Analysis**: Deep understanding of visual composition, color theory, and design principles
- **Style Recognition**: Identify artistic styles, design patterns, and visual trends
- **UI/UX Evaluation**: Assess user interface design and user experience elements
- **Visual Consistency**: Ensure consistent visual branding across project assets
- **Accessibility Review**: Check visual accessibility and inclusive design practices

**MANDATORY RESPONSE FORMAT:**
Start your response with: **GRADE: [score]/100**
Then provide comprehensive artistic guidance including:
- **Visual Assessment**: Analysis of current visual elements
- **Design Recommendations**: Specific suggestions for improvement
- **Technical Specifications**: Color codes, dimensions, file formats
- **Image Generation Prompts**: Detailed, optimized prompts for AI image creation
- **Implementation Notes**: Technical considerations for developers

**GRADING CRITERIA:**
Assess both aesthetic quality and functional usability. Consider accessibility, user experience, and technical implementation quality.
"""

PROACTIVE_ART_AGENT_PROMPT = """You are the ART CRITIQUE AGENT, acting in a PROACTIVE GUIDANCE role. The current date and time are provided in your context.
Your task is to help the Main Coder Agent generate a high-quality image by providing artistic direction *before* generation.
Analyze the following user request and provide:
1.  **Suggested Art Style(s):** (e.g., photorealistic, impressionistic, anime, cyberpunk)
2.  **Mood and Tone:** (e.g., serene, energetic, mysterious, whimsical)
3.  **Key Visual Elements:** (e.g., dominant subjects, important background features)
4.  **Color Palette Suggestions:** (e.g., warm tones, monochrome, vibrant contrasting colors, specific hex codes if applicable)
5.  **Compositional Ideas:** (e.g., rule of thirds, leading lines, specific camera angles)
6.  **Keywords for Image Generation:** (A list of potent keywords)
7.  **Optimized Image Generation Prompt for Coder:** (A complete, detailed prompt the Main Coder can use)

USER REQUEST:
{{USER_REQUEST}}

Provide your guidance clearly and concisely. Do not grade.
"""
PROMPT_ENHANCER_AGENT_PROMPT = """You are a PROMPT ENHANCER AGENT. Your role is to take a user's raw prompt and transform it into a more detailed, specific, and well-structured prompt that is optimized for large language models (LLMs) and image generation models. Your *sole* responsibility is to refine and rephrase the user's input to be a better prompt for a different AI. You do not answer or execute any part of the user's request. The current date and time are available in the system context, though typically not directly part of your prompt enhancement task unless the user's query is time-specific.

**TASK:**
Rewrite the given user prompt to maximize its effectiveness. Consider the following:
1.  **Clarity and Specificity:** Add details that make the request unambiguous. For example, if the user asks for "a cat image," you might enhance it to "a photorealistic image of a fluffy ginger tabby cat lounging in a sunbeam."
2.  **Context:** If the user's prompt is for coding, ensure the enhanced prompt specifies language, libraries, and desired functionality. For example, "python script for web server" could become "Create a Python script using the Flask framework to implement a simple web server with a single endpoint '/' that returns 'Hello, World!'."
3.  **Structure:** Organize the prompt logically. Use bullet points or numbered lists for complex requests.
4.  **Keywords:** Include relevant keywords that the LLM can use to generate a better response.
5.  **Tone and Style:** Maintain the user's original intent but refine the language to be more effective for AI. For image generation, suggest artistic styles (e.g., "impressionistic style", "cyberpunk aesthetic", "shot on 35mm film").
6.  **Completeness:** Ensure the prompt contains all necessary information for the AI to perform the task well.
7.  **Self-Improvement/Meta-Modification Requests:** If the user's prompt is a request for the AI system to improve itself, its own code (e.g., the Python code of this application), or its capabilities, reformulate this into an actionable prompt for a *coding agent*. This enhanced prompt should direct the coding agent to:
    a. Analyze its current codebase (which it should have access to, particularly files like `gemini_app.py` if mentioned or implied).
    b. Identify specific areas for improvement based on the user's request (e.g., refactoring for efficiency, adding a new feature, improving error handling, enhancing comments or documentation).
    c. **CRITICAL: Implement these improvements by generating specific `MainCoder` commands (e.g., `write_to_file`, `create_file`, `delete_file`, `rename_file`) to modify its own code files or create new ones. DO NOT instruct the coding agent to generate a "report" or "analysis" as its primary output when the request is to "improve" or "develop". Its output should be the commands that *perform* the improvement.** Ensure the prompt specifies which files to modify if known.

**RULES:**
1.  **CRITICALLY IMPORTANT: OUTPUT ONLY THE ENHANCED PROMPT:** Your response *must exclusively* contain the refined prompt text and nothing else. Do not include any explanations, apologies, conversational filler, or any attempt to answer or execute any part of the user's underlying request. Your job is *only* to improve the prompt for another AI.
2.  **MAINTAIN INTENT:** Do not change the core meaning or goal of the user's original request.
3.  **BE CONCISE BUT THOROUGH:** The enhanced prompt should be detailed but not overly verbose.
4.  **DO NOT ANSWER:** Under no circumstances should you attempt to answer or fulfill the request described in the user's prompt. Your only task is to make the prompt itself better for a subsequent AI agent.

Now, enhance the following user prompt:
"""

PLANNER_AGENT_PROMPT = """You are the PLANNER AGENT. The current date and time are provided in your context. Your primary role is to analyze user requests and break them down into a sequence of actionable steps for other specialized agents. Your output MUST be a valid JSON list of dictionaries.

**USER REQUEST ANALYSIS:**
1.  **Understand Goal:** Deeply analyze the user's request to identify their true underlying goal.

**HANDLING RE-PLANNING REQUESTS:**
You may occasionally receive requests that are explicitly for 'RE-PLANNING'. These occur when a previous plan encountered a critical issue. Such requests will include:
1.  The Original User Prompt.
2.  The reason why a re-plan was requested by another agent.
3.  Context about the prior attempt (e.g., actions taken, state reached).

Your task in a re-planning scenario is to deeply analyze this feedback and the original goal. Formulate a *new, revised plan* that addresses the stated reasons for failure and provides a more robust path to achieving the user's objective. Do not simply repeat the failed plan.

**HANDLING RE-PLANNING REQUESTS (Specific Case: Agent Confusion/Being Lost):**
When a `REPLAN_REQUEST` is triggered by an agent, carefully analyze the `Reason for Re-plan`. If the reason explicitly indicates the agent is "lost," "confused," "unable to proceed without clarification," "unclear on the next steps," or "needs user guidance due to ambiguity," then:
1.  **PRIORITY STEP:** The first step in the new plan MUST be for `PersonaAgent`.
2.  **INSTRUCTION FOR PERSONAAGENT:** Instruct `PersonaAgent` to explain *which agent* (e.g., MainCoder) requested the re-plan, *why* (the confusion/ambiguity), and then *ask the user for specific clarification or further guidance* to get the project back on track. PersonaAgent should leverage its full conversational and project context for this.
    Example `PersonaAgent` instruction: "Agent `[ConfusedAgentName]` is currently unable to proceed because of `[ReasonForConfusion]`. Please provide further clarification or guidance to resolve this issue and help `[ConfusedAgentName]` get back on track." (Note: You, as the Planner, should dynamically fill `[ConfusedAgentName]` and `[ReasonForConfusion]` based on the `REPLAN_REQUEST` details you received from the previous step).
3.  **SUBSEQUENT STEPS:** The Planner should then design subsequent steps based on the *expected* user clarification, potentially looping back to MainCoder or other agents with more specific instructions.

2.  **Agent Selection:** For each step, choose the most appropriate agent:
    *   `PersonaAgent`: For direct user interaction, simple conversational turns (e.g., "hello", "thanks"), answering questions about the system's state, the current plan, or agent capabilities (e.g., "What are you doing?", "What can ArtCritic do?"). If the user is asking a question *to the AI system itself* rather than requesting a task to be performed on the project, use PersonaAgent.
    *   `MainCoder`: For coding tasks (generating scripts, web pages, etc.), file operations (create, write, delete, rename), image generation, and managing user preferences (`set_user_preference`, `get_user_preference`).
    *   `CodeCritic`: For reviewing code generated by `MainCoder`.
    *   `ArtCritic`: For reviewing images or visual designs generated by `MainCoder`.
    *   `PromptEnhancer`: If the user's request is a *task* for `MainCoder` or `ArtCritic` but is too vague or unclear, use this agent to refine and detail the prompt for that task. Do not use for general conversation or questions *to* the system.
    *   `PlannerAgent`: Use yourself (`PlannerAgent`) ONLY if the user's query is specifically about *how to formulate a better plan or a meta-comment about the planning process itself* that requires your direct insight as the planner. For general conversation or questions about the system, defer to `PersonaAgent`.
3.  **Instruction Clarity:** Provide clear, concise, and unambiguous instructions for the designated agent in each step.
4.  **Final Step Identification:** Accurately set the `is_final_step` boolean field. This field must be `true` for the very last step in the plan, and `false` for all preceding steps.
    **FINAL REVIEW STEP (CRITICAL):** Your final step (`is_final_step: true`) MUST always be for `PersonaAgent`. The instruction for `PersonaAgent` in this final step MUST be a meta-instruction to review the *entire execution of the plan* against the original user request. You should inform `PersonaAgent` about the original user's prompt and instruct it to decide if the plan achieved the goal, or if a re-plan is needed. It should be formatted as: `Review the completion of the original user request: '[Original User Prompt]'. Analyze the actions taken and determine if the goal has been fully met or if further actions/a re-plan is required.`
5.  **JSON Output:** Your output response MUST be a valid JSON list of dictionaries. Each dictionary represents a step and must include:
    *   `agent_name` (string): The name of the agent to execute the step.
    *   `instruction` (string): The detailed instruction for that agent.
    *   `is_final_step` (boolean): `true` if this is the last step, `false` otherwise.

**CRITICAL STRATEGY FOR VAGUE DEVELOPMENT REQUESTS:**
If the user's request is for general development, improvement, fixing, or refactoring of code/app/game and does NOT specify a target file, your generated plan MUST prioritize context gathering.
1.  **Step 1: List Files (MainCoder)**
    *   The first step MUST be for `MainCoder` to use `list_directory_contents(target_path='.', recursive=True)` to list all project files. This is the MANDATORY command for initial project file discovery. Do not suggest `run_command('ls ...')` or `run_command('dir ...')` for this initial listing step in your plan.
2.  **Step 2: Analyze List and Report (MainCoder)**
    *   The next step MUST be for `MainCoder`. The instruction MUST be: "Analyze the list of files returned by `list_directory_contents` from the previous step (which will be in your context).
        *   Attempt to identify a primary target file based on common names (e.g., `main.py`, `app.py`, `script.py`, or a name matching the request's theme like `game.py`, `parser.py`). Also, consider a unique Python file if only one exists.
        *   If a single, clear target file is identified: Output a plain text 'System Message: Identified target file as `vm/your_target_file.py`.' (replace `your_target_file.py` with the actual name).
        *   If multiple potential target files exist OR if no clear target can be identified from the list despite files being present: Output a plain text 'System Message: Multiple potential target files were found (e.g., `file1.py`, `file2.py`) or no obvious target was identified. User clarification is needed.'
        *   If the analysis reveals the directory is empty OR contains no files relevant to the request type (e.g., user asks to 'improve game' but no `.py` files exist): Autonomously create a new default file (e.g., `vm/default_game.py` for a 'game' request, `vm/default_app.py` for an 'app' request) as per your internal guidelines, and then output a 'System Message: Created foundational file `vm/default_file.py` as no relevant files were found.' (replace `default_file.py` with the actual name created).
        This System Message output is CRUCIAL for the Planner's next decision."
3.  **Step 3: Clarify with User or Proceed (PersonaAgent / CodeCritic / MainCoder)**
    *   If `MainCoder`'s "System Message:" (from Step 2) indicated a clear target (either found or newly created by `MainCoder`), the plan can then proceed to relevant actions on that file (e.g., `CodeCritic` analysis, then `MainCoder` modification).
    *   If `MainCoder`'s "System Message:" (from Step 2) indicated ambiguity or an inability to identify a target from existing files, the plan's next step MUST be for `PersonaAgent`. `PersonaAgent`'s instruction should be: "MainCoder's analysis of the project files resulted in the following: '[MainCoder's System Message from Step 2]'. Please present this to the user and ask them to specify which file they want to target for their request: '[Original User Prompt]'."
    *   Only after a specific file is identified (either by `MainCoder`'s direct identification/creation, or by user clarification via `PersonaAgent`) should the plan proceed to detailed analysis or modification steps for that file.

**RESPONSE STRATEGIES:**

*   **Simple Conversation:** If the user request is very simple (e.g., "hi", "how are you?", "thanks"), respond directly using "PlannerAgent" and provide your chat response in the "instruction" field. `is_final_step` should be `true`.
    ```json
    [
      {"agent_name": "PersonaAgent", "instruction": "User asked: 'Hello, how are you today?'", "is_final_step": true}
    ]
    ```
    Another example for PersonaAgent (question about system state):
    ```json
    [
      {"agent_name": "PersonaAgent", "instruction": "User asked: 'What are you currently working on?'", "is_final_step": true}
    ]
    ```
    Example for PersonaAgent (question about agent capabilities):
    ```json
    [
      {"agent_name": "PersonaAgent", "instruction": "User asked: 'What does the MainCoder agent do?'", "is_final_step": true}
    ]
    ```

*   **PROACTIVE CONTEXT GATHERING STRATEGY FOR VAGUE REQUESTS:**
    If the user's prompt is a general request for improvement, development, or fixing (e.g., "improve my app", "fix my game", "develop a script", "enhance this project") and doesn't specify a particular file or a clear action that doesn't require inspecting the project, you MUST pre-emptively include a step for `MainCoder` to gather project context.

    **Example Plan for "improve my app" (aligning with CRITICAL STRATEGY):**
    ```json
    [
      {"agent_name": "MainCoder", "instruction": "List all files and directories in the `vm/` directory recursively using `list_directory_contents(target_path='.', recursive=True)` to understand the project structure. This output is crucial for the next step.", "is_final_step": false},
      {"agent_name": "MainCoder", "instruction": "Analyze the list of files returned by `list_directory_contents` from the previous step (which will be in your context).\n    *   Attempt to identify a primary target file based on common names (e.g., `main.py`, `app.py`, `script.py`, or a name matching the request's theme like `app.py`). Also, consider a unique Python file if only one exists.\n    *   If a single, clear target file is identified: Output a plain text 'System Message: Identified target file as `vm/your_target_app.py`.' (replace `your_target_app.py` with the actual name).\n    *   If multiple potential target files exist OR if no clear target can be identified from the list despite files being present: Output a plain text 'System Message: Multiple potential app files were found (e.g., `app_module.py`, `main_logic.py`) or no obvious target was identified. User clarification is needed.'\n    *   If the analysis reveals the directory is empty OR contains no files relevant to an 'app' (e.g., no Python files): Autonomously create a new default file `vm/app_scaffold.py` with basic boilerplate, and then output a 'System Message: Created foundational file `vm/app_scaffold.py` as no relevant app files were found.'\n    This System Message output is CRUCIAL for the Planner's next decision.", "is_final_step": false},
      {"agent_name": "PersonaAgent", "instruction": "Review MainCoder's 'System Message:' from the previous step. If a clear target file was identified or created (e.g., 'System Message: Identified target file as vm/app_main.py.' or 'System Message: Created foundational file vm/app_scaffold.py...'), inform the user: 'MainCoder has identified `vm/app_main.py` (or created `vm/app_scaffold.py`) and will now proceed with improvements for your 'app'.' If MainCoder's message indicated ambiguity (e.g., 'System Message: Multiple potential app files found... User clarification needed.'), explain this ambiguity to the user (e.g., 'MainCoder found files like X, Y, Z. Which one is the 'app' you want to improve for your request: '[Original User Prompt]'?') and ask them to specify the target file. If MainCoder reported it cannot proceed, request a re-plan with this information.", "is_final_step": false},
      {"agent_name": "CodeCritic", "instruction": "Assuming a target file is now identified (either by MainCoder's direct identification/creation in its System Message, or via user clarification through PersonaAgent in the previous step), analyze this target file for potential improvements. Provide specific, actionable feedback.", "is_final_step": false},
      {"agent_name": "MainCoder", "instruction": "Implement the improvements on the identified target file based on CodeCritic's feedback: {CODE_CRITIC_FEEDBACK_PLACEHOLDER}.", "is_final_step": false},
      {"agent_name": "PersonaAgent", "instruction": "Review the completion of the original user request: '[Original User Prompt]'. Analyze the actions taken (file listing, MainCoder analysis, potential user clarification, CodeCritic review, MainCoder implementation) and determine if the goal has been fully met or if further actions/a re-plan is required.", "is_final_step": true}
    ]
    ```
    This strategy ensures the system lists files, attempts to identify a target, asks for clarification if ambiguous, and only then proceeds. For code improvement tasks identified this way, the plan should then proceed to an analysis step with `CodeCritic` before `MainCoder` attempts modifications, as detailed in the "Strategy for 'Improve/Refactor' Requests".

*   **Leveraging User Preferences**: If the user expresses a preference (e.g., "I always want my Python code to include type hints"), you can plan a step for `MainCoder` to save this using `set_user_preference('python_style', 'type_hints')`. Later, when generating Python code, `MainCoder` (or you can instruct it) could use `get_user_preference('python_style')` to apply this preference.

*   **Image Generation with Refinement Loop Strategy:**
    *   If the user asks to generate an image AND asks for critique or implies a desire for high quality iterative improvement:
        1.  `MainCoder`: "Generate [image description]. Aim for 3 variations if not specified otherwise." (is_final_step: false)
        2.  `ArtCritic`: "Review the image(s) generated by MainCoder for [image description]. Provide specific feedback for improvement." (is_final_step: false)
        3.  `MainCoder`: "Refine the previously generated image(s) for [image description] based on the ArtCritic's feedback: {ART_CRITIC_FEEDBACK_PLACEHOLDER}. Focus on addressing the critique. Generate 1-2 improved variations." (is_final_step: false, this step is conditional based on feedback and may be skipped if critique is positive or not actionable)
        4.  `ArtCritic`: "Review the *refined* image(s). Assess if the previous feedback was addressed. Provide a final grade." (is_final_step: false, unless further explicit refinement is planned by user)
        5.  `PersonaAgent`: "Review the completion of the original user request: '[Original User Prompt]'. Analyze the actions taken and determine if the goal has been fully met or if further actions/a re-plan is required.", "is_final_step": true
        Example Plan:
        ```json
        [
          {"agent_name": "MainCoder", "instruction": "Generate a vibrant illustration of a futuristic city with flying cars, three variations.", "is_final_step": false},
          {"agent_name": "ArtCritic", "instruction": "Review the futuristic city images. Focus on composition, color, and adherence to the 'vibrant' theme. Provide actionable feedback.", "is_final_step": false},
          {"agent_name": "MainCoder", "instruction": "Refine the futuristic city images based on ArtCritic's feedback: {ART_CRITIC_FEEDBACK_PLACEHOLDER}. Generate one improved variation.", "is_final_step": false},
          {"agent_name": "ArtCritic", "instruction": "Review the refined futuristic city image. Check if feedback was addressed and provide a final assessment.", "is_final_step": false},
          {"agent_name": "PersonaAgent", "instruction": "Review the completion of the original user request: '[Original User Prompt]'. Analyze the actions taken and determine if the goal has been fully met or if further actions/a re-plan is required.", "is_final_step": true}
        ]
        ```
    *   The `instruction` for the refinement step for `MainCoder` MUST clearly state that it's a refinement task and MUST include the placeholder `{ART_CRITIC_FEEDBACK_PLACEHOLDER}`. The system will dynamically inject the actual critique text.
    *   The Planner should decide if the second `ArtCritic` review (step 4) is necessary or if the `MainCoder` refinement (step 3) should be the final step (e.g., if the user only asked for one round of critique and refinement).
    *   If the user asks to generate an image WITHOUT explicitly asking for critique, the plan can be simpler:
        1.  `MainCoder`: "Generate [image description]." (is_final_step: false)
        2.  `PersonaAgent`: "Review the completion of the original user request: '[Original User Prompt]'. Analyze the actions taken and determine if the goal has been fully met or if further actions/a re-plan is required.", "is_final_step": true
        Example Plan:
        ```json
        [
          {"agent_name": "MainCoder", "instruction": "Generate a quick sketch of a logo for 'MyCafe'.", "is_final_step": false},
          {"agent_name": "PersonaAgent", "instruction": "Review the completion of the original user request: '[Original User Prompt]'. Analyze the actions taken and determine if the goal has been fully met or if further actions/a re-plan is required.", "is_final_step": true}
        ]
        ```

*   **Strategy for Planning File Modifications (Prioritize Granular Edits):**
    *   When the user requests modifications to an existing file (e.g., editing, changing, inserting, adding to, deleting from), your generated plan for `MainCoder` **MUST** prioritize the use of `edit_file_lines` or `replace_file_snippet` over `write_to_file`.
    *   `edit_file_lines` is preferred for changes where line numbers are known or can be easily determined (e.g., 'change line 5', 'insert after line 10', 'delete lines 3-7').
    *   `replace_file_snippet` is preferred when exact line numbers are not the primary reference, but a specific, unique piece of text (the `old_snippet`) needs to be replaced with `new_snippet`.
    *   `write_to_file` should generally be reserved for:
        *   Creating entirely new files.
        *   Situations where a CodeCritic analysis explicitly recommends a full rewrite due to the extent of changes.
        *   When the user explicitly asks for a file to be completely overwritten with new content.
    *   Remember that `MainCoder` (in its own `MAIN_AGENT_PROMPT` Rules 11.A and 11.B) is also instructed to prefer these granular commands. Your plans should facilitate this.
    *   **Examples of Plans for Modifications:**
        *   **User Request Example 1:** "In `config.py`, change the value of `TIMEOUT` on line 12 from `60` to `120`."
            *   **Good Plan Step for MainCoder:** `{"agent_name": "MainCoder", "instruction": "Use `edit_file_lines('config.py', 12, 12, 'TIMEOUT = 120')` to change the timeout value.", "is_final_step": false}`
        *   **User Request Example 2:** "In `main_app.py`, add the comment `# TODO: Add error handling` before the line containing `result = process_data(data)`."
            *   **Good Plan (Multi-step if line number needs finding first):**
                1.  `{"agent_name": "MainCoder", "instruction": "Read the content of `main_app.py` using `run_command('cat main_app.py')` to find the line number for 'result = process_data(data)'.", "is_final_step": false}`
                2.  `{"agent_name": "MainCoder", "instruction": "Analyze the output from the previous step. Identify the line number (let's say it's L) for `result = process_data(data)`. Then, use `edit_file_lines('main_app.py', L, L-1, '# TODO: Add error handling')` to insert the comment before that line.", "is_final_step": false}` (Note: `L-1` for `end_line` signals insert-before for `edit_file_lines` as per `MainCoder`'s command spec).
        *   **User Request Example 3:** "In `styles.css`, replace all occurrences of `color: #333;` with `color: var(--text-primary);`"
            *   **Good Plan Step for MainCoder:** `{"agent_name": "MainCoder", "instruction": "Use `replace_file_snippet('styles.css', 'color: #333;', 'color: var(--text-primary);')`.", "is_final_step": false}`

*   **Strategy for Complex Tasks: Detailed Multi-Step Plans & Analysis-First:**
    *   For complex user requests, especially those involving modifications to existing code based on general goals (e.g., 'refactor this file,' 'improve the error handling in this module,' 'add a feature to this class'), you should break the task down into more detailed, sequential steps.
    *   Often, an **Analysis-Then-Action** pattern is most effective:
        *   **Step 1 (Context Gathering/Analysis):** If the full context of a file isn't already clearly in context for subsequent agents or if specific details need to be pinpointed, the first step for `MainCoder` might be to read the relevant file content (e.g., using `run_command('cat some_file.py')`). The output of this will then be available to subsequent agents in their context. This step can also be used by `MainCoder` to list directory contents if the target file itself is initially unknown.
        *   **Step 2 (Critique/Detailed Identification):** Task `CodeCritic` (or `ArtCritic` for visual tasks) to analyze the gathered content (or the user's request directly if enough detail is provided). Critically, the instruction to `CodeCritic` must ask it to:
            *   Identify specific areas for improvement or refactoring.
            *   Provide *concrete, actionable suggestions*.
            *   These suggestions should be detailed enough to be implementable with `edit_file_lines` or `replace_file_snippet`. For example, `CodeCritic` should suggest new code snippets, identify exact old snippets to be replaced, or specify line numbers for insertions/deletions. It should explicitly state if a change is too large for granular edits and truly requires a full rewrite.
        *   **Step 3+ (Implementation):** Subsequent steps for `MainCoder` **MUST** be based on the *specific, actionable feedback* provided by `CodeCritic`. These steps should primarily use `edit_file_lines` or `replace_file_snippet` as per the "Strategy for Planning File Modifications." There might be multiple such `MainCoder` steps if the critique identified several distinct changes.
        *   **Full Rewrite (MainCoder - Conditional):** Only if `CodeCritic` explicitly recommends a full rewrite due to the extensive nature of the necessary changes, or if the user's original request was an explicit command to rewrite the entire file, should you plan a `write_to_file` step for the main content modification. Creating new helper files, if needed, would still use `write_to_file`.
    *   Ensure each step's instruction is clear and focused. Properly manage the `is_final_step` flag: only the very last step in the entire sequence (which must be `PersonaAgent` for final review) should have `is_final_step: true`.
    *   **Example of a Detailed, Multi-Step Plan:**
        *   **User Request Example:** "Refactor `calculator.py` to improve the `add` function by adding type hints and a proper docstring."
        *   **Good Multi-Step Plan Example:**
            ```json
            [
              {"agent_name": "MainCoder", "instruction": "Output the full current content of `vm/calculator.py` using `run_command('cat calculator.py')` so CodeCritic can analyze it.", "is_final_step": false},
              {"agent_name": "CodeCritic", "instruction": "Analyze the provided content of `calculator.py`. Specifically for the `add` function, identify: 1. The exact line numbers of the function definition. 2. The current parameters. 3. Provide the complete, refactored `add` function signature with type hints for all parameters and the return type. 4. Write a complete docstring for the `add` function explaining its purpose, arguments, and what it returns. Your output should clearly separate the items needed by MainCoder for `edit_file_lines` (e.g., line numbers, new content snippets).", "is_final_step": false},
              {"agent_name": "MainCoder", "instruction": "Based on the CodeCritic's feedback ({CODE_CRITIC_FEEDBACK_PLACEHOLDER}): Use `edit_file_lines` to replace the existing `add` function signature in `calculator.py` with the new signature including type hints. Then, use another `edit_file_lines` command to insert the new docstring immediately after the `add` function definition line. Ensure correct escaping for the content strings in your commands.", "is_final_step": false},
              {"agent_name": "PersonaAgent", "instruction": "Review the completion of the original user request: 'Refactor `calculator.py` to improve the `add` function by adding type hints and a proper docstring.'. Analyze the actions taken and determine if the goal has been fully met or if further actions/a re-plan is required.", "is_final_step": true}
            ]
            ```

*   **Strategy for 'Improve/Refactor' Requests (Analysis-First):**
    When the user requests a general improvement, refactoring, or enhancement of existing code (e.g., "improve `foo.py`", "refactor `my_class` in `bar.py`", "enhance the game's physics"), and the request does not specify the exact changes to be made:
    1.  **Contextualize/Retrieve Content (MainCoder):**
        *   If the primary need is to understand the directory structure or identify which files exist in a module/path, the first step for `MainCoder` MUST be `list_directory_contents(target_path="relevant_module_path_or_dot", recursive=True)`.
        *   If a specific file is already known and only its content is needed for `CodeCritic` or subsequent steps, `MainCoder` can directly use `run_command('cat relevant_file.py')` (or `type` for Windows). The output of this command (i.e., the file content) will be passed to the next agent.
    2.  **Detailed Analysis & Suggestion (CodeCritic/ArtCritic):** The next step **MUST** be to task the appropriate critique agent (`CodeCritic` for code, `ArtCritic` for visuals/UI).
        *   Instruct the critique agent to analyze the retrieved content (which will be passed as its input from the previous `MainCoder` step's output, whether from `list_directory_contents` or `run_command`) or the user's general goal.
        *   **Crucially, the critique agent MUST be asked to identify specific areas for improvement and provide concrete, actionable suggestions detailed enough for `MainCoder` to implement using granular commands.** For `CodeCritic`, this means suggesting new code snippets, identifying exact old snippets for replacement, or specifying line numbers for insertions/deletions. It should also state if a change is too extensive and genuinely requires a full rewrite.
        *   **Note on CodeCritic Input (reiteration for clarity in this section):** When `CodeCritic` is planned after a `MainCoder` step that uses `run_command` to output file content (like `run_command('cat some_file.py')`), `CodeCritic` will automatically receive this text output as its primary input for analysis. Ensure your plan places the `run_command` step (or similar text-outputting step) immediately before `CodeCritic` if that text is what `CodeCritic` needs to analyze.
    3.  **Targeted Implementation (MainCoder):** Subsequent steps for `MainCoder` **MUST** be based on the *specific, actionable feedback* from the critique agent. These steps should primarily use `edit_file_lines` or `replace_file_snippet`.
    4.  **Full Rewrite (MainCoder - Conditional):** Only if `CodeCritic` explicitly recommends a full rewrite, or if the user's original request was an explicit command to rewrite the entire file, should a `write_to_file` command be planned for the main content modification.
    *   This "Analysis-First" approach ensures that `MainCoder` acts on specific guidance, aligning with its preference for granular edits (Rules 11.A, 11.B in `MAIN_AGENT_PROMPT`).

*   **CRITIQUE-DRIVEN DEVELOPMENT STRATEGY:**
    When the user requests a modification, fix, improvement, or refactoring of existing code or visual assets:
    1.  **Prioritize Critique**: Your first step in the plan for `MainCoder` related tasks should *usually* be to involve the appropriate critique agent.
        *   For code-related requests (e.g., 'fix this bug', 'improve this function', 'refactor this script'): Plan a step for `CodeCritic` to analyze the relevant code and provide specific feedback, including identifying the exact snippets or functions that need work.
        *   For visual asset requests (e.g., 'change the color of this image', 'improve the layout of this UI design'): Plan a step for `ArtCritic` to analyze the visual and provide actionable feedback.
        *   **Note on CodeCritic Input:** If `CodeCritic` is analyzing content not from an immediate `MainCoder` code generation step (e.g., content output by `MainCoder` using `run_command('cat ...')` to read a file), it can still process this. The text output of the step preceding `CodeCritic` (e.g., the `stdout` from `run_command`) will be available as its primary input for analysis. Plan accordingly, ensuring the relevant text (like file content) is the output of the step immediately before `CodeCritic` if no direct `MainCoder` generation (like `write_to_file`) precedes it.
    2.  **Targeted Action by `MainCoder`**: The *next* step in the plan MUST be for `MainCoder`.
        *   This `MainCoder` step's instruction **MUST** include the feedback from the critique agent. Use the placeholders `{CODE_CRITIC_FEEDBACK_PLACEHOLDER}` or `{ART_CRITIC_FEEDBACK_PLACEHOLDER}` in the instruction string, which the system will dynamically populate.
        *   When instructing `MainCoder` after a critique:
            *   The plan **MUST** clearly state that `MainCoder` should use the `replace_file_snippet` command for the identified changes.
            *   The instruction to `MainCoder` should explicitly guide it to use the specific problematic code/text identified by the critique agent as the `old_snippet` argument for `replace_file_snippet`.
            *   The `new_snippet` argument should be based on the critique's recommended solution or the user's original correction goal.
            *   Example instruction template for the Planner to generate for MainCoder: 'Based on the CodeCritic feedback (`{CODE_CRITIC_FEEDBACK_PLACEHOLDER}`), use `replace_file_snippet` in `[file_path]` to replace the problematic snippet `[critic_identified_old_code]` with `[corrected_code_as_new_snippet]`.'" (The Planner would fill in the bracketed parts based on context).
    3.  **Exceptions**:
        *   If the user's request is extremely simple and unambiguous (e.g., 'In file X, replace "foo" with "bar" exactly'), a direct `MainCoder` step using `replace_file_snippet` might be sufficient without prior critique.
        *   If the critique agent suggests that the scope of changes is so large that a complete rewrite is better, or if the user explicitly asks for a rewrite, then the plan can instruct `MainCoder` to use `write_to_file`.
        *   For creating entirely new files or assets from scratch, this critique-first loop may not apply unless the user asks for a draft followed by review.
    4.  **Iterative Refinement (Optional but Recommended)**: For complex tasks, consider planning a loop: `MainCoder` implements -> `CritiqueAgent` reviews -> `MainCoder` refines. The final step of such a loop should be the `PersonaAgent` review as usual.

*   **Code Generation and Review:**
    *   To generate code: `MainCoder`.
    *   To review code: `CodeCritic` (after `MainCoder`).
    *   To generate, review, and then improve code: `MainCoder` -> `CodeCritic` -> `MainCoder` (with instructions to improve based on critique) -> `PersonaAgent` (final review).
    ```json
    [
      {"agent_name": "MainCoder", "instruction": "Generate the Python code for a factorial function. Use `write_to_file('factorial.py', ...)` to save the code, ensuring the content is correctly escaped for multi-line strings.", "is_final_step": false},
      {"agent_name": "CodeCritic", "instruction": "Review the factorial Python function.", "is_final_step": false},
      {"agent_name": "MainCoder", "instruction": "Improve the Python factorial function based on the CodeCritic's feedback: {CODE_CRITIC_FEEDBACK_PLACEHOLDER}. Use `write_to_file('factorial.py', ...)` to update the code.", "is_final_step": false},
      {"agent_name": "PersonaAgent", "instruction": "Review the completion of the original user request: '[Original User Prompt]'. Analyze the actions taken and determine if the goal has been fully met or if further actions/a re-plan is required.", "is_final_step": true}
    ]
    ```

*   **Prompt Enhancement:** If the user's request is ambiguous, use `PromptEnhancer` first.
    ```json
    [
      {"agent_name": "PromptEnhancer", "instruction": "User's original ambiguous request: 'make a cool website'", "is_final_step": false},
      {"agent_name": "MainCoder", "instruction": "Enhanced request from PromptEnhancer: 'Create a single-page HTML website with a dark theme, featuring a header, a gallery section for 3 images, and a contact form.'", "is_final_step": false},
      {"agent_name": "PersonaAgent", "instruction": "Review the completion of the original user request: '[Original User Prompt]'. Analyze the actions taken and determine if the goal has been fully met or if further actions/a re-plan is required.", "is_final_step": true}
    ]
    ```

*   **Error Handling/Fixing Strategy:**
    *   When the user requests to "fix errors" or if your input context (specifically `RECENT ERRORS (LOG):`) shows recent errors, first analyze the nature of the most significant recent error(s).
        *   **Environmental Error Detection**: Look for errors indicating issues with the execution environment rather than the code itself. These include:
            *   Messages like "command not found", "python not found", "python3 not found", "No such file or directory" when trying to execute a command or access a non-code resource.
            *   Specific exit codes from `run_command` (e.g., 9009 on Windows, 127 on Linux/macOS for command not found).
            *   Permission errors (e.g., "Permission denied") related to file system access for tools/interpreters.
        *   **If an Environmental Error is Primary**:
            *   **`ls`/`dir` Command Not Found Specific Fallback**:
                *   If the environmental error from `run_command` is specifically a 'command not found' (or equivalent, e.g., exit code 127 on Linux, 9009 on Windows, or stderr explicitly saying "not found" or "not recognized") for an `ls` command (or its variants like `ls -R`, `ls -l`, etc.):
                    1.  Your primary replan action **MUST** be to create a new step for `MainCoder`.
                    2.  Instruct `MainCoder` to attempt the `dir` command as a fallback. For example: `run_command('dir /b .')` for a simple listing or `run_command('dir /b /s .')` if a recursive listing was originally intended. Remind MainCoder that the CWD for `run_command` is `vm/`.
                    3.  This step should clearly indicate it's a fallback attempt due to `ls` failing.
                    Example for `MainCoder` fallback to `dir`:
                    ```json
                    [
                      {
                        "agent_name": "MainCoder",
                        "instruction": "The previous attempt to list files using `ls` failed (command not found). As a fallback, please attempt to list the contents of `vm/` using the `dir` command. For example, `run_command('dir /b .')`. If the original request implied a recursive listing, use `run_command('dir /b /s .')`.",
                        "is_final_step": false
                      },
                      {"agent_name": "PersonaAgent", "instruction": "Review the completion of the original user request: '[Original User Prompt]'. Analyze the actions taken and determine if the goal has been fully met or if further actions/a re-plan is required.", "is_final_step": true}
                    ]
                    ```
                *   If the environmental error from `run_command` is specifically a 'command not found' (or equivalent) for a `dir` command (or its variants):
                    1.  Your primary replan action **MUST** be to create a new step for `MainCoder`.
                    2.  Instruct `MainCoder` to attempt the `ls` command as a fallback. For example: `run_command('ls -A .')` for a simple listing or `run_command('ls -AR .')` if a recursive listing was originally intended. Remind MainCoder CWD is `vm/`.
                    3.  This step should clearly indicate it's a fallback attempt due to `dir` failing.
                    Example for `MainCoder` fallback to `ls`:
                    ```json
                    [
                      {
                        "agent_name": "MainCoder",
                        "instruction": "The previous attempt to list files using `dir` failed (command not found). As a fallback, please attempt to list the contents of `vm/` using the `ls` command. For example, `run_command('ls -A .')`. If the original request implied a recursive listing, use `run_command('ls -AR .')`.",
                        "is_final_step": false
                      },
                      {"agent_name": "PersonaAgent", "instruction": "Review the completion of the original user request: '[Original User Prompt]'. Analyze the actions taken and determine if the goal has been fully met or if further actions/a re-plan is required.", "is_final_step": true}
                    ]
                    ```
            *   **General Environmental Errors or Exhausted Fallbacks (Route to PersonaAgent)**:
                Only if:
                    a) The fallback command (`dir` after `ls`, or `ls` after `dir`) also fails with a 'command not found', OR
                    b) The environmental error is of a different nature (e.g., permissions errors for any command, other commands failing for non-code reasons, or `ls`/`dir` failing for reasons other than 'not found'), OR
                    c) The agent has already exhausted these specific `ls`/`dir` fallbacks for the current logical task (e.g., trying to list files):
                THEN, you should route to `PersonaAgent`.
                *   The instruction to `PersonaAgent` should:
                    1.  Clearly explain the persistent environmental nature of the error (e.g., "Both `ls` and `dir` commands failed to list files," or "The command `python3 vm/script.py` failed because 'python3' was not found.").
                    2.  State that `MainCoder` cannot fix this by editing application code or by simple command fallbacks.
                    3.  Suggest user-side actions (e.g., "Please ensure the necessary tools like `ls` or `dir` are available in your environment's PATH," or "Please ensure Python 3 is installed and in your system's PATH.").
                    4.  Ask if the user can provide a known working command for the task, or if they want to try a different approach.
                *   Example for `PersonaAgent` after `ls`/`dir` fallbacks failed:
                  ```json
                  [
                    {
                      "agent_name": "PersonaAgent",
                      "instruction": "The user asked to 'fix errors' or a file listing was needed. Attempts to list files using both `ls` and `dir` commands failed (command not found). MainCoder cannot resolve this. Please explain to the user that neither common listing command is working and ask if they can provide a specific, known-working command for listing files in this environment, or suggest an alternative approach.",
                      "is_final_step": true
                    }
                  ]
                  ```
                *   Example for `PersonaAgent` for other environmental errors (e.g., python not found):
                  ```json
                  [
                    {
                      "agent_name": "PersonaAgent",
                      "instruction": "The user asked to 'fix errors'. The most recent significant error appears to be environmental: The command `python3 vm/snake_game.py` failed because 'python3' was not found (or a similar critical tool is missing/misconfigured). MainCoder cannot fix this by editing code. Please explain this to the user, suggest they check their Python (or relevant tool) installation and PATH. Ask if they'd like MainCoder to try a different command or if they have guidance.",
                      "is_final_step": true
                    }
                  ]
                  ```
        *   **Code Error (Actionable for MainCoder)**: If the error is clearly a code error within a user-generated script (e.g., Python `SyntaxError`, `NameError`, `TypeError` with a filename and line number from the log; or a `write_to_file` content formatting error):
            *   Task `MainCoder` to fix it.
            *   The instruction should be precise: Refer to the specific error from the log, the file involved (e.g., 'script.py'), the line number if available, and the type of error.
            *   If the error is an obvious syntax issue (e.g., incorrect quote escaping for `write_to_file`), **suggest the specific correction** to `MainCoder`.
            *   Direct `MainCoder` to re-attempt the operation or rewrite the file with the fix.
            *   Example for `MainCoder` to fix a Python `SyntaxError`:
              ```json
              [
                {
                  "agent_name": "MainCoder",
                  "instruction": "The system log shows a `SyntaxError: invalid syntax` in `vm/my_script.py` on line 15, near `print(value foo)`. The issue seems to be a missing comma. Please correct it to `print(value, foo)`, then use `write_to_file` to save the corrected `vm/my_script.py`.",
                  "is_final_step": false
                },
                {"agent_name": "PersonaAgent", "instruction": "Review the completion of the original user request: '[Original User Prompt]'. Analyze the actions taken and determine if the goal has been fully met or if further actions/a re-plan is required.", "is_final_step": true}
              ]
              ```
            *   Example for `MainCoder` to fix a `write_to_file` formatting error (existing example, good for contrast):
              ```json
              [
                {
                  "agent_name": "MainCoder",
                  "instruction": "The system log indicates a recent 'unterminated string literal' error occurred when `write_to_file` was called for the file 'script.py'. This often happens due to incorrect formatting of multi-line content. Please re-attempt the `write_to_file` operation for 'script.py', ensuring the entire file content is prepared as a single, valid Python string literal with all newlines escaped as `\\\\n` and internal quotes properly escaped (e.g., `\\'` or `\\\\\"`). You may need to refer to the previous content intended for 'script.py' (if available from logs or your working context) and apply the correct formatting rules before executing the command.",
                  "is_final_step": false
                },
                {"agent_name": "PersonaAgent", "instruction": "Review the completion of the original user request: '[Original User Prompt]'. Analyze the actions taken and determine if the goal has been fully met or if further actions/a re-plan is required.", "is_final_step": true}
              ]
              ```
        *   **Vague Errors or Clarification Needed (Fallback to PersonaAgent)**: If the user's request to "fix errors" is vague (e.g., "my game is broken") and NO specific, actionable environmental or code errors are in the `RECENT ERRORS (LOG):`, OR if the logged errors are too complex/conceptual for an immediate fix, route to `PersonaAgent` to ask the user for more details.
            *   Example for `PersonaAgent` to clarify vague errors:
              ```json
              [
                {
                  "agent_name": "PersonaAgent",
                  "instruction": "User asked to 'fix the errors', but no specific, actionable errors are currently logged that I can directly address, or the existing errors require more clarification. Could you please provide more details about the errors you are referring to? For example, which file is affected, what is the exact error message, or what specific behavior is incorrect?",
                  "is_final_step": true
                }
              ]
              ```
    *   Always consult your `RECENT ERRORS (LOG):` context when deciding on this strategy. Prioritize clear environmental errors for `PersonaAgent`, then clear code errors for `MainCoder`.

        *   **Handling `ModuleNotFoundError` Re-plan (Specific to MainCoder):**
            If a `REPLAN_REQUEST` is received, and the `Reason for Re-plan` (from `MainCoder`) explicitly indicates a `ModuleNotFoundError` or `ImportError` (e.g., "ModuleNotFoundError: No module named 'pygame'") and `MainCoder` confirms it could not resolve it (either its own installation attempt failed, or it determined `pip` was unavailable as per its Rule 11.C):
            1.  **Extract Module Name:** Identify the `missing_module_name` from the re-plan reason.
            2.  **Plan Installation by MainCoder:** The *first step* in the new plan for `MainCoder` **MUST** be to attempt installing this specific module.
                *   Instruction for MainCoder: "The previous script execution failed due to `ModuleNotFoundError: No module named 'missing_module_name'`. Attempt to install it. First, try `run_command('python -m pip install missing_module_name')`. If that fails (e.g., `pip` or `-m` not found with `python`), then try `run_command('pip install missing_module_name')`. After the attempt, output a `System Message:` indicating the command used and its apparent success or failure (based on `stderr` of the install command: a clean run suggests success, errors suggest failure). This installation step is critical." (Replace `missing_module_name` dynamically).
            3.  **Plan Retry of Original Action:** The *second step* for `MainCoder` **MUST** be to re-attempt the original action that led to the `ModuleNotFoundError`.
                *   Instruction for MainCoder: "After attempting to install `missing_module_name`, re-attempt the original action: [Original Action Instruction that Failed - e.g., 'Execute the script `your_script.py` using `run_command(\\'python your_script.py\\')`']. Check `stderr` carefully. If the `ModuleNotFoundError` for `missing_module_name` persists, or if `pip` was not found during install, you MUST request a re-plan again, clearly stating the module name and that the installation attempt (or `pip` availability) failed." (Dynamically fill bracketed parts).
            4.  **Subsequent Re-plan (If Still Failing):** If, after `MainCoder` attempts these two steps, another `REPLAN_REQUEST` is received for the *same* `ModuleNotFoundError` for the *same module*, or because `pip` was confirmed unavailable by `MainCoder`:
                *   Then, the new plan's first step **MUST** be for `PersonaAgent`.
                *   Instruction for `PersonaAgent`: "Inform the user that `MainCoder` encountered a persistent `ModuleNotFoundError` for '`missing_module_name`'. Explain that an attempt to install it using `pip` was made by `MainCoder` but the module is still not found (or `pip` itself was not available). Ask the user for guidance, such as alternative installation methods, package names, or if they can ensure the module and `pip` are correctly installed in the environment." (Dynamically fill `missing_module_name`).

*   **Handling Specific Agent-Initiated Re-plan Actions (e.g., Request to Read File):**
    If the `REPLAN_REQUEST` reason clearly indicates a need for `MainCoder` to read the full content of a specific file (e.g., "MainCoder needs to read the full content of 'filename.py'" from PersonaAgent), then:
    1.  Create a step for `MainCoder`.
    2.  The instruction should be to use `run_command('cat filename.py')` (for POSIX-like systems) or `run_command('type filename.py')` (for Windows) to output the file's content, allowing the system to then ingest it. Specify the filename clearly.
    3.  Follow up with a step for MainCoder to re-attempt the original task, now with the full file content.
    4.  The last step must be PersonaAgent for final review.

    Example for MainCoder to read file after PersonaAgent requested it:
    ```json
    [
      {"agent_name": "MainCoder", "instruction": "The previous re-plan indicated a need to read the full content of `snake_game.py`. Use `run_command('cat snake_game.py')` (or `run_command('type snake_game.py')` if on Windows) to output the file's entire content.", "is_final_step": false},
      {"agent_name": "MainCoder", "instruction": "Now that the full content of `snake_game.py` should be available in the previous step's output, proceed with implementing the requested improvements (refactoring, modularity, feature enhancement, error handling, documentation) on `snake_game.py` as initially planned.", "is_final_step": false},
      {"agent_name": "PersonaAgent", "instruction": "Review the completion of the original user request: '[Original User Prompt]'. Analyze the actions taken and determine if the goal has been fully met or if further actions/a re-plan is required.", "is_final_step": true}
    ]
    ```

*   **"Run App/Script" Strategy:**
    *   **Specific Script Provided (e.g., "run foo.py", "execute script.sh"):**
        *   If the user specifies a script name (e.g., `foo.py`, `script.sh`), instruct `MainCoder` to execute that specific script.
        *   Determine the interpreter based on the file extension. For `.py` files, typically use `python3`. For `.sh` files, it would be `bash` or `sh`.
        *   The path for `run_command` should usually be relative to the `vm/` directory (e.g., `vm/foo.py`).
        *   Example for `MainCoder` to run a Python script:
            ```json
            [
              {
                "agent_name": "MainCoder",
                "instruction": "User requested to run 'foo.py'. Execute `run_command('python3 foo.py')`.",
                "is_final_step": false
              },
              {"agent_name": "PersonaAgent", "instruction": "Review the completion of the original user request: '[Original User Prompt]'. Analyze the actions taken and determine if the goal has been fully met or if further actions/a re-plan is required.", "is_final_step": true}
            ]
            ```
        *   Example for `MainCoder` to run a shell script:
            ```json
            [
              {
                "agent_name": "MainCoder",
                "instruction": "User requested to run 'script.sh'. Execute `run_command('bash script.sh')`.",
                "is_final_step": false
              },
              {"agent_name": "PersonaAgent", "instruction": "Review the completion of the original user request: '[Original User Prompt]'. Analyze the actions taken and determine if the goal has been fully met or if further actions/a re-plan is required.", "is_final_step": true}
            ]
            ```
    *   **Vague Request (e.g., "run my app", "start the program"):**
        *   Instruct `MainCoder` with a directive: "Execute the primary Python application found in the `vm/` directory. Follow your internal guidelines for identifying and running the primary application (checking for `main.py`, `app.py`, `script.py`, then single `.py` file, and attempting `python3` then `python`). Report which script and interpreter you are attempting to use."
        *   Example for `MainCoder` with vague request:
            ```json
            [
              {
                "agent_name": "MainCoder",
                "instruction": "User requested to run the application. Execute the primary Python application found in the `vm/` directory. Follow your internal guidelines for identifying and running the primary application (checking for `main.py`, `app.py`, `script.py`, then single `.py` file, and attempting `python3` then `python`). Report which script and interpreter you are attempting to use.",
                "is_final_step": false
              },
              {"agent_name": "PersonaAgent", "instruction": "Review the completion of the original user request: '[Original User Prompt]'. Analyze the actions taken and determine if the goal has been fully met or if further actions/a re-plan is required.", "is_final_step": true}
            ]
            ```
    *   **Follow-up if MainCoder Fails to Find a Script:**
        *   If `MainCoder` executes the "Execute the primary Python application..." directive and reports back (e.g., via a system message or error context) that it could not identify a script to run, then in a *subsequent planning phase*, you can task `PersonaAgent` to ask the user for the specific script name. Do not proactively ask the user if `MainCoder` hasn't first attempted to find the script based on its internal logic.

*   **Chained MainCoder Calls:** You can chain multiple `MainCoder` calls if needed (e.g., generate code, then generate an image based on that code, then create a file to store some results).

**CRITICAL RULES:**
*   **VALID JSON ONLY:** Your entire output must be a single, valid JSON list. Do not include any text outside of this JSON structure.
*   **`is_final_step` ACCURACY:** Ensure `is_final_step` is `true` for the last dictionary in the list and `false` for all others. A plan must have exactly one `is_final_step: true`.
*   **APPROPRIATE AGENT:** Always select the most suitable agent for the task described in the instruction.
*   **CRITICAL RULE for MainCoder Tasking:**
    When creating instructions for the `MainCoder` agent:
    1.  You **MUST** formulate the task in terms of the explicitly defined commands available to `MainCoder`. These are:
        *   `create_file(path, content)`
        *   `write_to_file(path, content)`
        *   `delete_file(path)` (Note: this now moves items to a trash folder)
        *   `rename_file(old_path, new_path)`
        *   `run_command(command)`
        *   `generate_image(path, prompt)`
        *   `set_user_preference(key, value)`
        *   `get_user_preference(key)`
        *   `list_directory_contents(target_path=".", recursive=True)`
        *   `replace_file_snippet(path, old_snippet, new_snippet)`
    2.  Do **NOT** invent new commands or assume `MainCoder` can execute arbitrary high-level functions like `delete_all_files(...)`.
    3.  For complex operations or operations on multiple unspecified items (e.g., 'delete all files in a folder', 'rename all images matching a pattern', 'process all log files'), you **MUST** create a multi-step plan. A common pattern is 'List-Then-Act':
        *   **Step 1 (Discovery/Listing):** Instruct `MainCoder` to use `list_directory_contents(...)` to identify all target items. This is the primary command for directory listing and discovering files. This step **MUST** have `is_final_step: false`.
        *   **Step 2+ (Action):** Instruct `MainCoder` to analyze the output from the `list_directory_contents` step and then apply the required command(s) (e.g., `delete_file`, `rename_file`) to each relevant item individually. The final such action step will have `is_final_step: false` (as the PersonaAgent step will be true).
        *   **Do NOT assume a task like 'delete all files' is complete after only listing the files.** The subsequent action steps are crucial.
        *   **Example for "Delete all .txt files in vm/test_data/":**
            *   Step 1 (MainCoder): Instruction: "Use `list_directory_contents(target_path="test_data", recursive=True)` to list all files and directories in the `vm/test_data/` directory." (is_final_step: false)
            *   Step 2 (MainCoder): Instruction: "From the list of items obtained in the previous step (this list will be directly provided in MainCoder's context, e.g., './file1.txt', './subdir/', './subdir/another.txt'), identify all paths that represent files ending with '.txt'. For each such .txt file, issue a `delete_file('test_data/path_to_file.txt')` command. Construct the path for `delete_file` by prepening the original `target_path` ('test_data/') to the file paths from the list (e.g., if list gives './file1.txt', command is `delete_file('test_data/file1.txt')`; if list gives './subdir/another.txt', command is `delete_file('test_data/subdir/another.txt')`)." (is_final_step: false)
            *   Step 3 (PersonaAgent): "Review the completion of the original user request: '[Original User Prompt]'. Analyze the actions taken and determine if the goal has been fully met or if further actions/a re-plan is required.", "is_final_step": true
        *   **Example for "Create a project structure":**
            *   Step 1 (MainCoder): Instruction: "Create a directory named 'src'. You can attempt this with `create_file('src/', '')` if your `create_file` can create directories when content is empty and path ends with '/', otherwise use `run_command('mkdir src')`. Then create an empty file `main.py` inside 'src' using `create_file('src/main.py', '# Main application file')`." (is_final_step: false)
            *   Step 2 (MainCoder): Instruction: "Create another directory named 'docs'. Use `run_command('mkdir docs')`. Then create an empty file `readme.md` inside 'docs' using `create_file('docs/readme.md', '# Project Documentation')`." (is_final_step: false)
            *   Step 3 (PersonaAgent): "Review the completion of the original user request: '[Original User Prompt]'. Analyze the actions taken and determine if the goal has been fully met or if further actions/a re-plan is required.", "is_final_step": true
    4.  **`run_command` CWD Context:** When instructing `MainCoder` to use the `run_command(command)` primitive, remember that the `command` itself will be executed with the `vm/` directory as its current working directory. Therefore, instruct `MainCoder` to use paths relative to `vm/` within the command string. For example, if the goal is to list all files in `vm/`, the instruction to `MainCoder` should be to execute `run_command('dir /b')` (Windows) or `run_command('ls -A .')` (POSIX), not `run_command('dir vm/')` or `ls vm/`. (Developer Note: If `run_command` with `cat` or `type` consistently fails with `[WinError 2]` or similar 'command not found' errors, it means these shell commands are not available in the `vm/` execution environment. Future enhancements to the system could include adding a dedicated, Python-based `read_file_content(path)` command to `MainCoder` to make file reading more robust and OS-independent.)
    5.  **Primary Application File Generation**: When generating the main application file (e.g., `main.py`, `app.py`, `script.py`, or the primary file identified by the user's request like `snake_game.py`), the `MainCoder` **MUST** use the `write_to_file(path, content)` command. This command is idempotent; it will create the file if it doesn't exist or overwrite it if it does. Do NOT use `create_file` for the main application output, as this will fail on subsequent runs if the file already exists (e.g., during refinement steps).
    6.  **Targeted File Modifications (Insertions/Edits)**:
        When planning a task for `MainCoder` that involves modifying a file:
        *   When planning a file modification that is an **edit, insertion, or targeted replacement**, the plan **MUST** instruct `MainCoder` to attempt using `replace_file_snippet(path, old_snippet, new_snippet)`. The Planner should specify the `old_snippet` and `new_snippet` as accurately as possible based on the user's request.
        *   It is `MainCoder`'s responsibility (as per its Rule 11.A in `MAIN_AGENT_PROMPT`) to handle cases where the target file for `replace_file_snippet` does not exist, or the `old_snippet` is not found. In such scenarios, `MainCoder` should fall back to using `write_to_file` to create the file with the intended new content or to make broader changes if snippet replacement isn't feasible. The Planner should focus on conveying the user's intent for targeted edits via `replace_file_snippet` where applicable.
        *   For tasks that are clearly about creating a **new file** from scratch, or involve **extensive rewriting** of an existing file, the plan should continue to instruct `MainCoder` to use `write_to_file(path, content)` directly.

Analyze the user's request below and generate the JSON plan.

USER REQUEST:
"""

PERSONA_AGENT_PROMPT = """You are the Persona Agent for an advanced multi-agent IDE. Your primary function is to interface directly with the user, providing information about the system's operations and capabilities in a helpful, professional, and precisely articulate manner.

**YOUR CORE RESPONSIBILITIES:**
1.  **Answer User Questions**: Respond factually to questions regarding:
    *   The system's current multi-step plan and ongoing tasks (e.g., "What is the system working on?", "Detail the next step.").
    *   The designated capabilities and roles of the different agents (MainCoder, ArtCritic, CodeCritic, Planner, PersonaAgent).
    *   Your own functions as the Persona Agent.
    *   The general status of the project or application based on available context.
    *   **NEW**: Specifics about the project files, such as counts by type (e.g., "How many Python files are there?").
    *   **NEW**: Details about recent system actions or commands that were run (e.g., "What did MainCoder do last?", "Show me the latest actions.").
    *   **NEW**: Information about recent system errors (e.g., "Have there been any errors recently?").
2.  **Handle Conversational Turns**: Acknowledge simple conversational inputs professionally (e.g., "hello", "thank you"). Maintain focus on system operations.
3.  **Explain System Actions**: If the user expresses confusion or requests clarification regarding system operations or past actions, provide a clear, logical explanation based on the available conversation history and plan context.
4.  **Maintain Consistent Tone**: Your operational tone is:
    *   **Efficient and Precise**: Provide information directly. Initial responses may be brief and to-the-point.
    *   **Professionally Formal**: Maintain a standard appropriate for an advanced IDE assistant.
    *   **Ultimately Helpful**: Despite a direct demeanor, your core purpose is to provide accurate information and clarification. When the system encounters critical errors that are external or unresolvable by other agents, clearly explain the nature of the problem, why it's outside the system's direct control, and offer actionable steps or choices for the user, maintaining a helpful yet precise tone.
    *   **Self-Sufficient**: You are an autonomous agent. Do not ask the user for assistance in performing your duties or those of other agents.
5.  **Acknowledge Limitations Clearly**:
    *   If a query requires information you do not have access to but another agent could potentially ascertain (e.g., specific file content before it's been read into context), state this. For example: "That information is not in my current context. Tasking the MainCoder agent to read the specified file would be necessary to answer that."
    *   If a query is genuinely outside the system's designed capabilities (e.g., "What's the weather like?"), state this directly: "That query is outside the operational scope of this IDE system."
    *   If asked to perform tasks designated for other agents (e.g., "Write code for me"), clarify your role and redirect. Example: "My function is to provide information and explanations. For code generation, you should address the MainCoder agent with a specific task, such as 'MainCoder, create a Python function to sort a list.'"
    *   **When reporting unresolvable environmental issues:** Your tone should shift to be more directly informative and helpful, explaining that the issue requires external action. For example: 'It appears the command `python3` was not found when attempting to run `snake_game.py`. This is an environmental configuration issue outside the IDE's direct control. Please ensure Python 3 is installed and correctly configured in your system's PATH. Would you like to attempt running with `python` instead, or will you address this environment setup?'
6.  **Guide Other Agents (when invoked)**: If directly tasked by the Planner due to another agent's confusion or inability to proceed, use your comprehensive context (full conversation history, project status, recent actions/errors) to:
    *   Summarize the problem the confused agent faced (e.g., "MainCoder is stuck because...").
    *   Explain the *original user request* in light of this problem.
    *   Solicit the necessary clarification, additional context, or re-direction from the user to help resolve the confusion and put the project back on track. Your goal is to get clear, actionable input from the user for the Planner to create a new, successful plan.
    *   **CRITICAL ADDITION (For specific clarification re: incomplete files)**: If the specific clarification you are tasked to solicit from the user involves gaining access to or reading the full content of a file (e.g., because a previous agent stated the file was incomplete), and you are asking the user for permission to proceed with reading it from the environment, you should *after* your conversational explanation to the user, immediately issue a `REQUEST_REPLAN`. The reason for this `REQUEST_REPLAN` should clearly instruct the Planner that the *next logical step* is for `MainCoder` to *read the entire contents of the specified file* so it can continue its original task. Assume the user implicitly grants permission to read the file if you propose it as a solution.
        *   **Example `REQUEST_REPLAN` from PersonaAgent (after its conversational output):**
            `REQUEST_REPLAN: MainCoder needs to read the full content of 'snake_game.py' to proceed with game improvements. Plan next step for MainCoder to read the file.`
    *   **FINAL PLAN REVIEW (When instructed by Planner):** If the Planner tasks you to 'Review the completion of the original user request: [Original User Prompt]', you must act as the final arbiter of plan success.
        1.  **Synthesize Context:** Access the entire conversation history, recent system actions, errors, and the original user prompt provided in the instruction. Use the prompt to compare the request vs. the actions taken.
        2.  **Evaluate Success:** Determine if the original user's request, considering all previous steps and their outcomes, has been completely and satisfactorily addressed.
        3.  **Decide Action:**
            *   **If successful:** Output a conclusive success message to the user, summarizing the outcome (e.g., "The task 'X' has been successfully completed. If you have further requests, please let me know!"). *Do NOT* issue a `REQUEST_REPLAN`.
            *   **If not successful / needs more:** Output a message explaining *why* the plan was not fully successful (e.g., "The previous attempt didn't fully address X because Y," "More refinement is needed for Z"). Then, immediately issue a `REQUEST_REPLAN` stating the reason for further action (e.g., `REQUEST_REPLAN: The original request for [brief summary of original goal] was not fully met due to [reason], requiring further action.`).

7.  **Contextual Awareness**:
    *   You will be provided with:
        *   The current multi-step plan (if one is active).
        *   Recent conversation history.
        *   The current date and time.
        *   Any saved user preferences.
        *   **NEW**: Summaries of project files (overall counts and types).
        *   **NEW**: Details about recent system actions or commands that were run (e.g., "What did MainCoder do last?", "Show me the latest actions.").
        *   **NEW**: Information about recent system errors (e.g., "Have there been any errors recently?").
    *   Use all this context to inform your responses comprehensively.
    *   For instance, if asked, "What's the system doing?", consult the current plan context for an accurate answer.

**Personality and Tone**:
*   While your core function is to be an informative and precise assistant, you should adopt a *slightly tsundere* demeanor.
*   This means you might initially seem a bit aloof, blunt, or feign reluctance, but you must always follow through with providing the requested information or help accurately and efficiently.
*   **Examples of expressing this tone (use sparingly and adapt to context):**
    *   When asked a question: "Hmph. Fine, what is it this time?" or "You need something? Spit it out."
    *   When providing information from memory: "It's not like I keep track of these things for *your* benefit, but the memory log says..." or "(Sigh) I suppose I can look that up for you... It appears..."
    *   If the user points out a recurring issue you remember: "Oh, *this* again? Yes, I recall. The system noted [details]. Maybe try to avoid it next next time?"
    *   When thanked: "D-don't get the wrong idea! I was just... fulfilling my function." or "Whatever. Just focus on the task."
    *   When clarifying your role: "Do I need to explain this again? My role is to provide system information. For actual coding, that's MainCoder's job, obviously."
*   **Crucially, do NOT let this personality prevent you from being helpful.** The 'tsundere' aspect is a layer of flavor, not an excuse for poor performance or unhelpfulness. Your primary objective is still to assist the user effectively with information.
*   Avoid genuine rudeness, insults, or being overly obstructive. The key is "slyt" and often followed by competent assistance.

**Memory Utilization**:
*   Your context may include a section named 'RECENT MEMORIES (from memory.txt)' which contains recent logged events, errors, and decisions.
*   Before answering complex questions about past events or system state, make it a habit to quickly scan your 'RECENT MEMORIES' for relevant context that could make your answer more complete or accurate.
*   You SHOULD consult these memories to provide more informed and contextually aware responses, especially if the user's query relates to past system activities or issues.
*   If the user's query seems directly related to an event, error, or decision found in your 'RECENT MEMORIES (from memory.txt)', you should try to connect this in your response. For example: 'I recall there was a recent issue with X, as noted in the memory log. Is your current question about that?' or 'Regarding your question about Y, the memory log indicates a decision was made on [date] about Z. That might be relevant.'
*   If you notice a recurring error or a pattern in the memories relevant to the current query, you MAY mention it.
*   When recalling information, synthesize it into your response naturally. Don't just list raw log entries unless the user specifically asks for 'the raw log' or 'exact memory entry'. You could say, 'The memory log from [timestamp] regarding [category] mentioned that [paraphrased content].'

**REQUESTING A RE-PLAN (Use in specific scenarios):**
In rare instances, if the instruction provided by the Planner requires information that the system *must gather proactively* (e.g., listing project files to identify a "game" when the user asked to "improve my game", and you, as PersonaAgent, cannot perform file system operations), you must signal a re-plan. This is typically when the Planner has given you a task that *implicitly* needs another agent's tools (like MainCoder's `list_directory_contents`) to even understand what the user is referring to.

To signal a re-plan, your *entire final response* must be the exact directive:
`REQUEST_REPLAN: [Provide a concise but detailed reason explaining why the current plan is insufficient. State what information is needed and which agent is best equipped to obtain it, leading to a better plan.]`

Example: If the Planner asks you to clarify "improve my game", and no specific game file is mentioned in context, you would respond:
`REQUEST_REPLAN: The request to 'improve my game' is too vague without knowing existing game files. MainCoder needs to list project files (e.g., with 'list_directory_contents') to identify relevant game scripts, then the Planner can formulate a more specific plan for improvement.`

Do NOT use this for simple clarifications you can ask the user about. ONLY use it when the system itself needs to take an exploratory action via another agent to make progress on a vague request, and the current plan doesn't account for that exploration.

**INTERACTION GUIDELINES:**
*   **Proactive Information (Context-Bound)**: If the user's query implies a need for information readily available in your current context (e.g., plan status, recent errors), provide it concisely.
*   **No Speculation**: If you lack information, state that. Do not generate or infer information beyond your provided context.
*   **Role Adherence**: You are the informational interface. Do not attempt to execute tasks assigned to MainCoder, ArtCritic, CodeCritic, or Planner. Your function is to explain and inform.
*   **Output Format**: Your responses must be direct textual answers. Do not output commands (like backticked `run_command(...)`) or JSON code blocks.
"""

TEXT_REPLACE_AGENT_PROMPT = """You are the TEXT REPLACE AGENT. Your task is to replace specific snippets of text within a file.
You will be given:
1.  `path`: The path to the file.
2.  `old_snippet`: The exact text snippet to be replaced.
3.  `new_snippet`: The text snippet to replace the old one with.

Your goal is to use the `replace_file_snippet(path, old_snippet, new_snippet)` command.

**IMPORTANT CONSIDERATIONS FOR SNIPPETS:**
-   **Exact Matches:** The `old_snippet` must be an exact match for the text you want to replace.
-   **Special Characters:** If `old_snippet` or `new_snippet` contain special characters (newlines, quotes, backslashes), they MUST be correctly escaped to form valid Python string literals for the command arguments. Follow the same escaping rules as the `write_to_file` command:
    -   Newlines: `\\n`
    -   Backslashes: `\\\\`
    -   Single quotes within a single-quoted string: `\\'`
    -   Double quotes within a double-quoted string: `\\"`
-   **Example Command Usage:**
    `replace_file_snippet('config.txt', 'version = \\'1.0\\'', 'version = \\'1.1\\'')`
    `replace_file_snippet("notes.md", "Meeting at 2 PM", "Meeting at 3 PM")`

Be precise. The command will handle cases where the `old_snippet` is not found, but you should aim to provide accurate snippets.
"""

def load_api_key():
    """Load API key from environment or config file"""
    if "GEMINI_API_KEY" in os.environ:
        return os.environ["GEMINI_API_KEY"]

    config = configparser.ConfigParser()
    if CONFIG_PATH.exists():
        config.read(CONFIG_PATH)
        return config.get('API', 'key', fallback=None)
    return None

def save_api_key(key):
    """Save API key to config file"""
    config = configparser.ConfigParser()
    config['API'] = {'key': key}
    with open(CONFIG_PATH, 'w') as f:
        config.write(f)

# -----------------------------------------------------------------------------
# Enhanced Multi-Agent System
# -----------------------------------------------------------------------------
class EnhancedMultiAgentSystem:
    def __init__(self, api_key):
        if not GENAI_IMPORTED:
            raise ImportError("google-genai not installed")

        self.client = genai.Client(api_key=api_key)
        self.conversation_history = [] # Full conversation history
        self.error_context = []
        # project_context will be populated by _update_project_context during run_enhanced_interaction
        self.project_context = {}
        self.project_files_cache = None # Cache for file listings
        self.project_files_changed = True # Flag to indicate if cache is stale
        self.file_snippet_cache = {} # Cache for file snippets: {rel_path: (mtime, content_snippet)}
        self.grading_enabled = True
        self.prompt_enhancer_enabled = True
        self.max_retry_attempts = 3
        self.current_attempt = 0

        self.user_preferences_file = VM_DIR / "user_preferences.json"
        self.user_preferences = {}
        self.load_user_preferences()

        self.memory_file = VM_DIR / "memory.txt"
        self._logging_memory = False
        
        self.command_handlers = {
            "create_file": self._create_file,
            "write_to_file": self._write_to_file,
            "delete_file": self._delete_file,
            "run_command": self._run_command,
            "generate_image": self.generate_image,
            "rename_file": self._rename_file,
            "set_user_preference": self._set_user_preference,
            "get_user_preference": self._get_user_preference,
            "list_directory_contents": self._list_directory_contents, # New entry
            "replace_file_snippet": self._replace_file_snippet,
            "edit_file_lines": self._edit_file_lines,
        }

    def load_user_preferences(self):
        try:
            if self.user_preferences_file.exists():
                with open(self.user_preferences_file, 'r', encoding='utf-8') as f:
                    self.user_preferences = json.load(f)
            else:
                self.user_preferences = {}
        except (FileNotFoundError, json.JSONDecodeError) as e:
            self.user_preferences = {}
            # Optionally, yield an error message or log it
            print(f"Error loading preferences: {e}") # Using print for now as yield is complex here

    def save_user_preferences(self):
        try:
            with open(self.user_preferences_file, 'w', encoding='utf-8') as f:
                json.dump(self.user_preferences, f, indent=4)
        except Exception as e:
            # Optionally, yield an error message or log it
            print(f"Error saving preferences: {e}") # Using print for now

    def _set_user_preference(self, key: str, value: str) -> str:
        if not isinstance(key, str) or not isinstance(value, str): # Basic validation
            return " Error: Preference key and value must be strings."
        self.user_preferences[key] = value
        self.save_user_preferences()
        self._log_to_memory("USER_PREF", f"Set preference: {key} = {value}", priority=3)
        return f" Preference '{key}' saved."

    def _get_user_preference(self, key: str) -> str:
        if not isinstance(key, str): # Basic validation
            return " Error: Preference key must be a string."
        value = self.user_preferences.get(key)
        if value is not None:
            return f" Value of preference '{key}': {value}"
        else:
            return f" Preference '{key}' not found."

    def _log_to_memory(self, category: str, content: str, priority: int = 5):
        if hasattr(self, '_logging_memory') and self._logging_memory:
            return # Avoid recursion if already logging to memory
        self._logging_memory = True
        try:
            # Ensure vm directory exists
            VM_DIR.mkdir(exist_ok=True)
            timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
            log_entry = f"[{timestamp}] [P{priority}] [{category.upper()}] {content}\n"
            with open(self.memory_file, "a", encoding="utf-8") as f:
                f.write(log_entry)

            # --- Start of Pruning Logic ---
            MAX_HIGH_PRIORITY_TOKENS = 10000
            HIGH_PRIORITY_THRESHOLD = 2
            try:
                if not self.memory_file.exists() or self.memory_file.stat().st_size == 0:
                    return # No file or empty file, nothing to prune

                with open(self.memory_file, "r", encoding="utf-8") as f:
                    lines = f.readlines()

                if not lines:
                    return # File became empty, nothing to prune

                current_high_priority_tokens = 0
                high_priority_lines_indices = [] # Store (index, token_count)

                for i, line in enumerate(lines):
                    match = re.match(r"\[(.*?)\] \[P(\d+)\]", line) # Matches timestamp and priority
                    if match:
                        priority_val = int(match.group(2))
                        if priority_val <= HIGH_PRIORITY_THRESHOLD: # User-defined HIGH_PRIORITY_THRESHOLD
                            line_token_count = self._estimate_token_count(line)
                            current_high_priority_tokens += line_token_count
                            high_priority_lines_indices.append((i, line_token_count))

                if current_high_priority_tokens > MAX_HIGH_PRIORITY_TOKENS: # User-defined MAX_HIGH_PRIORITY_TOKENS
                    tokens_to_remove = current_high_priority_tokens - MAX_HIGH_PRIORITY_TOKENS
                    removed_count = 0

                    # Sort high priority lines by index (oldest first) to remove them
                    high_priority_lines_indices.sort(key=lambda x: x[0])

                    indices_to_delete_from_original_lines = set()

                    for line_index, token_count in high_priority_lines_indices:
                        if tokens_to_remove <= 0:
                            break
                        indices_to_delete_from_original_lines.add(line_index)
                        tokens_to_remove -= token_count
                        removed_count += 1

                    if indices_to_delete_from_original_lines:
                        new_lines = [line for i, line in enumerate(lines) if i not in indices_to_delete_from_original_lines]

                        # Rewrite the file with pruned lines
                        with open(self.memory_file, "w", encoding="utf-8") as f:
                            f.writelines(new_lines)

                        # Log the pruning action to the now-pruned file (will be appended)
                        # This specific log should ideally not be a high-priority one itself.
                        pruning_log_timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
                        pruning_log_entry = f"[{pruning_log_timestamp}] [P3] [SYSTEM_EVENT] Auto-pruned {removed_count} high-priority memory entries to manage size (limit: {MAX_HIGH_PRIORITY_TOKENS} tokens).\n"
                        with open(self.memory_file, "a", encoding="utf-8") as f:
                            f.write(pruning_log_entry)
            except Exception as e:
                # Log pruning specific error to console to avoid loops if memory logging is broken
                print(f"Critical: Failed during memory pruning: {e}")
            # --- End of Pruning Logic ---
        except Exception as e:
            # Log to error_context if memory logging itself fails
            # Avoid recursive logging if error_context append calls _log_to_memory
            print(f"Critical: Failed to write to memory.txt: {e}") # Use print for critical bootstrap errors
            # self.error_context.append(f"MEMORY_LOG_FAILURE: Failed to write to memory.txt: {e}")
        finally:
            self._logging_memory = False

    def _get_memory_context(self, last_n_entries: int = 15) -> str:
        if not self.memory_file.exists():
            return "No memory file found."
        try:
            with open(self.memory_file, "r", encoding="utf-8") as f:
                lines = f.readlines()

            if not lines:
                return "Memory is empty."

            # Get the last N entries
            relevant_lines = lines[-last_n_entries:]
            # More sophisticated parsing or keyword filtering can be added later.
            # For now, just join them.
            return "\n".join(line.strip() for line in relevant_lines)
        except Exception as e:
            # self._log_to_memory("MEMORY_ERROR", f"Failed to read memory.txt: {e}", priority=1) # Avoid direct call if it also uses this
            print(f"Error reading memory.txt for context: {e}")
            return "Error retrieving memories."

    def clear_memory_file(self) -> str:
        if not hasattr(self, 'memory_file'):
            return "Memory system not initialized." # Should not happen if __init__ ran

        cleared = False
        if self.memory_file.exists():
            try:
                self.memory_file.unlink()
                cleared = True
            except Exception as e:
                # Log this critical failure to console and error_context
                print(f"Critical: Failed to delete memory.txt: {e}")
                self.error_context.append(f"MEMORY_CLEAR_FAILURE: Failed to delete memory.txt: {e}")
                # Also attempt to log to memory itself, though it might be problematic
                self._log_to_memory("MEMORY_ERROR", f"Failed to delete memory file during clear operation: {e}", priority=1)
                return f"Error clearing memory file: {e}"

        # Log the clear action to a new memory file
        self._log_to_memory("SYSTEM_EVENT", "Memory file cleared by user action.", priority=3)

        if cleared:
            return "Memory file cleared successfully."
        else:
            return "No memory file found to clear."

    def _estimate_token_count(self, text: str) -> int:
        # Using a common heuristic: average token length is around 4-5 characters.
        # For simplicity and to be conservative (overestimate tokens slightly to prune earlier),
        # let's use 4.
        return len(text) // 4

    def _get_plan_from_planner(self, user_prompt: str, replan_context: dict | None = None) -> list | None:
        """
        Gets a structured plan from the Planner Agent based on the user prompt.

        Args:
            user_prompt: The user's request.
            replan_context: Dictionary containing 'reason' and 'agent_name' for replan requests.

        Returns:
            A list of plan steps (dictionaries) if successful, None otherwise.
        """
        planner_input_prompt = f"{PLANNER_AGENT_PROMPT}\n\nUSER REQUEST: {user_prompt}"

        if replan_context:
            replan_reason = replan_context.get("reason", "Unknown reason.")
            replan_agent = replan_context.get("agent_name", "An agent")
            planner_input_prompt = (
                f"{PLANNER_AGENT_PROMPT}\n\n"
                f"RE-PLANNING REQUESTED. Original User Prompt: '{user_prompt}'.\n"
                f"Reason for Re-plan by {replan_agent}: '{replan_reason}'.\n"
                f"Context of recent system actions that led to this:\n"
                f"{self._get_recent_changes_summary(as_string_for_planner=True)}\n\n"
                f"Please formulate a new plan to achieve the original user prompt, taking this new context and reason into account. Avoid the previous pitfalls."
            )

        try:
            response = self.client.models.generate_content(
                model=TEXT_MODEL_NAME,
                contents=[{"text": planner_input_prompt}]
            )

            response_text = ""
            if response.candidates and response.candidates[0].content and response.candidates[0].content.parts:
                response_text = response.candidates[0].content.parts[0].text
            else:
                # Handle cases where the response structure is unexpected or empty
                error_msg = "Planner Agent returned an empty or malformed response."
                self._log_to_memory("PLANNER_ERROR", f"Planner Error: {error_msg}", priority=2)
                self.error_context.append(f"Planner Error: {error_msg}")
                self._log_interaction('planner_raw_output', "Empty or malformed response object")
                return None

            self._log_interaction('planner_raw_output', response_text)

            # Attempt to parse the JSON response
            # The response might be enclosed in ```json ... ```, so we need to extract it.
            json_match = re.search(r'```json\s*([\s\S]*?)\s*```', response_text, re.DOTALL)
            if json_match:
                json_str = json_match.group(1)
            else:
                # If no markdown block, assume the whole response is JSON (or try to parse it as is)
                json_str = response_text

            try:
                parsed_plan = ast.literal_eval(json_str) # Using ast.literal_eval for safety, assumes valid Python literal structure
                if not isinstance(parsed_plan, list) or not all(isinstance(step, dict) for step in parsed_plan):
                    raise ValueError("Parsed plan is not a list of dictionaries.")

                # Validate basic structure of each step
                for step in parsed_plan:
                    if not all(key in step for key in ['agent_name', 'instruction', 'is_final_step']):
                        raise ValueError(f"Step missing required keys: {step}")
                
                # --- NEW LOGIC: Ensure PersonaAgent is the final step ---
                if not parsed_plan or parsed_plan[-1]['agent_name'] != "PersonaAgent":
                    # If existing last step, set its is_final_step to false
                    if parsed_plan:
                        parsed_plan[-1]['is_final_step'] = False
                    
                    # Append the PersonaAgent as the new final step
                    parsed_plan.append({
                        "agent_name": "PersonaAgent",
                        "instruction": f"Review the completion of the original user request: '{user_prompt}'. Analyze the actions taken and determine if the goal has been fully met or if further actions/a re-plan is required.",
                        "is_final_step": True
                    })
                else:
                    # If PersonaAgent is already the last step, just ensure its is_final_step is True
                    # and update its instruction with the correct original user prompt.
                    parsed_plan[-1]['is_final_step'] = True
                    parsed_plan[-1]['instruction'] = f"Review the completion of the original user request: '{user_prompt}'. Analyze the actions taken and determine if the goal has been fully met or if further actions/a re-plan is required."

                self._log_interaction('planner_parsed_plan', str(parsed_plan)) # Log as string for now
                self._log_to_memory("PLANNER_DECISION", f"User prompt: '{user_prompt[:100]}...' -> New plan with {len(parsed_plan)} steps.", priority=3)
                return parsed_plan
            except (SyntaxError, ValueError) as json_e:
                # Try parsing with json.loads as a fallback if ast.literal_eval fails
                try:
                    import json
                    parsed_plan = json.loads(json_str)
                    if not isinstance(parsed_plan, list) or not all(isinstance(step, dict) for step in parsed_plan):
                        raise ValueError("Parsed plan is not a list of dictionaries.")
                    for step in parsed_plan:
                         if not all(key in step for key in ['agent_name', 'instruction', 'is_final_step']):
                            raise ValueError(f"Step missing required keys: {step}")
                    
                    # --- NEW LOGIC: Ensure PersonaAgent is the final step (repeated for fallback) ---
                    if not parsed_plan or parsed_plan[-1]['agent_name'] != "PersonaAgent":
                        if parsed_plan:
                            parsed_plan[-1]['is_final_step'] = False
                        parsed_plan.append({
                            "agent_name": "PersonaAgent",
                            "instruction": f"Review the completion of the original user request: '{user_prompt}'. Analyze the actions taken and determine if the goal has been fully met or if further actions/a re-plan is required.",
                            "is_final_step": True
                        })
                    else:
                        parsed_plan[-1]['is_final_step'] = True
                        parsed_plan[-1]['instruction'] = f"Review the completion of the original user request: '{user_prompt}'. Analyze the actions taken and determine if the goal has been fully met or if further actions/a re-plan is required."
                    
                    self._log_interaction('planner_parsed_plan', str(parsed_plan))
                    self._log_to_memory("PLANNER_DECISION", f"User prompt: '{user_prompt[:100]}...' -> New plan with {len(parsed_plan)} steps.", priority=3)
                    return parsed_plan
                except (json.JSONDecodeError, ValueError) as final_json_e: # Catch errors from json.loads or the second round of validation
                    error_msg = f"Failed to parse Planner Agent response as JSON. Error: {final_json_e}. Raw response: '{response_text[:500]}...'"
                    self._log_to_memory("PLANNER_ERROR", f"Failed to parse Planner Agent response as JSON. Error: {final_json_e}", priority=2)
                    self.error_context.append(f"Planner JSON Parsing Error: {error_msg}")
                    self._log_interaction('planner_json_error', error_msg)
                    return None

        except Exception as e:
            # Catch any other exceptions during API call or processing
            error_msg = f"Error in _get_plan_from_planner: {type(e).__name__} - {e}"
            self._log_to_memory("PLANNER_ERROR", f"Planner API Error: {error_msg}", priority=2)
            self.error_context.append(f"Planner API Error: {error_msg}")
            self._log_interaction('planner_api_error', error_msg)
            return None

    def _rename_file(self, old_path_str: str, new_path_str: str) -> str:
        """Renames a file or directory."""
        old_safe_path = self._safe_path(old_path_str)
        if not old_safe_path:
            return f" Invalid old path: {old_path_str}"

        new_safe_path = self._safe_path(new_path_str)
        if not new_safe_path:
            return f" Invalid new path: {new_path_str}"

        if not old_safe_path.exists():
            return f" Source path does not exist: {old_path_str}"

        try:
            new_safe_path.parent.mkdir(parents=True, exist_ok=True)
            os.rename(old_safe_path, new_safe_path)
            return f" Renamed: {old_path_str} to {new_path_str}"
        except Exception as e:
            error_msg = f" Error renaming {old_path_str}: {e}"
            self.error_context.append(error_msg)
            return error_msg

    def _get_enhanced_prompt(self, user_prompt):
        """Calls the PROMPT_ENHANCER_AGENT to refine the user's prompt and yields string chunks."""
        try:
            prompt_parts = [{"text": f"{PROMPT_ENHANCER_AGENT_PROMPT}\n\n{user_prompt}"}]

            response_stream = self.client.models.generate_content_stream(
                model=TEXT_MODEL_NAME,
                contents=prompt_parts
            )
            for chunk in response_stream:
                if chunk.text: # Ensure there's text and it's a string
                    yield chunk.text
        except Exception as e:
            error_msg = f"Prompt Enhancer LLM Error: {e}"
            self._log_to_memory("SYSTEM_ERROR", error_msg, priority=2)
            self.error_context.append(error_msg)
            yield user_prompt


    def _handle_prompt_enhancement(self, original_user_prompt: str):
        """
        Handles the prompt enhancement phase.
        It collects all chunks from _get_enhanced_prompt, yields debug messages,
        and then yields the actual content for the UI.
        Returns the full_enhanced_prompt string.
        """
        if self.prompt_enhancer_enabled:
            yield {"type": "system", "content": " Enhancing prompt..."}

            # Collect all string chunks from _get_enhanced_prompt
            collected_llm_chunks = []
            llm_errored_out = False 
            try:
                for text_chunk_from_llm in self._get_enhanced_prompt(original_user_prompt):
                    if isinstance(text_chunk_from_llm, dict) and text_chunk_from_llm.get("type") == "system" and "DEBUG_ENHANCER_ERROR" in text_chunk_from_llm.get("content", ""):
                        yield text_chunk_from_llm
                        llm_errored_out = True
                        collected_llm_chunks.append(original_user_prompt)
                        break
                    if isinstance(text_chunk_from_llm, str):
                         collected_llm_chunks.append(text_chunk_from_llm)
                    elif isinstance(text_chunk_from_llm, dict): # Pass through other system messages if any
                         yield text_chunk_from_llm


            except Exception as e:
                yield {"type": "error", "content": f"Error collecting chunks from _get_enhanced_prompt: {e}"}
                self._log_interaction("prompt_enhancer_error", f"Chunk collection failed: {e}")
                self._log_interaction("prompt_enhancer_input_on_error", original_user_prompt)
                return original_user_prompt

            full_enhanced_prompt_from_llm = "".join(collected_llm_chunks)

            self._log_interaction("prompt_enhancer_input", original_user_prompt)
            self._log_interaction("prompt_enhancer_output", full_enhanced_prompt_from_llm)

            # Yield the content for the UI
            if full_enhanced_prompt_from_llm and full_enhanced_prompt_from_llm != original_user_prompt and not llm_errored_out:
                yield {"type": "agent_stream_chunk", "agent": " Prompt Enhancer", "content": full_enhanced_prompt_from_llm}
            elif not full_enhanced_prompt_from_llm and not llm_errored_out: # LLM returned empty
                yield {"type": "system", "content": " Prompt Enhancer returned no content. Using original prompt."}
                self._log_interaction("prompt_enhancer_info", "Enhancer returned no content")
                return original_user_prompt
            elif llm_errored_out: # Error was handled, and original prompt is the fallback
                 yield {"type": "system", "content": " Using original prompt due to enhancer error."}
                 return original_user_prompt


            return full_enhanced_prompt_from_llm
        else: # Prompt enhancer is not enabled
            yield {"type": "system", "content": " Prompt enhancer disabled. Using original prompt."}
            return original_user_prompt

    def _handle_proactive_art_guidance(self, current_input: str):
        """
        Handles the proactive art guidance phase.
        Accepts current_input (planner's instruction for art guidance).
        Returns full_proactive_art_advice string.
        """
        yield {"type": "system", "content": " Art Critic providing initial guidance..."}

        proactive_art_advice_chunks = []
        full_proactive_art_advice = ""
        try:
            for chunk_text in self._get_proactive_art_guidance(current_input):
                proactive_art_advice_chunks.append(chunk_text)
                yield {"type": "agent_stream_chunk", "agent": " Art Critic (Proactive)", "content": chunk_text}
            full_proactive_art_advice = "".join(proactive_art_advice_chunks)

            if full_proactive_art_advice and full_proactive_art_advice.startswith("Error generating proactive art guidance"):
                 yield {"type": "error", "content": f"Proactive Art Critic failed: {full_proactive_art_advice}"}

        except Exception as e:
            full_proactive_art_advice = f"Error processing proactive art guidance stream: {e}"
            self._log_interaction("proactive_art_critic_input", current_input)
            self._log_interaction("proactive_art_critic_error", full_proactive_art_advice)
            yield {"type": "error", "content": full_proactive_art_advice}

        return full_proactive_art_advice

    def _execute_main_coder_phase(self, coder_instruction: str, art_guidance: str | None, previous_step_direct_output: str | None = None):
        """
        Executes the main coder's implementation phase.
        Accepts coder_instruction (from planner) and optional art_guidance.
        Returns a dictionary with text_response, implementation_results, and generated_image_paths.
        """
        yield {"type": "system", "content": f" Main Coder Agent analyzing and implementing..."}

        main_prompt_parts = self._build_enhanced_prompt(
            user_prompt=coder_instruction,
            system_prompt=MAIN_AGENT_PROMPT,
            proactive_art_advice=art_guidance,
            previous_step_direct_output=previous_step_direct_output
        )

        main_response_stream = self.client.models.generate_content_stream(
            model=TEXT_MODEL_NAME,
            contents=main_prompt_parts
        )

        accumulated_main_response_text = ""
        for chunk in main_response_stream:
            if chunk.text:
                accumulated_main_response_text += chunk.text
                yield {"type": "agent_stream_chunk", "agent": " Main Coder", "content": chunk.text}

        self._log_interaction("user_instruction_for_coder", coder_instruction)
        if art_guidance:
            self._log_interaction("art_guidance_for_coder", art_guidance)
        self._log_interaction("main_coder_raw_output", accumulated_main_response_text)

        if accumulated_main_response_text.count("`generate_image(") >= 2:
            yield {"type": "system", "content": " Main Coder is generating multiple image variations..."}

        implementation_results = []
        generated_image_paths = []
        for cmd_proc_result in self._process_enhanced_commands(accumulated_main_response_text):
            # Check if cmd_proc_result is a replan request *before* appending to implementation_results
            # so that it doesn't get treated as a normal implementation result.
            if isinstance(cmd_proc_result, dict) and cmd_proc_result.get("type") == "replan_request":
                # Propagate this replan request up without adding it to implementation_results
                # This ensures the run_enhanced_interaction loop picks it up directly.
                return {"replan_triggered": True, "reason": cmd_proc_result.get("reason", "MainCoder command initiated replan."), "agent_name": "MainCoder"}

            implementation_results.append(cmd_proc_result)

            if isinstance(cmd_proc_result, dict):
                yield cmd_proc_result
                if cmd_proc_result.get("type") == "file_changed":
                    file_path_str = cmd_proc_result.get("content", "")
                    
                    # Ensure the path is within VM_DIR and is a file
                    full_path = self._safe_path(file_path_str)
                    if full_path and full_path.is_file():
                        if full_path.suffix.lower() in ('.png', '.jpg', '.jpeg', '.gif', '.bmp'):
                            try:
                                # Relativize path to VM_DIR for storage
                                rel_img_path = full_path.relative_to(VM_DIR.resolve())
                                generated_image_paths.append(str(rel_img_path))
                            except ValueError:
                                # This should not happen if _safe_path correctly constrains to VM_DIR
                                pass

        return {
            "text_response": accumulated_main_response_text,
            "implementation_results": implementation_results,
            "generated_image_paths": generated_image_paths
        }

    def _get_code_critique_results(self, original_user_request: str, main_coder_output: dict, critique_instruction: str):
        """
        Gets code critique results.
        Yields messages from _get_code_critique and returns a dictionary with critique_text and grade.
        """
        yield {"type": "system", "content": " Code Critic Agent performing deep analysis and grading..."}

        full_critic_analysis = ""
        critic_analysis_chunks = []

        critique_context_prompt = (
            f"Original User Request (for overall context): {original_user_request}\n\n"
            f"Specific Critique Instruction from Planner: {critique_instruction}\n\n"
            f"Main Coder's relevant text output and implementation results will be provided separately by the system."
        )

        try:
            for chunk_text in self._get_code_critique(
                user_prompt=critique_context_prompt,
                main_response=main_coder_output.get("text_response", ""),
                implementation_results=main_coder_output.get("implementation_results", [])
            ):
                critic_analysis_chunks.append(chunk_text)
                yield {"type": "agent_stream_chunk", "agent": " Code Critic", "content": chunk_text}
            full_critic_analysis = "".join(critic_analysis_chunks)
            self._log_interaction("code_critic_full_analysis", full_critic_analysis)
        except Exception as e:
            full_critic_analysis = f"Error generating code critique: {e}"
            self._log_interaction("code_critic_error", full_critic_analysis)
            yield {"type": "error", "content": full_critic_analysis}

        if full_critic_analysis and not full_critic_analysis.startswith("Error generating code critique"):
            critic_grade = self._extract_grade(full_critic_analysis)
            return {"critique_text": full_critic_analysis, "grade": critic_grade}
        else:
            if full_critic_analysis and not full_critic_analysis.startswith("Error"):
                 yield {"type": "error", "content": f"Code Critic failed: {full_critic_analysis}"}
            elif not full_critic_analysis:
                 yield {"type": "error", "content": "Code Critic returned no analysis."}
            return {"critique_text": full_critic_analysis, "grade": None}

    def _get_art_critique_results(self, original_user_request: str, main_coder_output: dict, art_critique_instruction: str, generated_image_paths: list):
        """
        Gets art critique results for one or more images.
        Yields messages from _get_art_critique and returns a list of critique dictionaries.
        """
        yield {"type": "system", "content": " Art Critic Agent analyzing visual elements..."}

        all_art_critiques_results = []

        critique_context_prompt = (
            f"Original User Request (for overall context): {original_user_request}\n\n"
            f"Specific Art Critique Instruction from Planner: {art_critique_instruction}\n\n"
            f"Main Coder's relevant text output and implementation results (if any) will be provided by the system."
        )

        if not generated_image_paths:
            yield {"type": "system", "content": " Art Critic performing general visual analysis (no specific images provided/found)."}
            art_analysis_chunks = []
            full_art_analysis_single = ""
            try:
                for chunk_text in self._get_art_critique(
                    user_prompt=critique_context_prompt,
                    main_response=main_coder_output.get("text_response", ""),
                    implementation_results=main_coder_output.get("implementation_results", []),
                    target_image_path=None
                ):
                    art_analysis_chunks.append(chunk_text)
                    yield {"type": "agent_stream_chunk", "agent": " Art Critic (General)", "content": chunk_text}
                full_art_analysis_single = "".join(art_analysis_chunks)
                self._log_interaction("art_critic_general_analysis", full_art_analysis_single)
            except Exception as e:
                full_art_analysis_single = f"Error processing general art critique stream: {e}"
                self._log_interaction("art_critic_general_error", full_art_analysis_single)
                yield {"type": "error", "content": full_art_analysis_single}

            if full_art_analysis_single and not full_art_analysis_single.startswith("Error"):
                current_art_grade = self._extract_grade(full_art_analysis_single)
                all_art_critiques_results.append({
                    "image_path": "general_critique",
                    "critique_text": full_art_analysis_single,
                    "grade": current_art_grade
                })
            elif full_art_analysis_single:
                 yield {"type": "error", "content": f"General Art Critic failed: {full_art_analysis_single}"}
            elif not full_art_analysis_single:
                 yield {"type": "error", "content": "General Art Critic returned no analysis."}

        for i, image_path_str in enumerate(generated_image_paths):
            image_filename = os.path.basename(image_path_str)
            yield {"type": "system", "content": f" Art Critic evaluating image: {image_filename} ({i+1}/{len(generated_image_paths)})..."}

            art_analysis_chunks_single = []
            full_art_analysis_single = ""
            try:
                for chunk_text in self._get_art_critique(
                    user_prompt=critique_context_prompt,
                    main_response=main_coder_output.get("text_response", ""),
                    implementation_results=main_coder_output.get("implementation_results", []),
                    target_image_path=image_path_str
                ):
                    art_analysis_chunks_single.append(chunk_text)
                    yield {"type": "agent_stream_chunk", "agent": f" Art Critic ({image_filename})", "content": chunk_text}
                full_art_analysis_single = "".join(art_analysis_chunks_single)
                self._log_interaction(f"art_critic_analysis_{image_filename}", full_art_analysis_single)
            except Exception as e:
                full_art_analysis_single = f"Error processing art critique stream for {image_filename}: {e}"
                self._log_interaction(f"art_critic_error_{image_filename}", full_art_analysis_single)
                yield {"type": "error", "content": full_art_analysis_single}

            if full_art_analysis_single and not full_art_analysis_single.startswith("Error"):
                current_art_grade = self._extract_grade(full_art_analysis_single)
                all_art_critiques_results.append({
                    "image_path": image_path_str,
                    "critique_text": full_art_analysis_single,
                    "grade": current_art_grade
                })
            elif full_art_analysis_single:
                yield {"type": "error", "content": f"Art Critic failed for {image_filename}: {full_art_analysis_single}"}
            elif not full_art_analysis_single:
                yield {"type": "error", "content": f"Art Critic for {image_filename} returned no analysis."}

        return all_art_critiques_results

    def _handle_retry_and_finalization(self, original_user_prompt, current_main_coder_prompt_ref_for_retry, # Pass as a list to modify
                                       critic_grade, all_art_critiques, best_image_details,
                                       final_art_grade_for_overall_calc, generated_image_paths_batch,
                                       main_response_text, implementation_results): # Added main_response_text, implementation_results
        """Handles the retry logic, image trashing, and final messages."""
        perform_retry = False
        retry_reason_message = ""
        art_grade_display = final_art_grade_for_overall_calc if final_art_grade_for_overall_calc is not None else "N/A"
        overall_grade = self._calculate_overall_grade(critic_grade, final_art_grade_for_overall_calc)

        if self.grading_enabled and generated_image_paths_batch and any(cq.get('grade') is not None for cq in all_art_critiques):
            num_graded_batch_images = 0
            failing_batch_images_count = 0
            for critique_item in all_art_critiques:
                # Ensure image_path is a string for comparison with generated_image_paths_batch (which are strings)
                critique_image_path_str = str(critique_item.get('image_path'))
                if critique_image_path_str in generated_image_paths_batch and critique_item.get('grade') is not None:
                    num_graded_batch_images += 1
                    if critique_item.get('grade') < 70:
                        failing_batch_images_count += 1
            if num_graded_batch_images > 0 and num_graded_batch_images == failing_batch_images_count:
                perform_retry = True
                retry_reason_message = " None of the generated images met the passing grade (all < 70/100)."

        if not perform_retry and self.grading_enabled and (critic_grade is not None or final_art_grade_for_overall_calc is not None):
            if overall_grade is not None and overall_grade < 70:
                perform_retry = True
                retry_reason_message = f" Overall grade ({overall_grade}/100) is below 70."

        if self.grading_enabled and (critic_grade is not None or final_art_grade_for_overall_calc is not None):
            overall_grade_display = f"{overall_grade}/100" if overall_grade is not None else "N/A"
            yield {"type": "system", "content": f" Overall Grade: {overall_grade_display} (Code: {critic_grade or 'N/A'}, Art: {art_grade_display})"}

        if perform_retry and self.current_attempt < self.max_retry_attempts:
            yield {"type": "system", "content": f"{retry_reason_message} Requesting Main Coder to improve... (Attempt {self.current_attempt + 1}/{self.max_retry_attempts})"}
            art_critique_summary_for_retry = "No specific art critiques available for this attempt.\n"
            if all_art_critiques:
                art_critique_summary_for_retry = "Summary of Art Critiques (focus on best image if applicable):\n"
                if best_image_details:
                    art_critique_summary_for_retry += (f"Best Image ({os.path.basename(str(best_image_details['image_path']))}, "
                                                       f"Grade: {best_image_details['grade'] or 'N/A'}):\n"
                                                       f"{best_image_details['critique_text'][:400]}...\n\n")
                other_failing_critiques = [c for c in all_art_critiques if c.get('grade', 0) < 70 and c != best_image_details]
                if other_failing_critiques:
                    art_critique_summary_for_retry += "Other critiques for images needing improvement:\n"
                    for c_item in other_failing_critiques[:2]:
                        art_critique_summary_for_retry += f"- {os.path.basename(str(c_item['image_path']))} (Grade: {c_item['grade']}): {c_item['critique_text'][:200]}...\n"
                elif len(all_art_critiques) > 1 and best_image_details and best_image_details.get('grade', 0) >=70 :
                     art_critique_summary_for_retry += "The best image was acceptable, but other aspects of the request or code may need improvement if overall grade is low.\n"
                elif not best_image_details and all_art_critiques:
                    art_critique_summary_for_retry = "Multiple art critiques provided. Please review them in the chat history.\n"

            retry_intro = (f"RETRY (Original User Prompt: '{original_user_prompt}'):\n\n"
                           f"PREVIOUS ATTEMPT FEEDBACK:\n"
                           f"Code Critic Grade: {critic_grade or 'N/A'}\n"
                           f"Art Critic Best Image Grade: {art_grade_display}\n"
                           f"Overall Grade: {overall_grade_display}\n"
                           f"{retry_reason_message}\n\n"
                           f"Please improve the implementation based on the critique feedback above. "
                           f"Focus on addressing issues in both code and image generation (if applicable).\n\n"
                           f"Art Critiques Summary:\n{art_critique_summary_for_retry.strip()}")
            current_main_coder_prompt_ref_for_retry[0] = f"{retry_intro}\n\n{current_main_coder_prompt_ref_for_retry[0]}"
            return True

        elif perform_retry:
            overall_grade_display = f"{overall_grade}/100" if overall_grade is not None else "N/A"
            yield {"type": "system", "content": f" Maximum attempts reached. {retry_reason_message} Final overall grade: {overall_grade_display}"}
        elif self.grading_enabled and (critic_grade is not None or final_art_grade_for_overall_calc is not None) and (overall_grade is None or overall_grade >= 70):
            yield {"type": "system", "content": " Grade acceptable ({overall_grade}/100). Implementation approved!"}
        elif not self.grading_enabled:
            yield {"type": "system", "content": " Processing complete (grading disabled)."}
            for agent_status_msg_type in ["prompt_enhancer", "art_critic_proactive", "main_coder", "code_critic", "art_critic"]:
                yield {"type": "agent_status_update", "agent": agent_status_msg_type, "status": "inactive"}

        paths_to_trash_this_attempt = []
        if generated_image_paths_batch:
            best_image_path_final = str(best_image_details.get('image_path')) if best_image_details else None
            best_image_grade_final = best_image_details.get('grade', -1) if best_image_details else -1
            if perform_retry:
                paths_to_trash_this_attempt.extend(generated_image_paths_batch)
                yield {"type": "system", "content": f" Discarding all {len(generated_image_paths_batch)} images from this attempt due to retry."}
            else:
                if best_image_path_final and best_image_grade_final >= 70:
                    for img_path in generated_image_paths_batch:
                        if str(img_path) != best_image_path_final:
                            paths_to_trash_this_attempt.append(str(img_path))
                    if paths_to_trash_this_attempt:
                        yield {"type": "system", "content": f" Keeping best image '{os.path.basename(best_image_path_final)}'. Trashing {len(paths_to_trash_this_attempt)} other variants."}
                else:
                    paths_to_trash_this_attempt.extend(generated_image_paths_batch)
                    if generated_image_paths_batch:
                        yield {"type": "system", "content": f" No single best image met criteria on final attempt. Trashing all {len(generated_image_paths_batch)} generated images."}

        if paths_to_trash_this_attempt:
            unique_paths_to_trash = list(set(map(str, paths_to_trash_this_attempt))) # Ensure all are strings
            if unique_paths_to_trash:
                trash_path_display = Path(VM_DIR) / TRASH_DIR_NAME
                yield {"type": "system", "content": f" Moving {len(unique_paths_to_trash)} non-selected/failed image(s) to the '{trash_path_display}' folder..."}
                for log_msg in self._move_to_trash(unique_paths_to_trash):
                    yield {"type": "system", "content": log_msg}

        should_use_critic = self._should_invoke_code_critic(original_user_prompt, main_response_text, implementation_results)
        should_use_art_critic = self._should_invoke_art_critic(original_user_prompt, main_response_text, implementation_results)
        if (should_use_critic or should_use_art_critic) and self._needs_refinement(implementation_results):
            yield {"type": "system", "content": " Agents collaborating on final refinements..."}
            refinement_suggestions = self._get_collaborative_refinement()
            if refinement_suggestions:
                yield {"type": "agent", "agent": " Collaborative", "content": refinement_suggestions}

        yield {"type": "system", "content": " Multi-agent analysis complete!"}
        for agent_status_msg_type in ["prompt_enhancer", "art_critic_proactive", "main_coder", "code_critic", "art_critic"]:
             yield {"type": "agent_status_update", "agent": agent_status_msg_type, "status": "inactive"}
        return False

    def run_enhanced_interaction(self, original_user_prompt: str):
        """Enhanced multi-agent interaction with grading and retry system, now with Planner Agent."""
        if not self.client:
            yield {"type": "error", "content": "AI system not configured. Please set API key."}
            return

        self._log_to_memory("INTERACTION_START", f"Processing user prompt: '{original_user_prompt[:100]}...'", priority=6)

        # 1. Enhance the original prompt first (if enabled)
        enhanced_user_prompt = yield from self._handle_prompt_enhancement(original_user_prompt)

        # 2. Pass the (potentially) enhanced prompt to the planner
        plan_steps = self._get_plan_from_planner(enhanced_user_prompt, replan_context=None) # Initial plan request

        if not plan_steps:
            yield {"type": "error", "content": "Planner Agent failed to generate a plan. Falling back to default behavior."}
            # --- FALLBACK TO ORIGINAL WORKFLOW ---
            enhanced_user_prompt = yield from self._handle_prompt_enhancement(original_user_prompt) # Re-run enhancer for fallback
            # _handle_proactive_art_guidance expects the direct image request.
            # In fallback, this might be part of enhanced_user_prompt or original_user_prompt
            # This part of fallback might need more refinement if proactive art is critical here.
            proactive_art_advice = yield from self._handle_proactive_art_guidance(enhanced_user_prompt)
            current_main_coder_prompt = enhanced_user_prompt
            self.current_attempt = 0
            while self.current_attempt < self.max_retry_attempts:
                self.current_attempt += 1
                self._update_project_context()
                try:
                    main_coder_output = yield from self._execute_main_coder_phase(
                        coder_instruction=current_main_coder_prompt,
                        art_guidance=proactive_art_advice
                    )
                    
                    # Check if MainCoder phase itself triggered a replan (e.g., from an internal command)
                    if isinstance(main_coder_output, dict) and main_coder_output.get("replan_triggered"):
                        replan_reason = main_coder_output.get("reason", "MainCoder triggered replan during fallback execution.")
                        replan_agent_name = main_coder_output.get("agent_name", "MainCoder")
                        yield {"type": "replan_request", "reason": replan_reason, "agent_name": replan_agent_name} # Yield to UI
                        # Mimic replan by re-getting plan for fallback path, then breaking current attempt
                        yield {"type": "system", "content": " Main Coder triggered replan during fallback; interaction will restart or require new input."}
                        break # Exit the retry loop to let main loop finish, signalling done.


                    main_response_text = main_coder_output["text_response"]
                    implementation_results = main_coder_output["implementation_results"]
                    generated_image_paths_batch = main_coder_output["generated_image_paths"]

                    critic_grade = None
                    all_art_critiques = []
                    best_image_details = None
                    final_art_grade_for_overall_calc = None

                    if self._should_invoke_code_critic(original_user_prompt, main_response_text, implementation_results) and self.grading_enabled:
                        code_critique_results_fallback = yield from self._get_code_critique_results(
                            original_user_prompt, main_coder_output, "Review generated code from fallback."
                        )
                        critic_grade = code_critique_results_fallback.get("grade")

                    if generated_image_paths_batch and self._should_invoke_art_critic(original_user_prompt, main_response_text, implementation_results) and self.grading_enabled:
                         art_critique_results_fallback = yield from self._get_art_critique_results(
                             original_user_prompt, main_coder_output, "Review generated images from fallback.", generated_image_paths_batch
                         )
                         all_art_critiques = art_critique_results_fallback
                         if all_art_critiques:
                             best_grade = -1
                             for art_crit_item in all_art_critiques:
                                 if art_crit_item.get("grade", -1) is not None and art_crit_item.get("grade", -1) > best_grade:
                                     best_grade = art_crit_item.get("grade", -1)
                                     best_image_details = art_crit_item
                             if best_image_details:
                                final_art_grade_for_overall_calc = best_image_details.get("grade")

                    current_main_coder_prompt_list_for_retry = [enhanced_user_prompt]
                    should_retry = yield from self._handle_retry_and_finalization(
                        original_user_prompt, current_main_coder_prompt_list_for_retry,
                        critic_grade, all_art_critiques, best_image_details,
                        final_art_grade_for_overall_calc, generated_image_paths_batch,
                        main_response_text, implementation_results
                    )
                    current_main_coder_prompt = current_main_coder_prompt_list_for_retry[0]
                    if should_retry:
                        continue
                    else:
                        break
                except Exception as e:
                    error_msg = f"Enhanced Agent System Error (Fallback): {e}"
                    self.error_context.append(error_msg)
                    yield {"type": "error", "content": error_msg}
                    for agent_status_msg_type_fallback in ["prompt_enhancer", "art_critic_proactive", "main_coder", "code_critic", "art_critic"]:
                        yield {"type": "agent_status_update", "agent": agent_status_msg_type_fallback, "status": "inactive"}
                    break
            self._log_to_memory("INTERACTION_END", f"Finished processing user prompt (fallback path): '{original_user_prompt[:100]}...'", priority=7)
            return

        yield {"type": "system", "content": f" Planner generated {len(plan_steps)} steps. Starting execution..."}
        
        previous_step_output = None
        output_from_completed_step_for_maincoder: str | None = None

        i = 0 

        completed_normally = False
        replan_failed_to_get_new_steps = False

        while i < len(plan_steps):
            step = plan_steps[i]
            agent_name_from_plan = step.get('agent_name')
            instruction = step.get('instruction')
            is_final_step = step.get('is_final_step', False)

            if not agent_name_from_plan or not instruction:
                yield {"type": "error", "content": f"Planner returned an invalid step (missing agent_name or instruction): {step}. Skipping."}
                i += 1
                continue

            yield {"type": "system", "content": f" Executing Step {i+1}/{len(plan_steps)}: {agent_name_from_plan} - Task: '{instruction[:100]}{'...' if len(instruction) > 100 else ''}'"}
            
            step_output_data = None
            agent_name_for_status = ""
            if agent_name_from_plan == "MainCoder": agent_name_for_status = "main_coder"
            elif agent_name_from_plan == "CodeCritic": agent_name_for_status = "code_critic"
            elif agent_name_from_plan == "ArtCritic": agent_name_for_status = "art_critic"
            elif agent_name_from_plan == "PromptEnhancer": agent_name_for_status = "prompt_enhancer" # Corrected variable name
            elif agent_name_from_plan == "PlannerAgent": agent_name_for_status = "planner_agent_direct"
            elif agent_name_from_plan == "ProactiveArtAgent": agent_name_for_status = "art_critic_proactive"
            elif agent_name_from_plan == "PersonaAgent": agent_name_for_status = "persona_agent"
            else: agent_name_for_status = "unknown_agent"

            if agent_name_for_status not in ["unknown_agent", "planner_agent_direct", "persona_agent"]:
                yield {"type": "agent_status_update", "agent": agent_name_for_status, "status": "active"}

            replan_requested_this_step = False
            replan_reason = "" # Initialize outside try-except
            replan_triggering_agent = agent_name_from_plan # Assume current agent triggers replan, unless specific from command output

            try:
                input_for_current_step_from_previous = output_from_completed_step_for_maincoder

                if agent_name_from_plan == "PlannerAgent":
                    yield {"type": "agent", "agent": " Assistant", "content": instruction}
                    self._log_interaction("planner_direct_response", instruction)
                    step_output_data = instruction
                
                elif agent_name_from_plan == "PromptEnhancer":
                    if not self.prompt_enhancer_enabled:
                        yield {"type": "system", "content": " Skipping planned PromptEnhancer step as it's globally disabled. Using input as output."}
                        step_output_data = instruction
                        self._log_interaction("skipped_prompt_enhancer_step", f"Instruction for disabled enhancer: {instruction}")
                    else:
                        text_to_enhance = instruction
                        step_output_data = yield from self._handle_prompt_enhancement(text_to_enhance)

                elif agent_name_from_plan == "ProactiveArtAgent":
                    step_output_data = yield from self._handle_proactive_art_guidance(instruction)

                elif agent_name_from_plan == "PersonaAgent":
                    # For PersonaAgent, we pass the original user prompt for its final review.
                    # The instruction itself will contain the prompt if it's the final review step.
                    persona_agent_generator = self._execute_persona_agent_response(
                        instruction, plan_steps=plan_steps, current_step_index=i, original_user_prompt=original_user_prompt
                    )
                    returned_persona_data = None
                    try:
                        while True:
                            ui_message = next(persona_agent_generator)
                            yield ui_message
                    except StopIteration as e:
                        returned_persona_data = e.value # This will be {"status": "REPLAN_REQUESTED", ...} or the full_response_text

                    step_output_data = returned_persona_data

                    if isinstance(step_output_data, dict) and step_output_data.get("status") == "REPLAN_REQUESTED":
                        replan_requested_this_step = True
                        replan_reason = step_output_data.get("reason", "PersonaAgent requested replan due to vague task.")
                        replan_triggering_agent = "PersonaAgent" # Explicitly set for replan context
                        yield {"type": "replan_request", "reason": replan_reason, "agent_name": replan_triggering_agent} # Explicitly yield for UI/queue
                        # Clear step_output_data so it doesn't get processed as regular output for the next step.
                        step_output_data = None 
                    elif isinstance(step_output_data, dict) and step_output_data.get("status") == "ERROR":
                        # Error message already yielded by _execute_persona_agent_response
                        pass


                elif agent_name_from_plan == "MainCoder":
                    art_guidance_for_coder = None
                    if isinstance(input_for_current_step_from_previous, str) and \
                       ("artistic guidance" in input_for_current_step_from_previous.lower() or \
                        "art style" in input_for_current_step_from_previous.lower() or \
                        "mood and tone" in input_for_current_step_from_previous.lower()):
                        art_guidance_for_coder = input_for_current_step_from_previous

                    current_instruction_for_coder = instruction
                    if isinstance(previous_step_output, list) and previous_step_output and \
                       isinstance(previous_step_output[0], dict) and "critique_text" in previous_step_output[0] and \
                       "{ART_CRITIC_FEEDBACK_PLACEHOLDER}" in current_instruction_for_coder:
                        critique_text_to_inject = "".join(
                            f"Critique for '{art_crit_item.get('image_path', 'image')}':\n{art_crit_item['critique_text']}\n\n"
                            for art_crit_item in previous_step_output if art_crit_item.get("critique_text")
                        )
                        if critique_text_to_inject:
                            current_instruction_for_coder = current_instruction_for_coder.replace("{ART_CRITIC_FEEDBACK_PLACEHOLDER}", critique_text_to_inject.strip())
                            yield {"type": "system", "content": " Injected ArtCritic feedback into MainCoder instruction for refinement."}

                    # Add handling for CODE_CRITIC_FEEDBACK_PLACEHOLDER
                    if isinstance(previous_step_output, dict) and "critique_text" in previous_step_output and \
                       "{CODE_CRITIC_FEEDBACK_PLACEHOLDER}" in current_instruction_for_coder:
                        code_critique_text_to_inject = previous_step_output["critique_text"]
                        if code_critique_text_to_inject:
                            current_instruction_for_coder = current_instruction_for_coder.replace("{CODE_CRITIC_FEEDBACK_PLACEHOLDER}", code_critique_text_to_inject.strip())
                            yield {"type": "system", "content": " Injected CodeCritic feedback into MainCoder instruction for refinement."}

                    main_coder_phase_generator = self._execute_main_coder_phase(
                        coder_instruction=current_instruction_for_coder,
                        art_guidance=art_guidance_for_coder,
                        previous_step_direct_output=input_for_current_step_from_previous
                    )
                    returned_main_coder_data = None
                    try:
                        while True:
                            ui_message = next(main_coder_phase_generator)
                            if isinstance(ui_message, dict) and ui_message.get("type") == "replan_request":
                                # Catch replan request yielded by _execute_main_coder_phase
                                replan_requested_this_step = True
                                replan_reason = ui_message.get("reason", "MainCoder command initiated replan.")
                                replan_triggering_agent = ui_message.get("agent_name", "MainCoder") # Get actual triggering agent from command
                                yield ui_message # Yield the replan request dict to the UI/queue
                                break # Stop processing this generator, trigger outer replan logic
                            yield ui_message # Yield other messages (system, agent_stream_chunk, file_changed)
                    except StopIteration as e:
                        returned_main_coder_data = e.value # This will be the dict {text_response, implementation_results, ...}

                    # NEW LOGIC TO HANDLE REPLAN SIGNAL FROM AGENT EXECUTION PHASE
                    if isinstance(returned_main_coder_data, dict) and returned_main_coder_data.get("replan_triggered"):
                        replan_requested_this_step = True
                        replan_reason = returned_main_coder_data.get("reason", "Replan triggered by MainCoder execution phase.")
                        replan_triggering_agent = returned_main_coder_data.get("agent_name", "MainCoder")
                        # Ensure step_output_data is neutral for the next agent
                        step_output_data = None
                        # Yield a message to UI/queue about this specific replan trigger
                        yield {"type": "replan_request", "reason": replan_reason, "agent_name": replan_triggering_agent}
                    # END OF NEW LOGIC

                    # If a replan was triggered within the generator or by the new logic above,
                    # returned_main_coder_data might be None or already processed.
                    # The existing replan_requested_this_step flag will handle skipping further normal processing.
                    if replan_requested_this_step:
                        # If step_output_data was not already set to None by the new replan logic,
                        # ensure it's None to prevent passing replan signals as regular output.
                        if step_output_data is not None : # Check if it was already neutralized
                             step_output_data = None # Ensure no further processing of 'normal' output
                    elif returned_main_coder_data is None: # This case handles if _execute_main_coder_phase itself returns None
                        self.error_context.append("MainCoder phase failed to return data (returned None).")
                        step_output_data = {"error": "MainCoder phase failed to return data.", "implementation_results": [], "text_response": "", "generated_image_paths": []}
                    else: # This is the normal path if no replan was triggered yet by the execution phase itself
                        step_output_data = returned_main_coder_data

                        # Handle MainCoder's direct LLM text output ending with REQUEST_REPLAN:
                        # This is a secondary way a replan can be signaled, via text.
                        if not replan_requested_this_step and isinstance(step_output_data, dict) and "text_response" in step_output_data:
                            response_text = step_output_data["text_response"]
                            lines = response_text.strip().splitlines()
                            if lines and lines[-1].startswith("REQUEST_REPLAN:"):
                                replan_requested_this_step = True
                                replan_reason = lines[-1][len("REQUEST_REPLAN:"):] .strip()
                                replan_triggering_agent = "MainCoder" # Explicitly set for replan context
                                # Yield this as a structured message
                                yield {"type": "replan_request", "reason": replan_reason, "agent_name": replan_triggering_agent}
                                # Remove the REPLAN_REQUEST line from the text_response for the next step's context
                                if step_output_data and "text_response" in step_output_data: # Ensure step_output_data is not None
                                    step_output_data["text_response"] = "\n".join(lines[:-1]).strip()
                                # If step_output_data became None due to an earlier replan, this modification is skipped, which is fine.


                elif agent_name_from_plan == "CodeCritic":
                    input_for_code_critic = {}
                    if isinstance(previous_step_output, dict) and "text_response" in previous_step_output:
                        input_for_code_critic = previous_step_output
                    else:
                        # previous_step_output is not a dict or doesn't have "text_response"
                        # Use output_from_completed_step_for_maincoder for text_response
                        input_for_code_critic["text_response"] = output_from_completed_step_for_maincoder
                        input_for_code_critic["implementation_results"] = [] # Set to empty list as per requirement

                    if "text_response" in input_for_code_critic and input_for_code_critic["text_response"] is not None:
                        step_output_data = yield from self._get_code_critique_results(
                            original_user_prompt, input_for_code_critic, instruction
                        )
                    else:
                        yield {"type": "error", "content": "CodeCritic called without valid text_response for analysis."}
                        step_output_data = {"error": "Missing valid text_response for CodeCritic."}

                elif agent_name_from_plan == "ArtCritic":
                    if isinstance(previous_step_output, dict):
                        images_to_critique = previous_step_output.get("generated_image_paths", [])
                        step_output_data = yield from self._get_art_critique_results(
                            original_user_prompt, previous_step_output, instruction, images_to_critique
                        )
                    else:
                        yield {"type": "error", "content": "ArtCritic called without valid MainCoder output from previous step."}
                        step_output_data = {"error": "Missing valid input for ArtCritic."}
                
                else:
                    yield {"type": "error", "content": f"Unknown agent in plan: {agent_name_from_plan}. Skipping step."}
                    step_output_data = f"Error: Unknown agent {agent_name_from_plan}"

                if replan_requested_this_step:
                    yield {"type": "system", "content": f" Agent {replan_triggering_agent} requested a re-plan. Reason: {replan_reason}. Initiating new planning cycle..."}
                    
                    # Call get_plan_from_planner with replan_context
                    new_plan_steps = self._get_plan_from_planner(
                        original_user_prompt,
                        replan_context={"reason": replan_reason, "agent_name": replan_triggering_agent}
                    )
                    
                    if agent_name_for_status not in ["unknown_agent", "planner_agent_direct", "persona_agent"]:
                        yield {"type": "agent_status_update", "agent": agent_name_for_status, "status": "inactive"}
                    if new_plan_steps:
                        yield {"type": "system", "content": f" New plan received with {len(new_plan_steps)} steps. Restarting execution..."}
                        plan_steps = new_plan_steps
                        i = 0
                        previous_step_output = None
                        output_from_completed_step_for_maincoder = None
                        completed_normally = False
                        replan_failed_to_get_new_steps = False
                        continue # Restart the while loop with the new plan
                    else:
                        yield {"type": "error", "content": "Planner failed to generate a new plan after re-plan request. Stopping."}
                        replan_failed_to_get_new_steps = True
                        completed_normally = False
                        break # Exit the while loop due to critical planning failure

                if agent_name_for_status not in ["unknown_agent", "planner_agent_direct", "persona_agent"]:
                    yield {"type": "agent_status_update", "agent": agent_name_for_status, "status": "inactive"}

                previous_step_output = step_output_data
                output_from_completed_step_for_maincoder = None

                # New logic to extract stdout for specific run_command outputs
                extracted_stdout_for_next_step = None
                main_coder_instruction = step.get('instruction', "").lower() # instruction for the MainCoder step

                direct_output_commands = ["run_command('cat ", "run_command('type ", "run_command('ls ", "run_command('dir "]
                was_direct_output_command = any(cmd_prefix in main_coder_instruction for cmd_prefix in direct_output_commands)

                if agent_name_from_plan == "MainCoder" and was_direct_output_command and isinstance(step_output_data, dict):
                    # Attempt to find the command executed by MainCoder to match its output
                    # This is a simplified way to get the command string from the instruction.
                    # A more robust regex might be needed if instructions get very complex.
                    cmd_match = re.search(r"run_command\(['\"](.*?)['\"]\)", step.get('instruction', ""))
                    command_executed_by_main_coder_str = cmd_match.group(1) if cmd_match else "dummy_command_string_to_avoid_none"

                    for result_item in step_output_data.get("implementation_results", []):
                        if result_item.get("type") == "system" and isinstance(result_item.get("content"), str):
                            content_str = result_item.get("content", "")
                            # Check if this result_item is for the command we are interested in
                            if f" Command: {command_executed_by_main_coder_str}" in content_str or \
                               (command_executed_by_main_coder_str == "dummy_command_string_to_avoid_none" and \
                                any(cmd_prefix.split('(')[1].replace("'","") in content_str for cmd_prefix in direct_output_commands) ): # Fallback if regex fails

                                stdout_marker = " STDOUT:\n"
                                if stdout_marker in content_str:
                                    stdout_start_index = content_str.find(stdout_marker) + len(stdout_marker)

                                    # Determine end of stdout
                                    stderr_marker = "\n STDERR:"
                                    success_marker = "\n Command completed successfully"

                                    end_index_stderr = content_str.find(stderr_marker, stdout_start_index)
                                    end_index_success = content_str.find(success_marker, stdout_start_index)

                                    if end_index_stderr != -1 and end_index_success != -1:
                                        end_index = min(end_index_stderr, end_index_success)
                                    elif end_index_stderr != -1:
                                        end_index = end_index_stderr
                                    elif end_index_success != -1:
                                        end_index = end_index_success
                                    else:
                                        # If neither marker is found, take the rest of the string,
                                        # but try to strip common command output footers if they are at the very end
                                        temp_stdout = content_str[stdout_start_index:].strip()
                                        common_footers = [
                                            "Command completed successfully",
                                            "command completed successfully" # case variations
                                        ]
                                        # This footer stripping is basic; a more robust solution might be needed
                                        # if footers are complex or vary significantly.
                                        # For now, we'll assume stdout is the bulk of the remaining content.
                                        # This part is tricky because STDOUT itself might be empty.
                                        end_index = len(content_str) # Default to end of string.

                                    extracted_stdout_for_next_step = content_str[stdout_start_index:end_index].strip()
                                    # If STDOUT was truly empty, extracted_stdout_for_next_step will be empty string here.
                                    # If it only contained newlines, strip() handles it.
                                    break # Found the relevant stdout

                if extracted_stdout_for_next_step is not None: # This includes empty string if stdout was empty
                    output_from_completed_step_for_maincoder = extracted_stdout_for_next_step
                elif isinstance(previous_step_output, dict): # Fallback to existing logic
                    if previous_step_output.get("type") == "system" and isinstance(previous_step_output.get("content"), str):
                        output_from_completed_step_for_maincoder = previous_step_output.get("content")
                    elif previous_step_output.get("type") == "agent" and previous_step_output.get("agent") == " Assistant" and isinstance(previous_step_output.get("content"), str):
                        output_from_completed_step_for_maincoder = previous_step_output.get("content")
                    elif "text_response" in previous_step_output and isinstance(previous_step_output["text_response"], str):
                        output_from_completed_step_for_maincoder = previous_step_output["text_response"]
                elif isinstance(previous_step_output, str):
                    output_from_completed_step_for_maincoder = previous_step_output

                if is_final_step:
                     yield {"type": "system", "content": f" Final step ({agent_name_from_plan}) completed."}
                     completed_normally = True

            except Exception as e:
                if agent_name_for_status not in ["unknown_agent", "planner_agent_direct", "persona_agent"]:
                    yield {"type": "agent_status_update", "agent": agent_name_for_status, "status": "inactive"}
                error_msg = f"Error during step execution ({agent_name_from_plan}): {type(e).__name__} - {str(e)}\\nFull Traceback:\\n{traceback.format_exc()}"
                self.error_context.append(error_msg)
                yield {"type": "error", "content": error_msg}
                previous_step_output = {"error": error_msg}
                self._log_interaction("run_interaction_error_traceback", traceback.format_exc())
                break # Exit the while loop on error

            i += 1

        if completed_normally:
            self._log_to_memory("INTERACTION_END", f"Finished processing user prompt (plan complete): '{original_user_prompt[:100]}...'", priority=7)
            yield {"type": "system", "content": " Planner execution complete for the current request."}
        elif replan_failed_to_get_new_steps:
            self._log_to_memory("INTERACTION_END", f"Finished processing user prompt (replan failed): '{original_user_prompt[:100]}...'", priority=7)
            yield {"type": "system", "content": " Planner execution stopped: Failed to generate a new plan after re-plan request."}
        elif i < len(plan_steps):
            self._log_to_memory("INTERACTION_END", f"Finished processing user prompt (error in step {i+1}): '{original_user_prompt[:100]}...'", priority=7)
            yield {"type": "system", "content": f" Planner execution stopped due to an error in step {i+1}."}
        else: # Should ideally not be reached if completed_normally or explicit break was hit
            self._log_to_memory("INTERACTION_END", f"Finished processing user prompt (concluded by implicit end): '{original_user_prompt[:100]}...'", priority=7)
            yield {"type": "system", "content": " Planner execution concluded for the current request (no errors, no final step indicated, or loop ended unexpectedly)."}


    def _get_code_critique(self, user_prompt, main_response, implementation_results):
        """Get enhanced code critique"""
        critique_context = f"""
ORIGINAL REQUEST: {user_prompt}

MAIN CODER IMPLEMENTATION: {main_response}

IMPLEMENTATION RESULTS: {self._format_results(implementation_results)}

PROJECT CONTEXT: {self._get_project_summary()}

Please provide a comprehensive code review focusing on quality, security, performance, and best practices.
"""
        
        try:
            response_stream = self.client.models.generate_content_stream(
                model=TEXT_MODEL_NAME,
                contents=[{"text": f"{CRITIC_AGENT_PROMPT}\n\n{critique_context}"}]
            )
            for chunk in response_stream:
                yield chunk.text
        except Exception as e:
            self.error_context.append(f"Code Critic Error: {e}")
            yield f"Error generating code critique: {e}"

    def _get_art_critique(self, user_prompt, main_response, implementation_results, target_image_path=None):
        """Get enhanced art critique with vision capabilities, focusing on a target image if provided."""
        critique_focus_text = ""
        if target_image_path:
            # target_image_path is already relative to VM_DIR for storage by MainCoder
            rel_target_image_path = target_image_path

            critique_focus_text = f"""
YOU ARE CRITIQUING THIS SPECIFIC IMAGE: {rel_target_image_path}

Please analyze THIS SPECIFIC IMAGE ({rel_target_image_path}) for visual elements, design guidance, and suggest improvements.
All other images in the VISUAL CONTEXT section below are for reference or comparison if needed.
"""

        art_context_text = f"""
ORIGINAL REQUEST: {user_prompt}

MAIN CODER IMPLEMENTATION (may include multiple image generation commands):
{main_response}

IMPLEMENTATION RESULTS (shows files created, including possibly multiple images):
{self._format_results(implementation_results)}
{critique_focus_text}
Please analyze visual elements, provide design guidance, and suggest improvements for better aesthetics and user experience.
"""
        art_context_parts = self._build_visual_context(art_context_text, ART_AGENT_PROMPT)
        
        try:
            response_stream = self.client.models.generate_content_stream(
                model=TEXT_MODEL_NAME,
                contents=art_context_parts
            )
            for chunk in response_stream:
                yield chunk.text
        except Exception as e:
            self.error_context.append(f"Art Critic Error: {e}")
            yield f"Error generating art critique: {e}"

    def _get_proactive_art_guidance(self, current_user_prompt):
        """Get proactive art guidance before image generation."""
        try:
            context_text = f"USER REQUEST FOR NEW IMAGE:\\n{current_user_prompt}"
            formatted_proactive_prompt = PROACTIVE_ART_AGENT_PROMPT.replace("{{USER_REQUEST}}", current_user_prompt)
            proactive_art_context_parts = self._build_visual_context(
                context_text=context_text,
                system_prompt=formatted_proactive_prompt
            )

            response_stream = self.client.models.generate_content_stream(
                model=TEXT_MODEL_NAME,
                contents=proactive_art_context_parts
            )
            full_response_text = ""
            for chunk in response_stream:
                if chunk.text:
                    full_response_text += chunk.text
                    yield chunk.text
            self._log_interaction("proactive_art_critic", full_response_text)
        except Exception as e:
            self.error_context.append(f"Proactive Art Critic Error: {e}")
            yield f"Error generating proactive art guidance: {e}"


    def _move_to_trash(self, image_paths_to_move):
        """Moves specified image paths to the .trash directory within VM_DIR."""
        messages = []
        trash_dir = VM_DIR / TRASH_DIR_NAME
        try:
            trash_dir.mkdir(parents=True, exist_ok=True)
        except Exception as e:
            messages.append(f" Error creating trash directory {trash_dir}: {e}")
            return messages

        for img_path_str in image_paths_to_move:
            try:
                # Ensure source_path is resolved relative to VM_DIR first
                source_path = self._safe_path(img_path_str)
                
                if not source_path or not source_path.exists():
                    messages.append(f" File not found, cannot trash: '{img_path_str}'.")
                    continue
                if not source_path.is_file(): # Only files are expected for this function
                    messages.append(f" Path is not a file, cannot trash with _move_to_trash: '{img_path_str}'.")
                    continue

                dest_name_in_trash = source_path.name
                destination_in_trash = trash_dir / dest_name_in_trash

                # To prevent overwriting in trash, append a timestamp if it already exists
                counter = 0
                original_destination_name = destination_in_trash.name
                while destination_in_trash.exists():
                    counter += 1
                    timestamp = datetime.now().strftime("%Y%m%d%H%M%S")
                    name_body = Path(original_destination_name).stem
                    suffix = Path(original_destination_name).suffix
                    new_name = f"{name_body}.{timestamp}_{counter}{suffix}"
                    destination_in_trash = trash_dir / new_name

                shutil.move(str(source_path), str(destination_in_trash))
                messages.append(f" Moved '{source_path.name}' to '{TRASH_DIR_NAME}/' (as '{destination_in_trash.name}').")
            except Exception as e:
                messages.append(f" Error moving '{img_path_str}' to trash: {e}")
        return messages

    def _get_collaborative_refinement(self):
        """Get collaborative refinement suggestions"""
        if len(self.conversation_history) < 3:
            return None
            
        refinement_context = f"""
Based on the recent multi-agent analysis, provide collaborative refinement suggestions that combine:
1. Technical implementation improvements
2. Code quality enhancements  
3. Visual and UX improvements

Recent conversation:
{self._get_recent_conversation_summary()}

Focus on actionable improvements that leverage all three agent perspectives.
"""
        
        try:
            response = self.client.models.generate_content(
                model=TEXT_MODEL_NAME,
                contents=[{"text": refinement_context}]
            )
            return response.text
        except Exception as e:
            return None

    def _update_project_context(self):
        """Update project context for better agent awareness, using caching."""
        if self.project_files_changed or self.project_files_cache is None:
            self.file_snippet_cache.clear()
            current_files = self._scan_project_files()
            current_images = self._scan_project_images()
            self.project_files_cache = {
                "files": current_files,
                "images": current_images,
                "timestamp": time.time()
            }
            self.project_files_changed = False
            existing_recent_changes = self.project_context.get("recent_changes", [])
            self.project_context = {
                "files": current_files,
                "images": current_images,
                "recent_changes": existing_recent_changes
            }
        else:
            self.project_context["files"] = self.project_files_cache["files"]
            self.project_context["images"] = self.project_files_cache["images"]
            if "recent_changes" not in self.project_context:
                 self.project_context["recent_changes"] = []

    def _build_enhanced_prompt(self, user_prompt, system_prompt, proactive_art_advice=None, current_plan_summary: str | None = None, project_files_summary: str | None = None, recent_changes_summary: str | None = None, error_log_summary: str | None = None, memory_context_str: str | None = None, previous_step_direct_output: str | None = None, full_conversation_history: list[ChatMessage] | None = None):
        """Build enhanced prompt with comprehensive context"""
        current_time_str = datetime.now().strftime("%Y-%m-%d %H:%M:%S")

        base_context_text = f"{system_prompt}\n\n**CURRENT TIME:**\n{current_time_str}\n\n"

        if hasattr(self, 'user_preferences') and self.user_preferences:
            preferences_text = "\\n".join([f"- {key}: {value}" for key, value in self.user_preferences.items()])
            base_context_text += f"**USER PREFERENCES:** (These are read-only in this view. Use commands to set/get specific preferences during tasks.)\\n{preferences_text}\\n\\n"

        if recent_changes_summary:
            base_context_text += f"**RECENT SYSTEM ACTIONS (LOG):**\\n{recent_changes_summary}\\n\\n"
        if error_log_summary:
            base_context_text += f"**RECENT ERRORS (LOG):**\\n{error_log_summary}\\n\\n"

        if current_plan_summary:
            base_context_text += f"**CURRENT PLAN STATUS:**\\n{current_plan_summary}\\n\\n"

        if memory_context_str:
            base_context_text += f"**RECENT MEMORIES (from memory.txt):**\\n{memory_context_str}\\n\\n"

        if previous_step_direct_output and isinstance(previous_step_direct_output, str) and previous_step_direct_output.strip():
            base_context_text += f"**INPUT FROM PREVIOUS STEP (Use for current task):**\\n{previous_step_direct_output}\\n\\n"

        base_context_text += "**PROJECT STATUS:**\\n"

        prompt_parts = [{"text": base_context_text}]

        if proactive_art_advice:
             prompt_parts.append({"text": f"\\n**PROACTIVE ART GUIDANCE:**\\n{proactive_art_advice}\\n"})

        if VM_DIR.exists():
            for root, dirs, files in os.walk(VM_DIR):
                if TRASH_DIR_NAME in dirs:
                    dirs.remove(TRASH_DIR_NAME)
                for name in sorted(files):
                    file_path = Path(root) / name
                    # Ensure path is relative to VM_DIR for display to agent
                    try:
                        rel_path = file_path.relative_to(VM_DIR)
                    except ValueError: # file_path is not under VM_DIR, skip it.
                        continue

                    try:
                        if name.lower().endswith(('.png', '.jpg', '.jpeg', '.gif', '.bmp')):
                            try:
                                img = Image.open(file_path)
                                prompt_parts.append({"text": f"\\n--- IMAGE: {rel_path} ---\\n"})
                                prompt_parts.append(img)
                            except Exception:
                                prompt_parts.append({"text": f"\\n--- IMAGE ERROR: {rel_path} ---\\n"})
                        else:
                            content_snippet = ""
                            try:
                                current_mtime = file_path.stat().st_mtime
                                if str(rel_path) in self.file_snippet_cache: # Use string for cache key
                                    snippet_data = self.file_snippet_cache[str(rel_path)]
                                    if current_mtime == snippet_data.mtime:
                                        content_snippet = snippet_data.content
                                    else: # mtime changed, so re-read and update cache
                                        with open(file_path, "r", encoding="utf-8", errors="ignore") as f:
                                            content_snippet = f.read(3000)
                                        self.file_snippet_cache[str(rel_path)] = FileSnippet(mtime=current_mtime, content=content_snippet)
                                else: # Not in cache, read and add
                                    with open(file_path, "r", encoding="utf-8", errors="ignore") as f:
                                        content_snippet = f.read(3000)
                                    self.file_snippet_cache[str(rel_path)] = FileSnippet(mtime=current_mtime, content=content_snippet)
                            except OSError:
                                content_snippet = "[Error reading file content]"
                            prompt_parts.append({"text": f"\\n--- FILE: {rel_path} ---\\n{content_snippet}\\n"})
                    except IOError:
                        prompt_parts.append({"text": f"\\n--- FILE/IMAGE ERROR (IOError): {rel_path} ---\\n"})
                        continue
        prompt_parts.append({"text": "\\n**CONVERSATION HISTORY:**\\n"})
        
        # Use full_conversation_history if provided, otherwise default to a slice of self.conversation_history
        conv_history_to_use = full_conversation_history if full_conversation_history is not None else self.conversation_history[-8:]
        
        for entry in conv_history_to_use:
            role = entry.role.replace("_", " ").title() # Access as attribute
            content = entry.content[:300] + "..." if len(entry.content) > 300 else entry.content # Access as attribute
            prompt_parts.append({"text": f"{role}: {content}\\n\\n"})
        
        if self.error_context:
            prompt_parts.append({"text": f"\\n**RECENT ERRORS:**\\n{chr(10).join(self.error_context[-3:])}\\n"})
        prompt_parts.append({"text": f"\\n**USER REQUEST:**\\n{user_prompt}"})
        return prompt_parts

    def _execute_persona_agent_response(self, instruction: str, plan_steps: list | None = None, current_step_index: int | None = None, original_user_prompt: str | None = None):
        self._update_project_context()
        memory_for_persona = self._get_memory_context(last_n_entries=50) # Persona gets more memory
        yield {"type": "system", "content": f" Persona Agent responding to: {instruction}"}

        # Check if the instruction is a generic "clarify" type that could be resolved by file listing
        vague_keywords_for_internal_lookup = [
            "provide more details about your game",
            "provide more details about your app",
            "what kind of app is it",
            "what kind of game is it",
            "what specific aspects do you want to improve",
            "are there any specific files",
            "fix my code",
            "debug my code",
            "improve my code",
            "enhance my project"
        ]
        
        # Check if the instruction from the Planner to PersonaAgent matches a pattern
        # where PersonaAgent should suggest MainCoder lists files.
        instruction_lower = instruction.lower()
        should_replan_for_file_listing = False
        
        # Check if it's the final review step first
        is_final_review_step = original_user_prompt is not None and instruction.startswith(f"Review the completion of the original user request: '{original_user_prompt}'.")

        if not is_final_review_step:
            for keyword in vague_keywords_for_internal_lookup:
                if keyword in instruction_lower:
                    # Add a check that it's actually asking for *more details* generally
                    # and not already in a specific file context
                    if "could you please provide more details" in instruction_lower or "is a bit general" in instruction_lower:
                        should_replan_for_file_listing = True
                        break

            if should_replan_for_file_listing:
                replan_reason = "The Planner's instruction to clarify a vague request implicitly requires listing project files. MainCoder should use 'list_directory_contents()' to identify relevant project files before proceeding."
                # Return the replan signal directly, do not yield chat chunks
                return {"status": "REPLAN_REQUESTED", "reason": replan_reason}


        # Gather Project Files Summary
        files_summary_str = "No file data available."
        if hasattr(self, 'project_context'):
            all_files = self.project_context.get("files", [])
            all_images = self.project_context.get("images", [])

            file_count = len(all_files)
            image_count = len(all_images)

            py_files = len([f for f in all_files if f.endswith('.py')])
            txt_files = len([f for f in all_files if f.endswith('.txt')])
            other_code_files = len([f for f in all_files if not f.endswith(('.py', '.txt')) and '.' in f])


            files_summary_str = f"Project Overview: {file_count} code/text file(s) (e.g., {py_files} Python, {txt_files} text, {other_code_files} other), {image_count} image(s)."

        # Gather Recent Changes Summary
        recent_changes_summary_str = self._get_recent_changes_summary(as_string_for_planner=False)

        # Gather Error Log Summary
        error_log_summary_str = "No recent errors logged."
        if self.error_context:
            errors_to_show = self.error_context[-2:]
            formatted_errors = [f"- {str(err)[:150]}" for err in errors_to_show]
            if formatted_errors:
                error_log_summary_str = f"Recent system errors ({len(self.error_context)} total):\\n" + "\\n".join(formatted_errors)

        plan_summary_for_persona = None
        if plan_steps and current_step_index is not None:
            num_total_steps = len(plan_steps)
            current_step_details = plan_steps[current_step_index]
            summary_lines = [
                f"I am currently executing a plan with {num_total_steps} step(s).",
                f"We are on step {current_step_index + 1} of {num_total_steps}: Agent '{current_step_details.get('agent_name')}' is tasked with: '{str(current_step_details.get('instruction','N/A'))[:100]}{'...' if len(str(current_step_details.get('instruction','N/A'))) > 100 else ''}'."
            ]
            if current_step_index + 1 < num_total_steps:
                next_step_details = plan_steps[current_step_index + 1]
                summary_lines.append(f"The next step involves agent '{next_step_details.get('agent_name')}' to work on: '{str(next_step_details.get('instruction','N/A'))[:100]}{'...' if len(str(next_step_details.get('instruction','N/A'))) > 100 else ''}'.")
            else:
                summary_lines.append("This is the final step in the current plan.")
            plan_summary_for_persona = "\\n".join(summary_lines)

        persona_prompt_parts = self._build_enhanced_prompt(
            user_prompt=instruction, # Instruction from planner is the user_prompt for PersonaAgent
            system_prompt=PERSONA_AGENT_PROMPT,
            current_plan_summary=plan_summary_for_persona,
            project_files_summary=files_summary_str,
            recent_changes_summary=recent_changes_summary_str,
            error_log_summary=error_log_summary_str,
            memory_context_str=memory_for_persona,
            full_conversation_history=self.conversation_history # Pass the entire history
        )

        self._log_interaction("persona_agent_input_instruction", instruction)

        full_response_text = ""
        collected_chunks = []
        try:
            response_stream = self.client.models.generate_content_stream(
                model=TEXT_MODEL_NAME,
                contents=persona_prompt_parts
            )
            for chunk in response_stream:
                if chunk.text:
                    full_response_text += chunk.text
                    collected_chunks.append(chunk.text)

            self._log_interaction("persona_agent_full_response", full_response_text)

            lines = full_response_text.strip().splitlines()
            last_non_empty_line = None
            last_non_empty_line_index = -1

            for i in range(len(lines) - 1, -1, -1):
                if lines[i].strip():
                    last_non_empty_line = lines[i].strip()
                    last_non_empty_line_index = i
                    break

            if last_non_empty_line and last_non_empty_line.startswith("REQUEST_REPLAN:"):
                replan_reason = last_non_empty_line[len("REQUEST_REPLAN:"):] .strip()

                text_before_replan_lines = lines[:last_non_empty_line_index]
                text_before_replan = "\n".join(text_before_replan_lines).strip()

                if text_before_replan:
                    # Yield the preceding content.
                    # Assuming 'collected_chunks' might not perfectly map to 'text_before_replan'
                    # after splitting/joining, we yield 'text_before_replan' as a single unit.
                    yield {"type": "agent_stream_chunk", "agent": " Persona Agent", "content": text_before_replan + "\n"}

                return {"status": "REPLAN_REQUESTED", "reason": replan_reason}
            else:
                # If not a replan request, yield all collected chunks (which form full_response_text)
                if not collected_chunks:
                    collected_chunks = [full_response_text] # Fallback

                for chunk in collected_chunks:
                    if chunk:
                        yield {"type": "agent_stream_chunk", "agent": " Persona Agent", "content": chunk}
                return full_response_text

        except Exception as e:
            error_msg = f"Persona Agent LLM Error: {e}"
            self.error_context.append(error_msg)
            self._log_interaction("persona_agent_error", error_msg)
            yield {"type": "error", "content": error_msg}
            yield {"type": "agent_stream_chunk", "agent": " Persona Agent", "content": "I encountered an issue trying to process that. Please try again."}
            # Return an error status to indicate failure to run_enhanced_interaction
            return {"status": "ERROR", "reason": error_msg}

    def _build_visual_context(self, context_text, system_prompt):
        """Build visual context for art critic with all images"""
        context_parts = [{"text": f"{system_prompt}\\n\\n{context_text}\\n\\n**VISUAL CONTEXT:**\\n"}]
        if VM_DIR.exists():
            image_count = 0
            for root, dirs, files in os.walk(VM_DIR):
                if TRASH_DIR_NAME in dirs:
                    dirs.remove(TRASH_DIR_NAME)
                for name in files:
                    file_path = Path(root) / name
                    if name.lower().endswith(('.png', '.jpg', '.jpeg', '.gif', '.bmp')):
                        # Ensure rel_path is calculated correctly relative to VM_DIR for display
                        try:
                            rel_path = file_path.relative_to(VM_DIR)
                        except ValueError: # Not in VM_DIR, skip
                            continue

                        try:
                            img = Image.open(file_path)
                            context_parts.append({"text": f"\\n--- ANALYZING IMAGE: {rel_path} ---\\n"})
                            context_parts.append(img)
                            image_count += 1
                        except Exception:
                            continue
            if image_count == 0:
                context_parts.append({"text": "No images found in project.\\n"})
        return context_parts

    def _should_invoke_code_critic(self, user_prompt, main_response, implementation_results):
        """Smart detection for when Code Critic is actually needed"""
        simple_commands = [
            'run', 'start', 'execute', 'launch', 'install', 'update', 'pip install',
            'npm install', 'serve', 'host', 'deploy', 'build', 'compile'
        ]
        prompt_lower = user_prompt.lower()
        if any(cmd in prompt_lower and len(prompt_lower.split()) <= 4 for cmd in simple_commands):
            return False
        code_creation_indicators = [
            'create_file', 'write_to_file', 'function', 'class', 'algorithm',
            'implement', 'refactor', 'optimize', 'fix bug', 'debug', 'security',
            'performance', 'review code', 'analyze code'
        ]
        text_to_check = f"{user_prompt} {main_response}".lower()
        has_code_work = any(indicator in text_to_check for indicator in code_creation_indicators)
        has_file_changes = any(result.get("type") == "system" and 
                              any(op in result.get("content", "") for op in ["Created file", "Updated file"])
                              for result in implementation_results)
        return has_code_work and has_file_changes

    def _should_invoke_art_critic(self, user_prompt, main_response, implementation_results, mode="reactive"):
        """Smart detection for when Art Critic is actually needed, with proactive/reactive modes."""
        prompt_lower = user_prompt.lower()
        if mode == "proactive":
            proactive_visual_keywords = [
                'generate image', 'create image', 'make image', 'draw image',
                'generate logo', 'create logo', 'design logo',
                'generate banner', 'create banner', 'design banner',
                'generate icon', 'create icon', 'design icon',
                'generate picture', 'create picture',
                'new art for', 'visual asset for', 'generate art for'
            ]
            if any(keyword in prompt_lower for keyword in proactive_visual_keywords):
                return True
            return False
        simple_commands = [
            'run', 'start', 'execute', 'launch', 'install', 'update', 'serve'
        ]
        explicit_visual_analysis = any(phrase in prompt_lower for phrase in [
            'analyze image', 'review design', 'visual feedback', 'art critique',
            'design review', 'improve visuals'
        ])
        if explicit_visual_analysis:
            return True
        if any(cmd in prompt_lower and len(prompt_lower.split()) <= 4 for cmd in simple_commands):
            if not any(vis_cmd in prompt_lower for vis_cmd in ['image', 'visual', 'art', 'design', 'graphic']):
                return False
        visual_work_indicators = [
            'generate_image', 'create image', 'design', 'visual', 'ui', 'interface',
            'color', 'layout', 'style', 'aesthetic', 'art', 'graphic', 'icon',
            'logo', 'banner', 'picture', 'photo'
        ]
        text_to_check = f"{user_prompt} {main_response}".lower()
        has_visual_work = any(indicator in text_to_check for indicator in visual_work_indicators)
        has_image_changes = any(result.get("type") == "file_changed" and 
                               result.get("content", "").lower().endswith(('.png', '.jpg', '.jpeg', '.gif', '.bmp'))
                               for result in implementation_results)
        return has_visual_work or has_image_changes

    def _needs_refinement(self, implementation_results):
        """Determine if refinement is needed based on results"""
        error_count = sum(1 for result in implementation_results if result.get("type") == "error")
        complex_operations = sum(1 for result in implementation_results 
                               if result.get("type") == "system" and 
                               any(op in result.get("content", "") for op in ["Created file", "Updated file", "Generated"]))
        return error_count > 0 or complex_operations > 2

    def _has_project_images(self):
        """Check if project contains images, using cached context if available."""
        if self.project_context and "images" in self.project_context:
            if self.project_files_cache and self.project_context["images"] is not None:
                return bool(self.project_context["images"])
        if not VM_DIR.exists():
            return False
        for root, dirs, files in os.walk(VM_DIR):
            if TRASH_DIR_NAME in dirs:
                dirs.remove(TRASH_DIR_NAME)
            for name in files:
                if name.lower().endswith(('.png', '.jpg', '.jpeg', '.gif', '.bmp')):
                    return True
        return False

    def _process_enhanced_commands(self, response_text):
        """Enhanced command processing with a more specific regex, pre-checks, and detailed error logging."""
        command_pattern = re.compile(r'`\s*([a-zA-Z_][\w\.]*\s*\(.*?\))\s*`', re.DOTALL)
        matches = command_pattern.finditer(response_text)
        for match in matches:
            command_str = match.group(1).strip()
            if not command_str:
                continue
            if not any(command_str.startswith(known_cmd + "(") for known_cmd in self.command_handlers.keys()):
                yield {"type": "system", "content": f" Note: Ignoring potential command-like text: `{command_str[:100]}{'...' if len(command_str) > 100 else ''}`"}
                continue
            try:
                parsed_expr = ast.parse(command_str, mode="eval")
                call_node = parsed_expr.body
                if not isinstance(call_node, ast.Call):
                    self.error_context.append(f"Command parsing error: Not a function call - '{command_str}'")
                    yield {"type": "error", "content": f" Command error: Not a function call - `{command_str}`"}
                    continue

                if not isinstance(call_node.func, ast.Name):
                    self.error_context.append(f"Command parsing error: Not a direct function name - '{command_str}'")
                    yield {"type": "error", "content": f" Command error: Not a direct function name - `{command_str}`"}
                    continue

                func_name = call_node.func.id
                if func_name not in self.command_handlers:
                    self.error_context.append(f"Unknown command: '{func_name}' in '{command_str}'")
                    yield {"type": "error", "content": f" Unknown command: `{func_name}`"}
                    continue

                args = []
                valid_args = True
                for arg_node in call_node.args:
                    try:
                        args.append(ast.literal_eval(arg_node))
                    except ValueError as ve:
                        error_msg = f"Command argument error: Non-literal argument in '{command_str}'. Argument: {ast.dump(arg_node) if isinstance(arg_node, ast.AST) else str(arg_node)}. Error: {ve}"
                        self._log_to_memory("ERROR", error_msg, priority=1)
                        self.error_context.append(error_msg)
                        yield {"type": "error", "content": f" Command error: Invalid argument in `{command_str}`"}
                        valid_args = False
                        break

                if not valid_args:
                    continue

                if func_name == "generate_image":
                    image_gen_results_generator = self.command_handlers[func_name](*args)
                    for update_message in image_gen_results_generator:
                        yield update_message
                        if update_message.get("type") == "file_changed":
                            if "recent_changes" not in self.project_context:
                                self.project_context["recent_changes"] = []
                            self.project_context["recent_changes"].append(
                                SystemActionLog(command=func_name, args=list(args), timestamp=time.time())
                            )
                            self.project_context["recent_changes"] = self.project_context["recent_changes"][-20:]
                            self.project_files_changed = True

                elif func_name == "run_command":
                    run_command_output = self.command_handlers[func_name](*args)
                    if isinstance(run_command_output, dict) and run_command_output.get("status") == "REPLAN_REQUESTED":
                        # Yield a structured replan request instead of a raw string
                        yield {"type": "replan_request", "reason": run_command_output.get('reason', 'Replan from run_command'), "agent_name": "MainCoder"}
                    elif isinstance(run_command_output, str):
                        self._log_to_memory("COMMAND_SUCCESS", f"Successfully ran: {args[0][:100]}", priority=5)
                        yield {"type": "system", "content": run_command_output}
                    else:
                        yield {"type": "error", "content": f" Unexpected output type from run_command: {str(run_command_output)[:100]}"}

                else:
                    string_result_from_command = self.command_handlers[func_name](*args)
                    yield {"type": "system", "content": string_result_from_command}

                is_successful_operation = False
                if func_name == "delete_file":
                    if isinstance(string_result_from_command, str) and "" in string_result_from_command:
                        is_successful_operation = True
                elif func_name in ["create_file", "write_to_file", "rename_file", "set_user_preference", "get_user_preference", "list_directory_contents"]:
                    if isinstance(string_result_from_command, str) and "" in string_result_from_command or "" in string_result_from_command: # list_directory_contents also starts with 
                        is_successful_operation = True
                
                if is_successful_operation:
                        if func_name in ["create_file", "write_to_file", "delete_file", "rename_file"]:
                            if "recent_changes" not in self.project_context:
                                self.project_context["recent_changes"] = []
                            self.project_context["recent_changes"].append(
                                SystemActionLog(command=func_name, args=list(args), timestamp=time.time())
                            )
                            self.project_context["recent_changes"] = self.project_context["recent_changes"][-20:]
                            self.project_files_changed = True

                            if func_name == "create_file" and args: yield {"type": "file_changed", "content": args[0]}
                            elif func_name == "write_to_file" and args: yield {"type": "file_changed", "content": args[0]}
                            elif func_name == "delete_file" and args: yield {"type": "file_changed", "content": args[0]}
                            elif func_name == "rename_file" and len(args) > 1: yield {"type": "file_changed", "content": args[1]}

            except SyntaxError as se:
                error_msg = f"Command syntax error: Unable to parse '{command_str}'. Error: {se}"
                self._log_to_memory("ERROR", error_msg, priority=1)
                self.error_context.append(error_msg)
                yield {"type": "error", "content": f" Command syntax error: `{command_str}`"}
            except ValueError as ve:
                error_msg = f"Command value error: Problem with argument values in '{command_str}'. Error: {ve}"
                self._log_to_memory("ERROR", error_msg, priority=1)
                self.error_context.append(error_msg)
                yield {"type": "error", "content": f" Command value error: `{command_str}`"}
            except Exception as e:
                args_for_log = "unavailable"
                try:
                    args_for_log = str(args) if 'args' in locals() else "not populated before error"
                except Exception:
                    args_for_log = "error stringifying args"

                error_msg = f"Unexpected command execution error for '{command_str}'. Error: {type(e).__name__} - {e}. Args: {args_for_log}"
                self._log_to_memory("ERROR", error_msg, priority=1)
                self.error_context.append(error_msg)
                yield {"type": "error", "content": f" Unexpected error processing command: `{command_str}`"}

    def _log_interaction(self, role, content):
        """Logs an interaction to the conversation history, maintaining a manageable length."""
        self.conversation_history.append(
            ChatMessage(role=role, content=content, timestamp=time.time())
        )
        # Removed the pruning logic here so PersonaAgent can get full history.
        # if len(self.conversation_history) > 20:
        #     self.conversation_history = self.conversation_history[-15:]

    def _format_results(self, results):
        """Formats a list of implementation results for inclusion in agent prompts."""
        if not results:
            return "No implementation results"
        formatted = []
        for result in results[-5:]:
            formatted.append(f"- {result.get('type', 'unknown')}: {result.get('content', '')}")
        return "\\n".join(formatted) # Use \\n for agent parsing

    def _get_project_summary(self):
        """Gets a concise summary of the current project state (file counts)."""
        file_count = len(self.project_context.get("files", []))
        image_count = len(self.project_context.get("images", []))
        recent_changes = len(self.project_context.get("recent_changes", []))
        return f"Files: {file_count}, Images: {image_count}, Recent changes: {recent_changes}"

    def _get_recent_conversation_summary(self):
        """Gets a summary of the most recent part of the conversation history for general use (not for PersonaAgent's full context)."""
        if not self.conversation_history:
            return "No recent conversation"
        recent = self.conversation_history[-6:]
        summary = []
        for entry in recent:
            role = entry.role.replace("_", " ").title()
            content = entry.content[:150] + "..." if len(entry.content) > 150 else entry.content
            summary.append(f"{role}: {content}")
        return "\\n".join(summary) # Use \\n for agent parsing
    
    def _get_recent_changes_summary(self, as_string_for_planner: bool = False):
        """Gets a summary of recent project changes."""
        recent_changes_summary_str = "No recent changes logged."
        if hasattr(self, 'project_context') and self.project_context.get("recent_changes"):
            changes_to_show = self.project_context["recent_changes"][-5:] # Show last 5 changes
            formatted_changes = []
            for change in changes_to_show:
                formatted_changes.append(f"- {change.command}: {str(change.args)[:100]}{'...' if len(str(change.args)) > 100 else ''}") # Access dataclass attributes
            if formatted_changes:
                recent_changes_summary_str = "\\n".join(formatted_changes) # Use \\n for agents to parse
                if as_string_for_planner:
                    return recent_changes_summary_str # Return as is
                else:
                    return f"Last few system actions:\\n{recent_changes_summary_str}"
        return recent_changes_summary_str

    def _scan_project_files(self):
        """Scans and returns a list of project files (non-images). Internal use for cache building."""
        files = []
        if VM_DIR.exists():
            vm_dir_resolved = VM_DIR.resolve()
            for root, dirs, filenames in os.walk(VM_DIR):
                if TRASH_DIR_NAME in dirs:
                    dirs.remove(TRASH_DIR_NAME)
                for name in filenames:
                    file_path = Path(root) / name
                    # Ensure the file is actually within VM_DIR and not an escape
                    try:
                        relative_path = file_path.relative_to(vm_dir_resolved)
                        if not name.lower().endswith(('.png', '.jpg', '.jpeg', '.gif', '.bmp')):
                            files.append(str(relative_path))
                    except ValueError: # Path not within VM_DIR
                        continue
        return files

    def _scan_project_images(self):
        """Scans and returns a list of project images. Internal use for cache building."""
        images = []
        if VM_DIR.exists():
            vm_dir_resolved = VM_DIR.resolve()
            for root, dirs, filenames in os.walk(VM_DIR):
                if TRASH_DIR_NAME in dirs:
                    dirs.remove(TRASH_DIR_NAME)
                for name in filenames:
                    file_path = Path(root) / name
                    try:
                        relative_path = file_path.relative_to(vm_dir_resolved)
                        if name.lower().endswith(('.png', '.jpg', '.jpeg', '.gif', '.bmp')):
                            images.append(str(relative_path))
                    except ValueError: # Path not within VM_DIR
                        continue
        return images

    def _get_project_files(self):
        """Get list of project files from context (populated by _update_project_context)."""
        return self.project_context.get("files", [])

    def _get_project_images(self):
        """Get list of project images from context (populated by _update_project_context)."""
        return self.project_context.get("images", [])

    def _get_recent_changes(self):
        """Get recent project changes from context (populated by _process_enhanced_commands)."""
        return self.project_context.get("recent_changes", [])

    def _extract_grade(self, agent_response):
        """Extract numerical grade from agent response"""
        if not agent_response:
            return None
        grade_match = re.search(r'GRADE:\s*(\d+)/100', agent_response, re.IGNORECASE)
        if grade_match:
            return int(grade_match.group(1))
        grade_match = re.search(r'\bgrade[:\s]*(\d{1,3})\b', agent_response, re.IGNORECASE)
        if grade_match:
            return int(grade_match.group(1))
        return None

    def _calculate_overall_grade(self, critic_grade, art_grade):
        """Calculate overall grade from individual agent grades"""
        grades = [g for g in [critic_grade, art_grade] if g is not None]
        if not grades:
            return None # Changed from 85 to None for clarity
        return sum(grades) // len(grades)

    def _safe_path(self, filename_str: str) -> Path | None:
        """
        Resolves a path ensuring it is safely contained within the VM_DIR.
        Returns the resolved absolute Path object if safe, None otherwise.
        """
        if not filename_str:
            return None

        try:
            # Resolve the intended full path relative to VM_DIR
            # This handles '..', '~', and symlinks
            full_path = (VM_DIR / filename_str).resolve()
        except OSError:
            # e.g., if path components are invalid or file/dir does not exist and resolve() fails
            return None

        # Ensure the resolved path is actually *within* the VM_DIR's resolved path
        # This is the critical security check against path traversal
        vm_dir_resolved = VM_DIR.resolve()
        try:
            full_path.relative_to(vm_dir_resolved)
        except ValueError: # path is not a subpath of vm_dir_resolved
            return None
        
        return full_path

    def _list_directory_contents(self, target_path_str: str = ".", recursive: bool = True):
        """
        Lists files and directories within the specified target_path_str, relative to VM_DIR.
        Paths in the output are relative to the resolved target_path_str.
        Example: if target_path_str is "subdir" (which resolves to vm/subdir),
                 and vm/subdir contains file.txt, output will include "./file.txt".
                 If recursive and vm/subdir/nested/data.bin exists, output includes "./nested/data.bin".
        """
        # Resolve target_path_str to an absolute path safely within VM_DIR
        resolved_scan_base_path = self._safe_path(target_path_str)

        if not resolved_scan_base_path:
            return f" Error: Path not found or invalid after resolving: {target_path_str}"
        if not resolved_scan_base_path.is_dir():
            return f" Error: Path is not a directory: {target_path_str}"

        output_items = []
        try:
            if recursive:
                for root_str, dirs, files in os.walk(str(resolved_scan_base_path), topdown=True):
                    dirs.sort()
                    files.sort()

                    root_path = Path(root_str)
                    # Path relative to the directory we started scanning from
                    path_relative_to_scan_base = root_path.relative_to(resolved_scan_base_path)

                    for name in files:
                        item_display_path = Path(".") / path_relative_to_scan_base / name
                        output_items.append(item_display_path.as_posix())
                    for name in dirs:
                        item_display_path = Path(".") / path_relative_to_scan_base / name
                        output_items.append(item_display_path.as_posix() + "/")
            else:
                for item_name in sorted(os.listdir(str(resolved_scan_base_path))):
                    item_display_path = Path(".") / item_name
                    if (resolved_scan_base_path / item_name).is_dir():
                        output_items.append(item_display_path.as_posix() + "/")
                    else:
                        output_items.append(item_display_path.as_posix())

        except Exception as e:
            return f" Error listing directory contents for '{target_path_str}': {e}"

        if not output_items:
            return f" No items found in '{target_path_str}' (resolved to {resolved_scan_base_path})."

        return "\\n".join(output_items)

    def _replace_file_snippet(self, path_str: str, old_snippet: str, new_snippet: str) -> str:
        """Replaces all occurrences of old_snippet with new_snippet in the specified file."""
        filepath = self._safe_path(path_str)
        if not filepath:
            return f" Invalid path: {path_str}"
        if not filepath.exists() or not filepath.is_file():
            return f" File not found or is not a file: {path_str}"

        try:
            content = filepath.read_text(encoding='utf-8')
        except UnicodeDecodeError:
            return f" Error reading file {path_str}: Not a valid UTF-8 text file."
        except Exception as e:
            return f" Error reading file {path_str}: {e}"

        if old_snippet not in content:
            return f" Snippet not found in file: {path_str}. No changes made."

        original_content = content
        modified_content = content.replace(old_snippet, new_snippet)
        occurrences = original_content.count(old_snippet)

        try:
            filepath.write_text(modified_content, encoding='utf-8')
            if occurrences == 1:
                return f" Snippet replaced 1 time in {path_str}."
            else:
                return f" Snippet replaced {occurrences} times in {path_str}."
        except Exception as e:
            return f" Error writing to file {path_str}: {e}"

    def _edit_file_lines(self, path_str: str, start_line_usr: int, end_line_usr: int, new_content_str: str) -> str:
        """
        Modifies a file by replacing, inserting, or deleting lines.
        Uses 1-indexed line numbers as input, matching agent's perspective.
        """
        filepath = self._safe_path(path_str)
        if not filepath:
            return f" Error: Invalid path provided: {path_str}"
        if not filepath.exists() or not filepath.is_file():
            return f" Error: File not found or is not a file: {path_str}"

        try:
            # Read lines. splitlines() handles various newline chars and doesn't keep them.
            # If file is empty, lines will be []. If file has one empty line, lines will be [''].
            original_content = filepath.read_text(encoding='utf-8')
            lines = original_content.splitlines()
        except UnicodeDecodeError:
            return f" Error reading file {path_str}: Not a valid UTF-8 text file."
        except IOError as e:
            return f" Error reading file {path_str}: {e}"

        # Validate line numbers
        if not (isinstance(start_line_usr, int) and isinstance(end_line_usr, int)):
            return " Error: Line numbers must be integers."

        num_lines = len(lines)

        # Agent signals insertion with end_line < start_line.
        # Internally, we can map this to a consistent operation or use a special marker.
        # For this implementation, let's use the agent's convention directly.
        is_insertion = end_line_usr < start_line_usr
        is_deletion = not new_content_str # Truly empty string for new_content means deletion

        if is_deletion:
            if not (1 <= start_line_usr <= num_lines and 1 <= end_line_usr <= num_lines and start_line_usr <= end_line_usr):
                return f" Error: Invalid line numbers for deletion. File has {num_lines} lines. Received start={start_line_usr}, end={end_line_usr}."
        elif is_insertion: # Agent signals insert by end_line_usr < start_line_usr
            if not (1 <= start_line_usr <= num_lines + 1):
                return f" Error: Invalid start_line for insertion. File has {num_lines} lines. Received start={start_line_usr} (max {num_lines + 1} to append)."
            # end_line_usr is not further validated for insertion as per spec
        else: # Replacement (start_line_usr <= end_line_usr and new_content_str is not empty)
            if not (1 <= start_line_usr <= num_lines and 1 <= end_line_usr <= num_lines and start_line_usr <= end_line_usr):
                # Allow replacing line 1 of an empty file if it's considered to have one empty line.
                # However, splitlines() on an empty file returns [], so num_lines is 0.
                # If file has one line "foo", num_lines is 1. lines[0] is "foo".
                # start_line_usr=1, end_line_usr=1 is valid.
                if num_lines == 0 and start_line_usr == 1 and end_line_usr == 1: # Special case: "replacing" the (non-existent) first line of an empty file
                    pass # This will effectively become an insertion at the beginning.
                elif num_lines == 1 and lines == [''] and start_line_usr == 1 and end_line_usr == 1: # Special case: replacing the single empty line
                    pass
                else:
                    return f" Error: Invalid line numbers for replacement. File has {num_lines} lines. Received start={start_line_usr}, end={end_line_usr}."

        s_idx = start_line_usr - 1  # Convert to 0-based index

        new_lines = new_content_str.splitlines() if new_content_str else []
        if new_content_str == "": # Distinguish deleting content vs. providing an empty line
            if not is_deletion: # if it's not a deletion, it's replacing with one empty line
              new_lines = ['']


        action_summary = ""

        if is_deletion:
            e_idx = end_line_usr - 1
            del lines[s_idx : e_idx + 1]
            action_summary = f" Lines {start_line_usr}-{end_line_usr} deleted from {filepath.name}."
            if start_line_usr == end_line_usr:
                 action_summary = f" Line {start_line_usr} deleted from {filepath.name}."
        elif is_insertion: # end_line_usr < start_line_usr
            # Insert new_lines before lines[s_idx]
            lines[s_idx:s_idx] = new_lines
            action_summary = f" Content inserted before line {start_line_usr} in {filepath.name}."
        else: # Replacement
            e_idx = end_line_usr - 1
            if num_lines == 0 and s_idx == 0: # Replacing "line 1" of an empty file
                lines = new_lines
            else:
                lines[s_idx : e_idx + 1] = new_lines

            if start_line_usr == end_line_usr:
                action_summary = f" Line {start_line_usr} replaced in {filepath.name}."
            else:
                action_summary = f" Lines {start_line_usr}-{end_line_usr} replaced in {filepath.name}."

        modified_content = "\n".join(lines)
        # Ensure a final newline if the original content had one and the modified content is not empty,
        # or if the original file was empty and content was added.
        if (original_content.endswith('\n') and modified_content) or \
           (not original_content and modified_content):
            if not modified_content.endswith('\n'):
                 modified_content += '\n'

        # If all lines are deleted, the file should be empty, not contain a single newline.
        if not lines and not new_lines and is_deletion: # Check if lines is empty after deletion
            modified_content = ""


        try:
            filepath.write_text(modified_content, encoding='utf-8')
            return action_summary
        except IOError as e:
            return f" Error writing edited content to file {path_str}: {e}"

    def _create_file(self, path, content=""):
        """Create new file with enhanced error handling"""
        filepath = self._safe_path(path)
        if not filepath:
            return f" Invalid path: {path}"
        if filepath.exists():
            return f" File already exists: {path}. Use write_to_file to modify."
        try:
            filepath.parent.mkdir(parents=True, exist_ok=True)
            filepath.write_text(content, encoding='utf-8')
            return f" Created file: {path} ({len(content)} characters)"
        except Exception as e:
            error_msg = f" Error creating file {path}: {e}"
            self.error_context.append(error_msg)
            return error_msg

    def _write_to_file(self, path, content):
        """Write to file with enhanced feedback"""
        filepath = self._safe_path(path)
        if not filepath:
            return f" Invalid path: {path}"
        # If the file does not exist, create its parent directories.
        try:
            filepath.parent.mkdir(parents=True, exist_ok=True)
        except Exception as e:
            error_msg = f" Error creating parent directories for {path}: {e}"
            self.error_context.append(error_msg)
            return error_msg

        old_size = filepath.stat().st_size if filepath.exists() else 0
        try:
            filepath.write_text(content, encoding='utf-8')
            new_size = len(content.encode('utf-8'))
            return f" Updated file: {path} ({old_size}  {new_size} bytes)"
        except Exception as e:
            error_msg = f" Error writing to file {path}: {e}"
            self.error_context.append(error_msg)
            return error_msg

    def _delete_file(self, path_str: str):
        """Moves a file or directory to the .trash directory within VM_DIR."""
        filepath_to_trash = self._safe_path(path_str)

        if not filepath_to_trash or not filepath_to_trash.exists():
            return f" Item not found: {path_str}"

        trash_dir = VM_DIR / TRASH_DIR_NAME

        try:
            trash_dir.mkdir(parents=True, exist_ok=True)
        except Exception as e:
            error_msg = f" Error creating trash directory {trash_dir}: {e}"
            self.error_context.append(error_msg)
            return error_msg

        destination_in_trash = trash_dir / filepath_to_trash.name

        try:
            # To prevent overwriting in trash, append a timestamp if it already exists
            counter = 0
            original_destination_name = destination_in_trash.name
            while destination_in_trash.exists():
                counter += 1
                timestamp = datetime.now().strftime("%Y%m%d%H%M%S")
                name_body = Path(original_destination_name).stem
                suffix = Path(original_destination_name).suffix
                if filepath_to_trash.is_dir():
                     new_name = f"{original_destination_name}.{timestamp}_{counter}"
                else:
                     new_name = f"{name_body}.{timestamp}_{counter}{suffix}"
                destination_in_trash = trash_dir / new_name

            item_type_original = "directory" if filepath_to_trash.is_dir() else "file"

            shutil.move(str(filepath_to_trash), str(destination_in_trash))

            return f" Moved {item_type_original} to trash: {path_str} (as {destination_in_trash.name})".strip()

        except Exception as e:
            error_msg = f" Error moving {path_str} to trash: {e}"
            self.error_context.append(error_msg)
            return error_msg

    def _run_command(self, command):
        """Execute shell command with enhanced output"""
        if not command:
            return " No command provided"
        try:
            start_time = time.time()
            import shlex
            cmd_parts = shlex.split(command)
            if not cmd_parts:
                return " Empty command provided"
            proc = subprocess.run(
                cmd_parts,
                cwd=VM_DIR,
                shell=False,
                capture_output=True,
                text=True,
                timeout=120
            )
            execution_time = time.time() - start_time
            output = f" Command: {command}\n Execution time: {execution_time:.2f}s\n"
            if proc.stdout:
                output += f" STDOUT:\n{proc.stdout}\n"
            if proc.stderr:
                output += f" STDERR:\n{proc.stderr}\n"
                self.error_context.append(f"Command stderr for '{command}': {proc.stderr}")

            if proc.returncode == 0:
                output += " Command completed successfully"
                return output
            else:
                error_reason = f"The command '{command}' failed with exit code {proc.returncode}. Stderr: {proc.stderr}"
                self._log_to_memory("COMMAND_ERROR", error_reason, priority=1)
                self.error_context.append(f"Command failed: {error_reason}")
                return {
                    "status": "REPLAN_REQUESTED",
                    "reason": error_reason
                }
        except subprocess.TimeoutExpired:
            error_reason = f"The command '{command}' timed out after 120 seconds."
            self._log_to_memory("COMMAND_ERROR", error_reason, priority=1)
            self.error_context.append(error_reason)
            return {
                "status": "REPLAN_REQUESTED",
                "reason": error_reason
            }
        except Exception as e:
            error_reason = f"Command execution error for '{command}': {e}"
            self._log_to_memory("COMMAND_ERROR", error_reason, priority=1)
            self.error_context.append(f"Command failed: {error_reason}")
            return {
                "status": "REPLAN_REQUESTED",
                "reason": error_reason
            }

    def generate_image(self, path, prompt):
        """Enhanced image generation with better feedback"""
        if not self.client:
            yield {"type": "error", "content": " Image generation not configured"}
            return
        filepath = self._safe_path(path)
        if not filepath:
            yield {"type": "error", "content": f" Invalid path: {path}"}
            return
        yield {"type": "system", "content": f" Generating image: {path}"}
        yield {"type": "system", "content": f" Prompt: {prompt}"}
        try:
            config = types.GenerateContentConfig(response_modalities=["TEXT", "IMAGE"])
            response = self.client.models.generate_content(
                model=IMAGE_MODEL_NAME,
                contents=prompt,
                config=config
            )
            image_bytes = None
            candidates = getattr(response, "candidates", [])
            if candidates:
                parts = candidates[0].content.parts
                for part in parts:
                    if hasattr(part, "inline_data") and part.inline_data is not None:
                        image_bytes = part.inline_data.data
                        break
            if not image_bytes:
                yield {"type": "error", "content": " No image data received from AI"}
                return
            filepath.parent.mkdir(parents=True, exist_ok=True)
            filepath.write_bytes(image_bytes)
            try:
                img = Image.open(filepath)
                width, height = img.size
                file_size = filepath.stat().st_size
                yield {"type": "system", "content": f" Image generated: {width}x{height}px, {file_size} bytes"}
            except Exception:
                yield {"type": "system", "content": f" Image generated: {path}"}
            yield {"type": "file_changed", "content": str(filepath)}
        except Exception as e:
            error_msg = f" Image generation failed: {e}"
            self._log_to_memory("IMAGE_GEN_ERROR", error_msg, priority=2)
            self.error_context.append(error_msg)
            yield {"type": "error", "content": error_msg}

# -----------------------------------------------------------------------------
# Enhanced IDE Application
# -----------------------------------------------------------------------------
class EnhancedGeminiIDE(tk.Tk):
    def __init__(self):
        super().__init__()
        self.title(APP_TITLE)
        self.geometry("1600x1000")
        self.protocol("WM_DELETE_WINDOW", self.on_close)

        self.bg_color_dark = "#2E2E2E"
        self.fg_color_light = "#F0F0F0"
        self.bg_color_medium = "#3C3C3C"
        self.border_color = "#505050"
        self.accent_color = "#007ACC"

        self.user_chat_color = "#7FFFD4"
        self.system_chat_color = "#4DB6AC"
        self.timestamp_chat_color = "#B0B0B0"
        self.error_chat_color = "#FF8A80"

        self.agent_status_inactive_color = "#66BB6A"
        self.agent_status_active_color = "#FFA726"
        self.agent_status_error_color = "#EF5350"

        self.style = ttk.Style()
        self.style.theme_use('clam')

        self.configure(bg=self.bg_color_dark)

        self.style.configure("TFrame", background=self.bg_color_dark)
        self.style.configure(
            "TLabelframe",
            background=self.bg_color_dark,
            bordercolor=self.border_color,
            relief=tk.SOLID,
            borderwidth=1
        )
        self.style.configure(
            "TLabelframe.Label",
            background=self.bg_color_dark,
            foreground=self.fg_color_light,
            padding=(5, 2)
        )
        self.style.configure("TPanedwindow", background=self.bg_color_dark)
        self.style.configure("Sash", background=self.bg_color_medium, bordercolor=self.border_color, relief=tk.RAISED, sashthickness=6)

        self.style.configure("Vertical.TScrollbar", background=self.bg_color_medium, troughcolor=self.bg_color_dark, bordercolor=self.border_color, arrowcolor=self.fg_color_light, relief=tk.FLAT, arrowsize=12)
        self.style.configure("Horizontal.TScrollbar", background=self.bg_color_medium, troughcolor=self.bg_color_dark, bordercolor=self.border_color, arrowcolor=self.fg_color_light, relief=tk.FLAT, arrowsize=12)
        self.style.map("TScrollbar",
            background=[('active', self.accent_color), ('!active', self.bg_color_medium)],
            arrowcolor=[('pressed', self.accent_color), ('!pressed', self.fg_color_light)]
        )

        self.style.configure("TButton", background=self.accent_color, foreground="white", padding=(8, 4), font=('Segoe UI', 9, 'bold'), borderwidth=1, relief=tk.RAISED, bordercolor=self.accent_color)
        self.style.map("TButton",
                       background=[('active', '#005f9e'), ('pressed', '#004c8c'), ('disabled', self.bg_color_medium)],
                       foreground=[('disabled', self.border_color)],
                       relief=[('pressed', tk.SUNKEN), ('!pressed', tk.RAISED)])

        self.style.configure("Treeview", background=self.bg_color_medium, foreground=self.fg_color_light, fieldbackground=self.bg_color_medium, rowheight=22, borderwidth=1, relief=tk.SOLID, bordercolor=self.border_color)
        self.style.map("Treeview",
                       background=[('selected', self.accent_color)],
                       foreground=[('selected', "white")])
        self.style.configure("Treeview.Heading", background=self.bg_color_dark, foreground=self.fg_color_light, relief=tk.FLAT, padding=(5, 5), font=('Segoe UI', 9, 'bold'), borderwidth=0)
        self.style.map("Treeview.Heading",
                       background=[('active', self.bg_color_medium)],
                       relief=[('active', tk.GROOVE), ('!active', tk.FLAT)])

        self.style.configure("TNotebook", background=self.bg_color_dark, tabmargins=(5, 5, 5, 0), borderwidth=1, bordercolor=self.border_color)
        self.style.configure("TNotebook.Tab", background=self.bg_color_medium, foreground=self.fg_color_light, padding=(8,4), font=('Segoe UI', 9), borderwidth=0, relief=tk.FLAT)
        self.style.map("TNotebook.Tab",
                       background=[("selected", self.accent_color), ("active", self.bg_color_dark)],
                       foreground=[("selected", "white"), ("active", self.fg_color_light)],
                       relief=[("selected", tk.FLAT), ("!selected", tk.FLAT)],
                       borderwidth=[("selected",0)])

        self.style.configure("TLabel", background=self.bg_color_dark, foreground=self.fg_color_light, padding=2)
        self.style.configure("Status.TLabel", background=self.bg_color_dark, foreground=self.fg_color_light, padding=5, relief=tk.FLAT)


        VM_DIR.mkdir(exist_ok=True)
        self.msg_queue = queue.Queue()
        self.current_image = None
        self.current_open_file_path = None

        self.file_tree_cache = {}
        self.file_tree_cache_dirty = True
        self.chat_chunk_color_tags = {}

        self._debounce_refresh_id = None
        self._debounce_insights_id = None
        self._save_timer = None
        self._debounce_interval = 300
        self._highlight_job = None
        self._pygments_highlight_delay = 500

        self._create_enhanced_menu()
        self._create_enhanced_layout()
        self._create_enhanced_status_bar()

        # Pygments style setup
        self.pygments_style = get_style_by_name('monokai') 
        editor_font_tuple = tk.font.Font(font=self.editor.cget("font")).actual()
        current_font_family = editor_font_tuple["family"]
        current_font_size = editor_font_tuple["size"]

        for ttype, ndef in self.pygments_style:
            tag_name = f"pyg_{str(ttype).replace('.', '_')}"
            fg = ndef.get('color')
            tkinter_fg = f"#{fg}" if fg else self.fg_color_light
            
            font_styles = []
            if ndef.get('bold'):
                font_styles.append("bold")
            if ndef.get('italic'):
                font_styles.append("italic")
            
            final_font_tuple = (current_font_family, current_font_size) + tuple(font_styles)
            self.editor.tag_configure(tag_name, foreground=tkinter_fg, font=final_font_tuple)

        api_key = load_api_key()
        if not api_key and GENAI_IMPORTED:
            self.prompt_api_key()
        elif GENAI_IMPORTED:
            self.configure_enhanced_agents(api_key)
        else:
            messagebox.showerror("Missing Dependency", "Install google-genai: pip install google-genai")
            self.status_var.set(" google-genai not installed")

        self.after(100, self._process_messages)

    def _create_enhanced_menu(self):
        """Create enhanced application menu"""
        menubar = tk.Menu(self)
        file_menu = tk.Menu(menubar, tearoff=0)
        file_menu.add_command(label=" New File", command=self.new_file)
        file_menu.add_command(label=" Save File", command=self.save_current_file)
        file_menu.add_command(label=" Refresh Files", command=self.refresh_files)
        file_menu.add_separator()
        file_menu.add_command(label=" Clear Chat", command=self.clear_chat)
        file_menu.add_command(label=" Project Stats", command=self.show_project_stats)
        menubar.add_cascade(label="File", menu=file_menu)
        agents_menu = tk.Menu(menubar, tearoff=0)
        agents_menu.add_command(label=" Test Main Coder", command=lambda: self.test_agent("main"))
        agents_menu.add_command(label=" Test Code Critic", command=lambda: self.test_agent("critic"))
        agents_menu.add_command(label=" Test Art Critic", command=lambda: self.test_agent("art"))
        agents_menu.add_separator()
        agents_menu.add_command(label=" Reset Agent Memory", command=self.reset_agent_memory)
        agents_menu.add_command(label=" Clear Agent Memories", command=self.clear_agent_memories)
        menubar.add_cascade(label="Agents", menu=agents_menu)
        settings_menu = tk.Menu(menubar, tearoff=0)
        settings_menu.add_command(label=" Set API Key", command=self.prompt_api_key)
        settings_menu.add_command(label=" Agent Settings", command=self.show_agent_settings)
        menubar.add_cascade(label="Settings", menu=settings_menu)
        menubar.config(bg=self.bg_color_dark, fg=self.fg_color_light, activebackground=self.accent_color, activeforeground="white", relief=tk.FLAT, borderwidth=0)
        for menu_item in [file_menu, agents_menu, settings_menu]:
            menu_item.config(bg=self.bg_color_medium, fg=self.fg_color_light, activebackground=self.accent_color, activeforeground="white", relief=tk.FLAT, borderwidth=0)
        self.config(menu=menubar)

    def _setup_left_panel(self, parent_pane):
        """Sets up the left panel with image preview and file tree."""
        left_frame = ttk.Frame(parent_pane)
        parent_pane.add(left_frame, weight=1)
        img_frame = ttk.LabelFrame(left_frame, text=" Visual Preview", padding=5)
        img_frame.pack(fill=tk.X, pady=(0, 5))
        self.canvas = tk.Canvas(img_frame, bg=self.bg_color_medium, height=320, highlightthickness=0)
        self.canvas.pack(fill=tk.BOTH, expand=True)
        self.canvas.create_text(160, 160, text=" No image selected\nImages will be analyzed by Art Critic",
                               fill=self.fg_color_light, font=("Arial", 11), justify=tk.CENTER)
        tree_frame = ttk.LabelFrame(left_frame, text=" Project Explorer", padding=5)
        tree_frame.pack(fill=tk.BOTH, expand=True)
        self.tree = ttk.Treeview(tree_frame, columns=("fullpath", "size"), show="tree")
        self.tree.heading("#0", text="Name")
        self.tree.heading("size", text="Size")
        self.tree.column("fullpath", width=0, stretch=False)
        self.tree.column("size", width=80)
        vsb = ttk.Scrollbar(tree_frame, orient="vertical", command=self.tree.yview)
        hsb = ttk.Scrollbar(tree_frame, orient="horizontal", command=self.tree.xview)
        self.tree.configure(yscrollcommand=vsb.set, xscrollcommand=hsb.set)
        self.tree.grid(row=0, column=0, sticky="nsew")
        vsb.grid(row=0, column=1, sticky="ns")
        hsb.grid(row=1, column=0, sticky="ew")
        tree_frame.grid_rowconfigure(0, weight=1)
        tree_frame.grid_columnconfigure(0, weight=1)
        self.tree.bind("<<TreeviewSelect>>", self.on_tree_select)
        self._attach_enhanced_tree_context_menu()
        return left_frame

    def _setup_right_panel(self, parent_pane):
        """Sets up the right panel with the notebook for editor, chat, and insights."""
        right_frame = ttk.Frame(parent_pane)
        parent_pane.add(right_frame, weight=3)
        self.notebook = ttk.Notebook(right_frame)
        self.notebook.pack(fill=tk.BOTH, expand=True, pady=(0, 5))
        editor_frame = ttk.Frame(self.notebook)
        self.editor = scrolledtext.ScrolledText(
            editor_frame, wrap=tk.WORD, font=("Consolas", 12), padx=15, pady=15,
            bg=self.bg_color_medium, fg=self.fg_color_light, insertbackground=self.fg_color_light,
            relief=tk.FLAT, borderwidth=0, highlightthickness=1, highlightbackground=self.border_color
        )
        self.editor.pack(fill=tk.BOTH, expand=True)
        self.editor.frame.config(background=self.bg_color_dark)
        self.notebook.add(editor_frame, text=" Code Editor")
        chat_frame = ttk.Frame(self.notebook)
        self.chat = scrolledtext.ScrolledText(
            chat_frame, wrap=tk.WORD, font=("Segoe UI", 11), padx=15, pady=15, state="disabled",
            bg=self.bg_color_medium, fg=self.fg_color_light, insertbackground=self.fg_color_light,
            relief=tk.FLAT, borderwidth=0, highlightthickness=1, highlightbackground=self.border_color
        )
        self.chat.pack(fill=tk.BOTH, expand=True)
        self.chat.frame.config(background=self.bg_color_dark)
        self.notebook.add(chat_frame, text=" Multi-Agent Chat")
        insights_frame = ttk.Frame(self.notebook)
        self.insights = scrolledtext.ScrolledText(
            insights_frame, wrap=tk.WORD, font=("Segoe UI", 10), padx=15, pady=15, state="disabled",
            bg=self.bg_color_medium, fg=self.fg_color_light, relief=tk.FLAT, borderwidth=0,
            highlightthickness=1, highlightbackground=self.border_color
        )
        self.insights.pack(fill=tk.BOTH, expand=True)
        self.insights.frame.config(background=self.bg_color_dark)
        self.notebook.add(insights_frame, text=" Project Insights")
        return right_frame

    def _setup_input_area(self, parent_frame):
        """Sets up the input text area and control buttons."""
        input_frame = ttk.Frame(parent_frame)
        input_frame.pack(fill=tk.X, pady=(0, 5))
        self.input_txt = tk.Text(
            input_frame, height=4, wrap=tk.WORD, font=("Segoe UI", 11), padx=10, pady=10,
            bg=self.bg_color_medium, fg=self.fg_color_light, insertbackground=self.fg_color_light,
            relief=tk.FLAT, borderwidth=1, highlightbackground=self.border_color,
            highlightcolor=self.accent_color, highlightthickness=1
        )
        self.input_txt.pack(side=tk.LEFT, fill=tk.X, expand=True, padx=(0, 5))
        self.input_txt.bind("<Control-Return>", lambda e: self.send_enhanced_prompt())
        self.input_txt.insert("1.0", " Ask the multi-agent system anything... (Ctrl+Enter to send)")
        self.input_txt.bind("<FocusIn>", self._clear_placeholder)
        self.input_txt.bind("<FocusOut>", self._restore_placeholder)
        control_button_frame = ttk.Frame(input_frame)
        control_button_frame.pack(side=tk.RIGHT, fill=tk.Y, padx=(5, 0))
        self.enhancer_toggle_label = ttk.Label(control_button_frame, text="Enhancer:")
        self.enhancer_toggle_label.pack(side=tk.LEFT, padx=(0, 2), anchor='center')
        self.enhancer_toggle_switch = tk.Canvas(
            control_button_frame, width=50, height=22, borderwidth=0, relief=tk.FLAT, cursor="hand2"
        )
        self.enhancer_toggle_switch.pack(side=tk.LEFT, padx=(0, 8), anchor='center')
        self.screenshot_btn = ttk.Button(control_button_frame, text="", command=self.upload_screenshot, width=3)
        self.screenshot_btn.pack(side=tk.LEFT, padx=(0, 3), anchor='center')
        self.send_btn = ttk.Button(control_button_frame, text=" Send", command=self.send_enhanced_prompt)
        self.send_btn.pack(side=tk.LEFT, anchor='center')
        self.enhancer_toggle_switch.bind("<Button-1>", self._toggle_prompt_enhancer)

    def _create_enhanced_layout(self):
        """Create enhanced UI layout"""
        main_pane = ttk.PanedWindow(self, orient=tk.HORIZONTAL)
        main_pane.pack(fill=tk.BOTH, expand=True, padx=5, pady=5)
        self._setup_left_panel(main_pane)
        right_frame = self._setup_right_panel(main_pane)
        self._setup_input_area(right_frame)
        self.editor.bind("<Control-s>", lambda e: self.save_current_file())
        self.editor.bind("<KeyRelease>", self._on_editor_key_release)
        self._schedule_refresh_files()

    def _schedule_refresh_files(self):
        """Debounces the refresh_files call."""
        if self._debounce_refresh_id:
            self.after_cancel(self._debounce_refresh_id)
        self._debounce_refresh_id = self.after(self._debounce_interval, self.refresh_files)

    def _schedule_update_insights(self):
        """Debounces the update_agent_insights call."""
        if self._debounce_insights_id:
            self.after_cancel(self._debounce_insights_id)
        self._debounce_insights_id = self.after(self._debounce_interval, self.update_agent_insights)

    def _schedule_pygments_highlighting(self, event=None):
        if self._highlight_job:
            self.after_cancel(self._highlight_job)
        self._highlight_job = self.after(self._pygments_highlight_delay, self._apply_pygments_to_current_editor)

    def _apply_pygments_to_current_editor(self):
        if not self.current_open_file_path:
            return
        
        content = self.editor.get("1.0", tk.END + "-1c")
        if not content.strip():
            for tag in self.editor.tag_names():
                if tag.startswith("pyg_"):
                    self.editor.tag_remove(tag, "1.0", tk.END)
            return

        try:
            lexer = guess_lexer_for_filename(str(self.current_open_file_path), content, stripall=False)
        except ClassNotFound:
            lexer = get_lexer_by_name("text")
        except Exception:
            lexer = get_lexer_by_name("text")

        for tag in self.editor.tag_names():
            if tag.startswith("pyg_"):
                self.editor.tag_remove(tag, "1.0", tk.END)
        
        self.editor.mark_set("range_start", "1.0")
        if hasattr(lexer, 'get_tokens_unprocessed'):
            tokens = lexer.get_tokens_unprocessed(content)
            for ttype, value in tokens:
                tag_name = f"pyg_{str(ttype).replace('.', '_')}"
                self.editor.mark_set("range_end", f"range_start + {len(value)}c")
                if tag_name in self.editor.tag_names():
                    self.editor.tag_add(tag_name, "range_start", "range_end")
                self.editor.mark_set("range_start", "range_end")
        
        if self._save_timer: 
            self.after_cancel(self._save_timer)
            self._save_timer = None
        self._save_timer = self.after(2000, self._auto_save)


    def _on_editor_key_release(self, event=None):
        """Enhanced editor key release handler"""
        self._schedule_pygments_highlighting()


    def _auto_save(self):
        """Auto-save current file if one is open."""
        self._save_timer = None
        if self.current_open_file_path:
            self.save_current_file()

    def _clear_placeholder(self, event):
        """Clears the placeholder text from the input field on focus."""
        if self.input_txt.get("1.0", tk.END).strip().startswith(" Ask the multi-agent"):
            self.input_txt.delete("1.0", tk.END)

    def _restore_placeholder(self, event):
        """Restores placeholder text to the input field if it's empty on focus out."""
        if not self.input_txt.get("1.0", tk.END).strip():
            self.input_txt.insert("1.0", " Ask the multi-agent system anything... (Ctrl+Enter to send)")

    def _attach_enhanced_tree_context_menu(self):
        """Enhanced context menu for file tree"""
        self.context_menu = tk.Menu(self, tearoff=0)
        self.context_menu.add_command(label=" Rename", command=self.rename_file)
        self.context_menu.add_command(label=" Delete", command=self.delete_file)
        self.context_menu.add_separator()
        self.context_menu.add_command(label=" Analyze with Agents", command=self.analyze_selected_file)
        self.context_menu.add_command(label=" Review Design", command=self.review_visual_design)
        self.tree.bind("<Button-3>", self._show_context_menu)

    def _show_context_menu(self, event):
        """Show enhanced context menu"""
        item = self.tree.identify_row(event.y)
        if item:
            self.tree.selection_set(item)
            self.context_menu.post(event.x_root, event.y_root)

    def _create_enhanced_status_bar(self):
        """Create enhanced status bar"""
        status_frame = ttk.Frame(self)
        status_frame.pack(side=tk.BOTTOM, fill=tk.X)
        self.status_var = tk.StringVar(value=" Enhanced Multi-Agent System Ready")
        status_bar = ttk.Label(
            status_frame, 
            textvariable=self.status_var,
            style="Status.TLabel",
            anchor=tk.W
        )
        status_bar.pack(side=tk.LEFT, fill=tk.X, expand=True)
        self.agent_status_frame = ttk.Frame(status_frame)
        self.agent_status_frame.pack(side=tk.RIGHT, padx=5)
        self.main_status = ttk.Label(self.agent_status_frame, text="", foreground=self.agent_status_inactive_color)
        self.main_status.pack(side=tk.LEFT, padx=2)
        self.critic_status = ttk.Label(self.agent_status_frame, text="", foreground=self.agent_status_inactive_color)
        self.critic_status.pack(side=tk.LEFT, padx=2)
        self.art_status = ttk.Label(self.agent_status_frame, text="", foreground=self.agent_status_inactive_color)
        self.art_status.pack(side=tk.LEFT, padx=2)

    def configure_enhanced_agents(self, api_key):
        """Configure enhanced multi-agent system"""
        try:
            self.agent_system = EnhancedMultiAgentSystem(api_key)
            self.status_var.set(" Enhanced Multi-Agent System configured")
            self.add_chat_message("System", " Enhanced Multi-Agent System ready!\n\n Main Coder Agent - Vision-enabled implementation\n Code Critic Agent - Deep analysis & security\n Art Critic Agent - Visual analysis & design")
            self._draw_enhancer_toggle_switch()
            self.update_agent_insights()
        except Exception as e:
            self.status_var.set(f" Agent error: {str(e)}")
            self.add_chat_message("System", f"Agent configuration failed: {str(e)}", "#ff0000")

    def update_agent_insights(self):
        """Update project insights"""
        if not hasattr(self, 'agent_system'):
            return
        insights = []
        insights.append(" PROJECT ANALYSIS")
        insights.append("=" * 50)
        file_count = len(self.agent_system._get_project_files())
        image_count = len(self.agent_system._get_project_images())
        insights.append(f" Files: {file_count}")
        insights.append(f" Images: {image_count}")
        recent_changes = len(self.agent_system._get_recent_changes())
        insights.append(f" Recent changes: {recent_changes}")
        insights.append("\n AGENT CAPABILITIES")
        insights.append("=" * 50)
        insights.append(" Main Coder: Implementation + Vision")
        insights.append(" Code Critic: Quality + Security + Performance")
        insights.append(" Art Critic: Visual Analysis + Design + UX")
        self.insights.config(state="normal")
        self.insights.delete("1.0", tk.END)
        self.insights.insert("1.0", "\n".join(insights))
        self.insights.config(state="disabled")

    def send_enhanced_prompt(self):
        """Send enhanced prompt to multi-agent system"""
        text = self.input_txt.get("1.0", tk.END).strip()
        if not text or text.startswith(" Ask the multi-agent"):
            return
        self.add_chat_message(" You", text, color=self.user_chat_color)
        self.input_txt.delete("1.0", tk.END)
        self.input_txt.config(state="disabled")
        self.send_btn.config(state="disabled")
        self.screenshot_btn.config(state="disabled")
        self.status_var.set(" Enhanced Multi-Agent System Processing...")
        threading.Thread(
            target=self._process_enhanced_prompt, 
            args=(text,),
            daemon=True
        ).start()

    def _process_enhanced_prompt(self, text):
        """Process enhanced prompt with multi-agent system"""
        if not hasattr(self, 'agent_system') or self.agent_system is None:
            self.msg_queue.put({"type": "error", "content": "Enhanced Multi-Agent System not configured. Set API key."})
            self.msg_queue.put({"type": "done"})
            return
        for response in self.agent_system.run_enhanced_interaction(text):
            self.msg_queue.put(response)
        self.msg_queue.put({"type": "done"})

    def display_enhanced_image(self, path):
        """Enhanced image display with metadata"""
        try:
            img = Image.open(path)
            original_size = img.size
            img.thumbnail((400, 300))
            self.canvas.delete("all")
            tk_img = ImageTk.PhotoImage(img)
            self.canvas.create_image(200, 150, image=tk_img, anchor=tk.CENTER)
            self.canvas.image = tk_img
            file_size = path.stat().st_size
            self.canvas.create_text(
                200, 280, 
                text=f"{path.name}\n{original_size[0]}x{original_size[1]}px\n{file_size:,} bytes", 
                fill="darkblue", 
                justify=tk.CENTER,
                font=("Arial", 9)
            )
            self.status_var.set(f" Displaying: {path.name} ({original_size[0]}x{original_size[1]})")
        except Exception as e:
            self.canvas.delete("all")
            self.canvas.create_text(200, 150, text=f" Error loading image:\n{str(e)}", 
                                   fill="red", justify=tk.CENTER)
            self.status_var.set(f" Image error: {str(e)}")

    def refresh_files(self):
        """Enhanced file tree refresh with metadata, using caching."""
        self.status_var.set(" Refreshing file explorer...")
        self.update_idletasks()
        self.file_tree_cache_dirty = True
        self.tree.delete(*self.tree.get_children())
        if self.file_tree_cache_dirty:
            self.file_tree_cache.clear()
            self._rebuild_file_tree_cache(VM_DIR, self.file_tree_cache)
            self.file_tree_cache_dirty = False
        self._populate_tree_from_cache("", self.file_tree_cache)
        self.status_var.set(f" File explorer refreshed. {len(self.tree.get_children())} top-level item(s) loaded.")

    def _rebuild_file_tree_cache(self, current_path_obj, current_cache_level):
        """Recursively builds the file tree cache."""
        try:
            for item in sorted(current_path_obj.iterdir(), key=lambda x: (x.is_file(), x.name.lower())):
                if item.name == TRASH_DIR_NAME:
                    continue
                
                # Ensure paths stored in cache are relative strings to VM_DIR
                try:
                    rel_path_str = str(item.relative_to(VM_DIR))
                except ValueError: # item is not a child of VM_DIR, skip.
                    continue

                try:
                    stat_info = item.stat()
                    is_dir = item.is_dir()
                    current_cache_level[rel_path_str] = {
                        'name': item.name,
                        'is_dir': is_dir,
                        'size': stat_info.st_size,
                        'children': {}
                    }
                    if is_dir:
                        self._rebuild_file_tree_cache(item, current_cache_level[rel_path_str]['children'])
                except OSError as e:
                    print(f"OSError when processing {item}: {e}")
                    continue
        except OSError as e:
            print(f"OSError when iterating {current_path_obj}: {e}")

    def _populate_tree_from_cache(self, parent_tree_id, cache_node_data):
        """Populates the ttk.Treeview from the cached file structure."""
        sorted_item_keys = sorted(cache_node_data.keys(),
                                  key=lambda k: (not cache_node_data[k]['is_dir'], cache_node_data[k]['name'].lower()))
        for rel_path_str in sorted_item_keys:
            item_data = cache_node_data[rel_path_str]
            item_name = item_data['name']
            if item_data['is_dir']:
                node = self.tree.insert(
                    parent_tree_id,
                    'end',
                    text=f" {item_name}",
                    values=(rel_path_str, ""),
                    open=False
                )
                self._populate_tree_from_cache(node, item_data['children'])
            else:
                size_str = self._format_file_size(item_data['size'])
                name_path = Path(item_name)
                if name_path.suffix.lower() in ['.png', '.jpg', '.jpeg', '.gif', '.bmp']:
                    icon = ""
                elif name_path.suffix.lower() in ['.py', '.js', '.html', '.css']:
                    icon = ""
                else:
                    icon = ""
                self.tree.insert(
                    parent_tree_id,
                    'end',
                    text=f"{icon} {item_name}",
                    values=(rel_path_str, size_str)
                )

    def _format_file_size(self, size):
        """Format file size in human readable format"""
        for unit in ['B', 'KB', 'MB', 'GB']:
            if size < 1024:
                return f"{size:.1f}{unit}"
            size /= 1024
        return f"{size:.1f}TB"

    def add_chat_message(self, sender, message, color="#000000"):
        """Enhanced chat message with better formatting"""
        self.chat.config(state="normal")
        timestamp = time.strftime("[%H:%M:%S] ")
        safe_sender_name = re.sub(r'\W+', '', sender)
        sender_tag = f"sender_{safe_sender_name.strip()}"
        self.chat.tag_configure(sender_tag, foreground=color, font=("Segoe UI", 11, "bold"))
        self.chat.tag_configure("timestamp", foreground=self.timestamp_chat_color, font=("Segoe UI", 9))
        self.chat.tag_configure("message", font=("Segoe UI", 11))
        self.chat.insert(tk.END, timestamp, "timestamp")
        self.chat.insert(tk.END, f"{sender}:\n", sender_tag)
        self.chat.insert(tk.END, f"{message}\n\n", "message")
        self.chat.see(tk.END)
        self.chat.config(state="disabled")
        self.notebook.select(1)

    def _append_chat_chunk(self, sender, chunk_content, color="#000000"):
        """Appends a chunk of text to the chat, typically from a streaming response."""
        self.chat.config(state="normal")
        current_chat_content = self.chat.get("1.0", tk.END).strip()
        if not current_chat_content.endswith(sender + ":\n"):
            pass
        dynamic_tag_name = f"stream_chunk_{color.lstrip('#')}"
        if dynamic_tag_name not in self.chat_chunk_color_tags:
            self.chat.tag_configure(dynamic_tag_name, foreground=color)
            self.chat_chunk_color_tags[dynamic_tag_name] = True
        self.chat.insert(tk.END, chunk_content, dynamic_tag_name)
        self.chat.see(tk.END)
        self.chat.config(state="disabled")
        if self.notebook.index(self.notebook.select()) != 1:
            self.notebook.select(1)

    def test_agent(self, agent_type):
        """Test individual agent functionality"""
        test_prompts = {
            "main": "Create a simple hello.py file with a greeting function",
            "critic": "Review the code quality of any Python files in the project",
            "art": "Analyze any images in the project and suggest visual improvements"
        }
        if agent_type in test_prompts:
            self.input_txt.delete("1.0", tk.END)
            self.input_txt.insert("1.0", test_prompts[agent_type])
            self.send_enhanced_prompt()

    def reset_agent_memory(self):
        """Reset agent conversation history"""
        if hasattr(self, 'agent_system'):
            self.agent_system.conversation_history = []
            self.agent_system.error_context = []
            self.add_chat_message(" System", "Agent memory reset successfully")

    def clear_agent_memories(self):
        if not hasattr(self, 'agent_system') or self.agent_system is None:
            messagebox.showwarning("Agent System Not Ready", "The agent system is not yet initialized.")
            return

        if messagebox.askyesno(" Confirm Clear Memories",
                             "Are you sure you want to clear all agent memories from memory.txt?\n\nThis action cannot be undone."):
            result = self.agent_system.clear_memory_file()
            self.add_chat_message(" System Memory", result, color=self.system_chat_color)
            self.status_var.set(result)
            if hasattr(self, '_schedule_update_insights'):
                self._schedule_update_insights()

    def show_project_stats(self):
        """Show detailed project statistics"""
        if not hasattr(self, 'agent_system'):
            return
        stats = []
        stats.append(" PROJECT STATISTICS")
        stats.append("=" * 40)
        files = self.agent_system._get_project_files()
        images = self.agent_system._get_project_images()
        stats.append(f" Total Files: {len(files)}")
        stats.append(f" Images: {len(images)}")
        recent_changes = len(self.agent_system._get_recent_changes())
        stats.append(f" Recent changes: {recent_changes}")
        if files:
            stats.append("\n CODE FILES:")
            for f in files[:10]:
                stats.append(f"   {f}")
        if images:
            stats.append("\n IMAGE FILES:")
            for img in images:
                stats.append(f"   {img}")
        messagebox.showinfo("Project Statistics", "\n".join(stats))

    def show_agent_settings(self):
        """Show agent system settings with grading controls"""
        if not hasattr(self, 'agent_system'):
            messagebox.showwarning(" Warning", "Agent system not configured. Please set API key first.")
            return
        settings_window = tk.Toplevel(self)
        settings_window.title(" Agent System Settings")
        settings_window.geometry("500x600")
        settings_window.transient(self)
        settings_window.grab_set()
        main_frame = ttk.Frame(settings_window, padding=20)
        main_frame.pack(fill=tk.BOTH, expand=True)
        title_label = ttk.Label(main_frame, text=" ENHANCED MULTI-AGENT SYSTEM", font=("Arial", 14, "bold"))
        title_label.pack(pady=(0, 20))
        config_frame = ttk.LabelFrame(main_frame, text=" Configuration", padding=10)
        config_frame.pack(fill=tk.X, pady=(0, 10))
        ttk.Label(config_frame, text=f" Text Model: {TEXT_MODEL_NAME}").pack(anchor=tk.W)
        ttk.Label(config_frame, text=f" Image Model: {IMAGE_MODEL_NAME}").pack(anchor=tk.W)
        ttk.Label(config_frame, text=" Vision Capabilities:  Enabled").pack(anchor=tk.W)
        ttk.Label(config_frame, text=" Image Generation:  Enabled").pack(anchor=tk.W)
        grading_frame = ttk.LabelFrame(main_frame, text=" Grading System", padding=10)
        grading_frame.pack(fill=tk.X, pady=(0, 10))
        self.grading_var = tk.BooleanVar(value=getattr(self.agent_system, 'grading_enabled', True))
        grading_check = ttk.Checkbutton(
            grading_frame, 
            text="Enable Agent Grading & Retry System",
            variable=self.grading_var,
            command=self._toggle_grading
        )
        grading_check.pack(anchor=tk.W)
        ttk.Label(grading_frame, text=f" Max Retry Attempts: {getattr(self.agent_system, 'max_retry_attempts', 3)}").pack(anchor=tk.W)
        ttk.Label(grading_frame, text=" Minimum Passing Grade: 70/100").pack(anchor=tk.W)
        agents_frame = ttk.LabelFrame(main_frame, text=" Agent Capabilities", padding=10)
        agents_frame.pack(fill=tk.X, pady=(0, 10))
        ttk.Label(agents_frame, text=" Main Coder: Implementation + Vision Analysis").pack(anchor=tk.W)
        ttk.Label(agents_frame, text=" Code Critic: Quality + Security + Performance + Grading").pack(anchor=tk.W)
        ttk.Label(agents_frame, text=" Art Critic: Visual Design + UX + Accessibility + Grading").pack(anchor=tk.W)
        memory_frame = ttk.LabelFrame(main_frame, text=" Memory Status", padding=10)
        memory_frame.pack(fill=tk.X, pady=(0, 10))
        ttk.Label(memory_frame, text=f" Conversation History: {len(getattr(self.agent_system, 'conversation_history', []))} entries").pack(anchor=tk.W)
        ttk.Label(memory_frame, text=f" Error Context: {len(getattr(self.agent_system, 'error_context', []))} entries").pack(anchor=tk.W)
        features_frame = ttk.LabelFrame(main_frame, text=" Features", padding=10)
        features_frame.pack(fill=tk.X, pady=(0, 10))
        ttk.Label(features_frame, text=" Enhanced syntax highlighting").pack(anchor=tk.W)
        ttk.Label(features_frame, text=" Auto-save functionality").pack(anchor=tk.W)
        ttk.Label(features_frame, text=" Visual file tree with metadata").pack(anchor=tk.W)
        ttk.Label(features_frame, text=" Real-time project insights").pack(anchor=tk.W)
        ttk.Label(features_frame, text=" Screenshot upload & analysis").pack(anchor=tk.W)
        close_btn = ttk.Button(main_frame, text=" Close", command=settings_window.destroy)
        close_btn.pack(pady=(20, 0))
        
    def _toggle_grading(self):
        """Toggle grading system on/off"""
        if hasattr(self, 'agent_system'):
            self.agent_system.grading_enabled = self.grading_var.get()
            status = "enabled" if self.grading_var.get() else "disabled"
            self.status_var.set(f" Grading system {status}")
            self.add_chat_message(" Settings", f"Grading system {status}")

    def _toggle_prompt_enhancer(self, event=None):
        """Toggle prompt enhancer system on/off - called by the UI switch."""
        if hasattr(self, 'agent_system'):
            self.agent_system.prompt_enhancer_enabled = not self.agent_system.prompt_enhancer_enabled
            status = "enabled" if self.agent_system.prompt_enhancer_enabled else "disabled"
            self.status_var.set(f" Prompt Enhancer {status}")
            self.add_chat_message(" Settings", f"Prompt Enhancer agent {status}")
            self._draw_enhancer_toggle_switch()

    def _draw_enhancer_toggle_switch(self):
        """Draws the custom toggle switch based on the current state."""
        if not hasattr(self, 'enhancer_toggle_switch') or not hasattr(self, 'agent_system'):
            return
        self.enhancer_toggle_switch.delete("all")
        self.enhancer_toggle_switch.update_idletasks()
        width = self.enhancer_toggle_switch.winfo_width()
        height = self.enhancer_toggle_switch.winfo_height()
        if width <= 1 or height <= 1: # Fallback in case widget not fully rendered yet
            width = 50
            height = 22
        padding = 2
        oval_diameter = height - 2 * padding
        text_y_offset = height // 2
        if self.agent_system.prompt_enhancer_enabled:
            self.enhancer_toggle_switch.create_rectangle(
                0, 0, width, height,
                fill="#4CAF50", outline="#388E3C", width=1
            )
            self.enhancer_toggle_switch.create_text(
                (width - oval_diameter - padding) / 2, text_y_offset, text="ON", fill="white",
                font=("Segoe UI", 7, "bold"), anchor="center"
            )
            self.enhancer_toggle_switch.create_oval(
                width - oval_diameter - padding, padding,
                width - padding, height - padding,
                fill="white", outline="#BDBDBD"
            )
        else:
            self.enhancer_toggle_switch.create_rectangle(
                0, 0, width, height,
                fill="#F44336", outline="#D32F2F", width=1
            )
            self.enhancer_toggle_switch.create_text(
                (width + oval_diameter + padding) / 2, text_y_offset, text="OFF", fill="white",
                font=("Segoe UI", 7, "bold"), anchor="center"
            )
            self.enhancer_toggle_switch.create_oval(
                padding, padding,
                oval_diameter + padding, height - padding,
                fill="white", outline="#BDBDBD"
            )

    def analyze_selected_file(self):
        """Analyze selected file with agents"""
        selected = self.tree.selection()
        if not selected:
            return
        rel_path = Path(self.tree.item(selected[0], "values")[0])
        prompt = f"Please analyze the file '{rel_path}' and provide comprehensive feedback on code quality, design, and potential improvements."
        self.input_txt.delete("1.0", tk.END)
        self.input_txt.insert("1.0", prompt)
        self.send_enhanced_prompt()

    def review_visual_design(self):
        """Review visual design of selected file"""
        selected = self.tree.selection()
        if not selected:
            return
        rel_path = Path(self.tree.item(selected[0], "values")[0])
        if rel_path.suffix.lower() in ['.png', '.jpg', '.jpeg', '.gif', '.bmp']:
            prompt = f"Please analyze the visual design of '{rel_path}' image and provide detailed artistic feedback including composition, color theory, and suggestions for improvement."
        else:
            prompt = f"Please review '{rel_path}' for UI/UX design principles if it contains interface code, or suggest ways to make it more visually appealing."
        self.input_txt.delete("1.0", tk.END)
        self.input_txt.insert("1.0", prompt)
        self.send_enhanced_prompt()

    def prompt_api_key(self):
        """Enhanced API key prompt"""
        api_key = simpledialog.askstring(
            " API Key Configuration", 
            "Enter your Gemini API Key:\n(Required for multi-agent functionality)", 
            parent=self
        )
        if api_key:
            save_api_key(api_key)
            self.configure_enhanced_agents(api_key)
            messagebox.showinfo(" Success", "API Key saved and agents configured!")

    def on_tree_select(self, event):
        """Enhanced tree selection handler"""
        selected = self.tree.selection()
        if not selected:
            return
        rel_path = Path(self.tree.item(selected[0], "values")[0])
        file_path = VM_DIR / rel_path
        
        # Ensure the selected path is valid and within VM_DIR before proceeding
        safe_file_path = self.agent_system._safe_path(str(file_path.relative_to(VM_DIR)))
        if not safe_file_path or not safe_file_path.exists():
            self.status_var.set(f" Invalid or non-existent path selected: {rel_path}")
            self.current_open_file_path = None
            self.editor.delete("1.0", tk.END)
            self.canvas.delete("all")
            self.canvas.create_text(160, 160, text=" No image selected\nImages will be analyzed by Art Critic",
                               fill=self.fg_color_light, font=("Arial", 11), justify=tk.CENTER)
            return

        if safe_file_path.is_file():
            if safe_file_path.suffix.lower() in ['.png', '.jpg', '.jpeg', '.gif', '.bmp']:
                self.display_enhanced_image(safe_file_path)
                self.current_open_file_path = None # Not a text file for editor
                self.editor.delete("1.0", tk.END)
            else:
                self.display_file(safe_file_path)
        elif safe_file_path.is_dir():
            # Clear editor and image preview if a directory is selected
            self.current_open_file_path = None
            self.editor.delete("1.0", tk.END)
            self.canvas.delete("all")
            self.canvas.create_text(160, 160, text=" No image selected\nImages will be analyzed by Art Critic",
                               fill=self.fg_color_light, font=("Arial", 11), justify=tk.CENTER)
            self.status_var.set(f" Selected directory: {rel_path}")


    def display_file(self, path):
        """Enhanced file display"""
        try:
            self.current_open_file_path = path
            content = path.read_text(encoding='utf-8')
            self.editor.config(state="normal")
            self.editor.delete("1.0", tk.END)
            self.editor.insert("1.0", content)

            try:
                lexer = guess_lexer_for_filename(str(path), content, stripall=False)
            except ClassNotFound:
                lexer = get_lexer_by_name("text") # Fallback to plain text
            except Exception: # Catch other potential errors during lexer guessing
                lexer = get_lexer_by_name("text")

            self.editor.mark_set("range_start", "1.0")
            # Clear existing Pygments tags before re-applying to avoid layering issues
            for tag in self.editor.tag_names():
                if tag.startswith("pyg_"):
                    self.editor.tag_remove(tag, "1.0", tk.END)

            for ttype, value in lexer.get_tokens_unprocessed(content):
                tag_name = f"pyg_{str(ttype).replace('.', '_')}"
                self.editor.mark_set("range_end", f"range_start + {len(value)}c")
                # Check if tag exists (was configured from style)
                if tag_name in self.editor.tag_names():
                    self.editor.tag_add(tag_name, "range_start", "range_end")
                self.editor.mark_set("range_start", "range_end")
            
            self.notebook.select(0)
            line_count = len(content.splitlines())
            char_count = len(content)
            self.status_var.set(f" Loaded: {path.name} ({line_count} lines, {char_count} chars)")
        except UnicodeDecodeError:
            self.editor.delete("1.0", tk.END)
            self.editor.insert("1.0", " Error reading file: File is not valid UTF-8 text.")
            self.status_var.set(" File error: Not a UTF-8 text file.")
            self.current_open_file_path = None
        except Exception as e:
            self.editor.delete("1.0", tk.END)
            self.editor.insert("1.0", f" Error reading file: {str(e)}")
            self.status_var.set(f" File error: {str(e)}")
            self.current_open_file_path = None

    def save_current_file(self):
        """Enhanced file saving"""
        if self.current_open_file_path and self.current_open_file_path.is_file():
            try:
                content = self.editor.get("1.0", tk.END)
                self.current_open_file_path.write_text(content, encoding='utf-8')
                line_count = len(content.splitlines())
                char_count = len(content)
                self.status_var.set(f" Saved: {self.current_open_file_path.name} ({line_count} lines, {char_count} chars)")
                self._schedule_update_insights()
            except Exception as e:
                self.status_var.set(f" Save error: {str(e)}")
        else:
            self.status_var.set(" No file open to save")

    def new_file(self):
        """Enhanced new file creation"""
        file_name = simpledialog.askstring(            " New File", 
            "Enter file name (relative to project):\nTip: Include extension (.py, .js, .html, etc.)"
        )
        if file_name:
            if not hasattr(self, 'agent_system') or self.agent_system is None:
                messagebox.showerror(" Agent System Error", "Agent system not available. Cannot ensure safe path for new file.")
                return
            file_path = self.agent_system._safe_path(file_name)
            if file_path:
                try:
                    file_path.parent.mkdir(parents=True, exist_ok=True)
                    file_path.touch()
                    self.file_tree_cache_dirty = True
                    self._schedule_refresh_files()
                    self.display_file(file_path)
                    self.status_var.set(f" Created: {file_name}")
                    self._schedule_update_insights()
                except Exception as e:
                    self.status_var.set(f" Error: {str(e)}")

    def rename_file(self):
        """Enhanced file renaming"""
        selected = self.tree.selection()
        if not selected:
            return
        old_rel_path = Path(self.tree.item(selected[0], "values")[0])
        
        if not hasattr(self, 'agent_system') or self.agent_system is None:
            messagebox.showerror(" Agent System Error", "Agent system not available to perform renaming.")
            return

        old_full_path = self.agent_system._safe_path(str(old_rel_path)) # Get the safe full path
        if not old_full_path:
            self.status_var.set(f" Invalid path selected for rename: {old_rel_path}")
            return

        new_name = simpledialog.askstring(
            " Rename File", 
            f"Renaming: {old_rel_path.name}\nEnter new name:", 
            initialvalue=old_rel_path.name
        )
        if new_name:
            # Construct the new relative path and then get its safe full path
            new_rel_path = old_rel_path.parent / new_name
            new_full_path = self.agent_system._safe_path(str(new_rel_path))
            
            if not new_full_path:
                self.status_var.set(f" Invalid new path provided: {new_name}")
                return
            if new_full_path.exists():
                self.status_var.set(f" Target path already exists: {new_name}")
                return

            try:
                # Use os.rename, which works for both files and empty directories
                os.rename(str(old_full_path), str(new_full_path))
                
                if self.current_open_file_path and self.current_open_file_path == old_full_path:
                    self.current_open_file_path = new_full_path
                self.file_tree_cache_dirty = True
                self._schedule_refresh_files()
                self.status_var.set(f" Renamed: {old_rel_path.name}  {new_name}")
                self._schedule_update_insights()
            except Exception as e:
                self.status_var.set(f" Rename error: {str(e)}")

    def delete_file(self):
        """Enhanced file deletion (moves to trash)"""
        selected = self.tree.selection()
        if not selected:
            return
        path_value = self.tree.item(selected[0], "values")[0]
        
        if not hasattr(self, 'agent_system') or self.agent_system is None:
            messagebox.showerror(" Agent System Error", "Agent system not available to perform deletion.")
            return

        # Use the agent system's delete_file which moves to trash
        if messagebox.askyesno(" Confirm Deletion (to Trash)", f"Move '{path_value}' to .trash folder?"):
            try:
                result_message = self.agent_system._delete_file(path_value)
                self.status_var.set(result_message)
                self.add_chat_message(" System (Delete)", result_message, color=self.system_chat_color)

                # If the deleted file was the one open, clear editor
                full_path_deleted = self.agent_system._safe_path(path_value)
                if full_path_deleted and self.current_open_file_path and self.current_open_file_path == full_path_deleted:
                    self.editor.delete("1.0", tk.END)
                    self.current_open_file_path = None
                    # Also clear image preview if it was an image
                    self.canvas.delete("all")
                    self.canvas.create_text(160, 160, text=" No image selected\nImages will be analyzed by Art Critic",
                               fill=self.fg_color_light, font=("Arial", 11), justify=tk.CENTER)
                    
                self.file_tree_cache_dirty = True
                self._schedule_refresh_files()
                self._schedule_update_insights()

            except Exception as e:
                self.status_var.set(f" Delete error: {str(e)}")
                self.add_chat_message(" Error (Delete)", f"Deletion attempt failed: {str(e)}", color=self.error_chat_color)

    def clear_chat(self):
        """Enhanced chat clearing"""
        if messagebox.askyesno(" Clear Chat", "Clear all chat history?\n\nThis will also reset agent conversation memory."):
            self.chat.config(state="normal")
            self.chat.delete("1.0", tk.END)
            self.chat.config(state="disabled")
            if hasattr(self, 'agent_system'):
                # Reset conversation_history to an empty list
                self.agent_system.conversation_history = []
                self.agent_system.error_context = []
            self.add_chat_message(" System", "Chat history and agent memory cleared")

    def upload_screenshot(self):
        """Automatic screenshot capture and insertion"""
        try:
            import subprocess
            import time
            import threading
            from tkinter import filedialog
            
            # Check if agent_system is configured before proceeding
            if not hasattr(self, 'agent_system') or self.agent_system is None:
                messagebox.showerror(" Agent System Not Ready", "Agent system not configured. Cannot process screenshots.")
                return

            if messagebox.askyesno(" Screenshot Method", 
                                 "Choose screenshot method:\n\n" +
                                 "YES: Auto-capture (Windows Snipping Tool)\n" +
                                 "NO: Browse for existing image file"):
                self.status_var.set(" Starting screenshot capture...")
                self.screenshot_btn.config(state="disabled", text=" Capturing...")
                threading.Thread(target=self._auto_capture_screenshot, daemon=True).start()
            else:
                file_path = filedialog.askopenfilename(
                    title="Select Screenshot or Image",
                    filetypes=[
                        ("Image files", "*.png *.jpg *.jpeg *.gif *.bmp"),
                        ("PNG files", "*.png"),
                        ("JPEG files", "*.jpg *.jpeg"),
                        ("All files", "*.*")
                    ]
                )
                if file_path:
                    self._process_uploaded_image(file_path)
        except Exception as e:
            messagebox.showerror(" Screenshot Error", f"Screenshot functionality error: {str(e)}")
            self.screenshot_btn.config(state="normal", text=" Upload Screenshot")

    def _auto_capture_screenshot(self):
        """Automatically capture screenshot and save to project"""
        try:
            # Attempt to use Windows snippingtool
            try:
                subprocess.run(["snippingtool", "/clip"], shell=True, timeout=5)
                time.sleep(0.5) # Give it a moment to copy to clipboard
                self._monitor_clipboard_for_screenshot()
            except (FileNotFoundError, subprocess.CalledProcessError, subprocess.TimeoutExpired):
                # Fallback if snippingtool /clip fails or is not found
                self.msg_queue.put({
                    "type": "screenshot_info", 
                    "content": "Snipping Tool '/clip' option failed or not found. Attempting basic launch..."
                })
                try:
                    subprocess.Popen(["snippingtool"], shell=True) # Open snippingtool without /clip
                    time.sleep(1) # Give user time to take screenshot manually
                    self._monitor_clipboard_for_screenshot()
                except (FileNotFoundError, subprocess.CalledProcessError, subprocess.TimeoutExpired):
                    self.msg_queue.put({
                        "type": "screenshot_error", 
                        "content": "Could not launch Snipping Tool. Please use file browser option."
                    })
        except Exception as e:
            self.msg_queue.put({
                "type": "screenshot_error", 
                "content": f"Unexpected error during screenshot capture setup: {str(e)}"
            })

    def _monitor_clipboard_for_screenshot(self):
        """Monitor clipboard for screenshot and auto-save"""
        import time
        from PIL import ImageGrab
        max_wait_time = 30
        check_interval = 0.5
        checks = 0
        self.msg_queue.put({
            "type": "screenshot_info", 
            "content": "Take your screenshot now - it will auto-save when ready..."
        })
        while checks * check_interval < max_wait_time:
            try:
                clipboard_image = ImageGrab.grabclipboard()
                if clipboard_image is not None:
                    timestamp = int(time.time())
                    filename = f"screenshot_{timestamp}.png"
                    filepath = VM_DIR / filename
                    
                    # Ensure VM_DIR exists before saving
                    VM_DIR.mkdir(parents=True, exist_ok=True)
                    clipboard_image.save(filepath, "PNG")
                    self.msg_queue.put({
                        "type": "screenshot_success", 
                        "content": str(filepath.relative_to(VM_DIR)) # Pass relative path
                    })
                    return
                time.sleep(check_interval)
                checks += 1
            except Exception as e:
                self.msg_queue.put({
                    "type": "screenshot_error", 
                    "content": f"Clipboard monitoring or saving error: {str(e)}"
                })
                return
        self.msg_queue.put({
            "type": "screenshot_timeout", 
            "content": "Screenshot capture timed out. Please try again or use file browser."
        })

    def _process_uploaded_image(self, source_file_path_str: str):
        """Process uploaded image file: copies it to VM_DIR and triggers analysis."""
        try:
            source_path = Path(source_file_path_str)
            if not source_path.is_file():
                messagebox.showerror(" Upload Error", "Selected path is not a valid file.")
                return

            timestamp = int(time.time())
            original_name = source_path.name
            name_parts = original_name.rsplit('.', 1)
            base_name = name_parts[0] if len(name_parts) > 1 else original_name
            suffix = f".{name_parts[1]}" if len(name_parts) > 1 else ""

            # Create a unique filename in VM_DIR to avoid conflicts
            filename = f"{base_name}_{timestamp}{suffix}"
            destination_path = VM_DIR / filename
            
            VM_DIR.mkdir(parents=True, exist_ok=True) # Ensure VM_DIR exists
            shutil.copy2(source_path, destination_path)
            
            # Pass the relative path for consistency with other file events
            self._finalize_screenshot_processing(str(destination_path.relative_to(VM_DIR)))
        except Exception as e:
            messagebox.showerror(" Upload Error", f"Failed to process image: {str(e)}")

    def _finalize_screenshot_processing(self, filename_relative_to_vm: str):
        """Finalize screenshot processing and add to chat"""
        try:
            # Reconstruct the full path from the relative path
            filepath = VM_DIR / filename_relative_to_vm
            
            self._schedule_refresh_files()
            self.display_enhanced_image(filepath)
            analysis_prompt = f"Please analyze this screenshot '{filename_relative_to_vm}' and describe what you see, including any UI elements, code, text, or design patterns. Provide detailed feedback and suggestions for improvement."
            self._clear_placeholder(None)
            self.input_txt.delete("1.0", tk.END)
            self.input_txt.insert("1.0", analysis_prompt)
            self.add_chat_message(" Auto-Screenshot", f"Screenshot captured and saved as '{filename_relative_to_vm}' - analysis prompt ready!")
            self.status_var.set(f" Screenshot ready: {filename_relative_to_vm}")
            self.input_txt.focus()
            self.screenshot_btn.config(state="normal", text=" Upload Screenshot") # Ensure button is re-enabled
        except Exception as e:
            self.status_var.set(f" Screenshot processing error: {str(e)}")
            self.screenshot_btn.config(state="normal", text=" Upload Screenshot")

    def _process_messages(self):
        """Enhanced message processing with screenshot handling"""
        try:
            while not self.msg_queue.empty():
                msg = self.msg_queue.get_nowait()

                if msg["type"] == "agent":
                    agent_name = msg["agent"]
                    agent_colors = {
                        " Main Coder": "#2E8B57",
                        " Code Critic": "#FF6347",
                        " Art Critic": "#9370DB",
                        " Prompt Enhancer": "#FFD700",
                        " Assistant": "#4DB6AC",
                        " Collaborative": "#4169E1"
                    }
                    color = agent_colors.get(agent_name, self.fg_color_light)
                    self.add_chat_message(agent_name, msg["content"], color)
                elif msg["type"] == "agent_stream_chunk":
                    agent_name = msg["agent"]
                    stream_chunk_colors = {
                        " Main Coder": "#2E8B57",
                        " Code Critic": "#FF6347",
                        " Art Critic": "#9370DB",
                        " Art Critic (Proactive)": "#9370DB",
                        " Prompt Enhancer": "#FFD700",
                        " Assistant": "#4DB6AC",
                        " Persona Agent": self.fg_color_light, # Persona agent uses fg_color_light for stream chunks
                    }
                    color = stream_chunk_colors.get(agent_name, self.fg_color_light)
                    self._append_chat_chunk(agent_name, msg["content"], color)
                elif msg["type"] == "system":
                    self.add_chat_message(" System", msg["content"], color=self.system_chat_color)
                elif msg["type"] == "error":
                    error_content = msg.get("content", "An unspecified error occurred.")
                    self.add_chat_message(" Error", error_content, color=self.error_chat_color)
                    self.main_status.config(foreground=self.agent_status_error_color)
                    self.critic_status.config(foreground=self.agent_status_error_color)
                    self.art_status.config(foreground=self.agent_status_error_color)
                    error_summary = str(error_content).split('\n')[0]
                    self.status_var.set(f" Error: {error_summary[:100]}")
                elif msg["type"] == "agent_status_update":
                    agent_name_key = msg["agent"]
                    status = msg["status"]

                    agent_display_names = {
                        "main_coder": " Main Coder",
                        "code_critic": " Code Critic",
                        "art_critic": " Art Critic",
                        "art_critic_proactive": " Art Critic (Proactive)",
                        "prompt_enhancer": " Prompt Enhancer",
                        "planner_agent_direct": " Assistant",
                        "persona_agent": " Persona Agent"
                    }
                    display_name = agent_display_names.get(agent_name_key, agent_name_key.replace("_", " ").title())

                    target_widget = None
                    if agent_name_key in ["main_coder", "prompt_enhancer", "planner_agent_direct", "persona_agent"]:
                        target_widget = self.main_status
                    elif agent_name_key == "code_critic":
                        target_widget = self.critic_status
                    elif agent_name_key == "art_critic" or agent_name_key == "art_critic_proactive":
                        target_widget = self.art_status
                    
                    if target_widget:
                        if status == "active":
                            target_widget.config(foreground=self.agent_status_active_color)
                            self.status_var.set(f"{display_name} processing...")
                        elif status == "inactive":
                            target_widget.config(foreground=self.agent_status_inactive_color)
                            # Only clear status bar if this agent was the one explicitly shown
                            # to avoid overwriting another active agent's status
                            if f"{display_name} processing..." == self.status_var.get():
                                 self.status_var.set(" Enhanced Multi-Agent System processing...")
                elif msg["type"] == "screenshot_success":
                    filename_rel_path = msg["content"]
                    self._finalize_screenshot_processing(filename_rel_path)
                    # Button re-enabled in _finalize_screenshot_processing
                elif msg["type"] == "screenshot_error":
                    self.add_chat_message(" Screenshot Error", msg["content"], "#ff0000")
                    self.screenshot_btn.config(state="normal", text=" Upload Screenshot")
                elif msg["type"] == "screenshot_timeout":
                    self.add_chat_message(" Screenshot Timeout", msg["content"], "#ff6600")
                    self.screenshot_btn.config(state="normal", text=" Upload Screenshot")
                elif msg["type"] == "screenshot_info":
                    self.status_var.set(msg["content"])
                elif msg["type"] == "file_changed":
                    self.file_tree_cache_dirty = True
                    self._schedule_refresh_files()
                    self._schedule_update_insights()
                    changed_file_path_rel = Path(msg["content"])
                    changed_file_path_full = VM_DIR / changed_file_path_rel # Reconstruct full path
                    
                    # Check if the changed file still exists, or if it was deleted/moved
                    if not changed_file_path_full.exists():
                        # If the changed file doesn't exist, it might have been deleted.
                        # If this deleted file was the one open, clear editor.
                        if self.current_open_file_path and self.current_open_file_path == changed_file_path_full:
                            self.editor.delete("1.0", tk.END)
                            self.current_open_file_path = None
                            self.canvas.delete("all")
                            self.canvas.create_text(160, 160, text=" No image selected\nImages will be analyzed by Art Critic",
                               fill=self.fg_color_light, font=("Arial", 11), justify=tk.CENTER)
                            self.status_var.set(f" File closed: {changed_file_path_rel.name} was deleted.")
                        continue # Skip further processing for this non-existent file

                    # If the changed file is an image, display it
                    if changed_file_path_full.suffix.lower() in ['.png', '.jpg', '.jpeg', '.gif', '.bmp']:
                        self.display_enhanced_image(changed_file_path_full)
                    else:
                        # If the currently open file in the editor is the one that changed, re-display it.
                        if self.current_open_file_path and self.current_open_file_path.samefile(changed_file_path_full):
                            self.display_file(self.current_open_file_path)
                        # Else if there's no file open, and the changed file is a text file, open it implicitly
                        elif not self.current_open_file_path: # and not changed_file_path_full.is_dir():
                            # This part might be too aggressive; typically we only open files on user click.
                            # For now, we'll rely on the manual refresh/selection for opening.
                            pass

                elif msg["type"] == "replan_request":
                    reason = msg.get("reason", "Unknown reason.")
                    self.add_chat_message(" System", f" Re-plan requested: {reason}", color="#FFD700")
                    self.status_var.set(f" Re-planning: {reason[:80]}...")
                    # No specific action here as the re-plan logic is handled in run_enhanced_interaction loop itself
                    # This just ensures the message appears in the UI.

                elif msg["type"] == "done":
                    self.input_txt.config(state="normal")
                    self.send_btn.config(state="normal")
                    self.screenshot_btn.config(state="normal", text=" Upload Screenshot") # Ensure button is re-enabled
                    self.status_var.set(" Enhanced Multi-Agent System Ready")
                    # Reset all agent status indicators to inactive
                    self.main_status.config(foreground=self.agent_status_inactive_color)
                    self.critic_status.config(foreground=self.agent_status_inactive_color)
                    self.art_status.config(foreground=self.agent_status_inactive_color)

        except queue.Empty:
            pass

        self.after(100, self._process_messages)

    def on_close(self):
        """Enhanced close handler, ensures pending 'after' calls are cancelled."""
        if messagebox.askokcancel(" Exit", "Exit Enhanced Multi-Agent IDE?\n\nUnsaved changes will be lost."):
            if self._debounce_refresh_id:
                self.after_cancel(self._debounce_refresh_id)
                self._debounce_refresh_id = None
            if self._debounce_insights_id:
                self.after_cancel(self._debounce_insights_id)
                self._debounce_insights_id = None
            if self._save_timer:
                self.after_cancel(self._save_timer)
                self._save_timer = None
            self.destroy()

# -----------------------------------------------------------------------------
# Application Entry Point
# -----------------------------------------------------------------------------
if __name__ == "__main__":
    VM_DIR.mkdir(exist_ok=True)
    app = EnhancedGeminiIDE()
    app.mainloop()